<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Estimating Energy Consumption of Cloud, Fog and Edge Computing Infrastructures</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ehsan</forename><surname>Ahvar</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Anne-Cécile</forename><surname>Orgerie</surname></persName>
							<email>anne-cecile.orgerie@irisa.fr</email>
						</author>
						<author>
							<persName><forename type="first">Adrien</forename><surname>Lebre</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">with Univ. Rennes</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Adrien Lebre is with IMT-Atlantique</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<address>
									<settlement>Nantes</settlement>
									<region>LS2N</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Estimating Energy Consumption of Cloud, Fog and Edge Computing Infrastructures</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C3B339929A2E8FD6AFFD2FA8748EC9C5</idno>
					<idno type="DOI">10.1109/TSUSC.2019.2905900</idno>
					<note type="submission">Manuscript received May 31, 2018; revised December 8, 2018; accepted March 9, 2019.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-12T12:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Cloud computing</term>
					<term>energy consumption</term>
					<term>distributed Clouds</term>
					<term>Fog computing</term>
					<term>Edge computing</term>
					<term>Peer-to-peer</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In order to improve locality aspects, new Cloudrelated architectures such as Edge Computing have been proposed. Despite the growing popularity of these new architectures, their energy consumption has not been well investigated yet. To move forward on such a critical question, we first introduce a taxonomy of different Cloud-related architectures. From this taxonomy, we then present an energy model to evaluate their consumption. Unlike previous proposals, our model comprises the full energy consumption of the computing facilities, including cooling systems, and the energy consumption of network devices linking end users to Cloud resources. Finally, we instantiate our model on different Cloud-related architectures, ranging from fully centralized to completely distributed ones, and compare their energy consumption. The results show that a completely distributed architecture, because of not using intra-data center network and large-size cooling systems, consumes between 14% and 25% less energy than fully centralized and partly distributed architectures respectively. To the best of our knowledge, our work is the first one to propose a model that enables researchers to analyze and compare energy consumption of different Cloudrelated architectures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Energy consumption of Cloud Computing solutions has become one of the critical challenge of our modern computing facilities. Data centers (DCs) constitute major elements consuming energy in Cloud computing. According to Lawrence Berkeley National Laboratory (LBNL)'s report, published in 2016 <ref type="bibr" target="#b0">[1]</ref>, DCs consumed an estimated 70 billion kWh (about 1.8% of total U.S. electricity consumption) and they are projected to consume approximately 73 billion kWh by 2020 in the U.S.</p><p>At the same time, the proliferation of new usages related to Internet of Things (IoT) calls for more distributed cloudrelated architectures, relying on resources deployed across and at the edge of the network. Referred to as Fog, Edge and sometimes P2P computing infrastructures <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, these emerging virtualized architectures aim at satisfying low latency and high bandwidth requirements expected by IoT-based applications. While there is no more debate on whether such infrastructures will be deployed, the question of their energy footprint has not been studied yet.</p><p>The main objective of this paper is to propose a generic energy model to accurately evaluate and compare the energy consumed by these new Cloud-related architectures.</p><p>Frontiers of cloud-related architectures are currently moving, and we first present the existing definitions and the key features of each architecture. We then propose to identify each of them as one well defined architecture, ranging from centralized to fully distributed ones. To this end, we propose a taxonomy that categorizes available Cloud-related architectures based on their characteristics and classifies hardware elements of each infrastructure. Based on the proposed taxonomy, an energy model is proposed. As the model accurately considers the differences among architectures, it can be used to estimate energy consumption of one particular architecture as well as comparing them.</p><p>Our key contributions are to: (i) Develop a taxonomy of Cloud-related architectures and components that provide an extensive coverage of this field in terms of technical features, services and user satisfaction. The main aim of our proposed taxonomy is to explore the unique features of different architectures and components from similar paradigms and to provide a basis for categorizing present and future architectures. (ii) Present a generic and accurate model to estimate energy consumption of the existing Cloud-related infrastructures.</p><p>The model provides a basis for an in-depth analysis and clear understanding of the current Cloud landscape. Besides, this work gives an insight into the underlying technologies that are currently deployed in the domain. The rest of the paper is organized as follows: Section II presents the related work. Section III categorizes Cloudrelated architectures using our proposed taxonomy. Section IV introduces the proposed energy model. Energy consumption of different architectures are analyzed in Section V. Finally, Section VI concludes our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we first introduce existing Cloud-related infrastructures. Then, we provide a comparison among the energy models of the most commonly used Cloud and DC simulators. Finally, the efforts to compare energy consumption of different Cloud-related architectures are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Virtualized architectures</head><p>Cloud computing has recently moved to more distributed architectures as an answer to users' needs for mobility, high data volume processing and low latency. In 2014, the European Telecommunications Standards Institute (ETSI) has proposed a new Cloud architecture named Mobile Edge Computing <ref type="bibr" target="#b3">[4]</ref>. According to the initial definition, "Mobile-edge Computing provides IT and cloud-computing capabilities within the Radio Access Network (RAN) in close proximity to mobile subscribers" <ref type="bibr" target="#b3">[4]</ref>. The Mobile Edge Computing (MEC) group of ETSI was renamed to Multi-access Edge Computing in 2016 to enlarge its access to heterogeneous networks <ref type="bibr" target="#b4">[5]</ref>. MEC's infrastructures are managed through hierarchical or distributed control depending on the considered application <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. They can include mobile devices when they are used to provide computation to smaller devices <ref type="bibr" target="#b6">[7]</ref>.</p><p>Driven by the expansion of Internet of Things (IoT), Cisco proposed in 2012 the concept of Fog Computing <ref type="bibr" target="#b7">[8]</ref>. According to the Open Fog Consortium, "Fog computing is a system-level horizontal architecture that distributes resources and services of computing, storage, control and networking anywhere along the continuum from Cloud to Things" <ref type="bibr" target="#b8">[9]</ref>. In particular, this architecture aims at dealing with the timesensitive and large volumes of data generated at the network edge by IoT devices <ref type="bibr" target="#b9">[10]</ref>. To this end, Fog computing can extend the cloud to any device nearby the Things and with computing, storage and network connectivity <ref type="bibr" target="#b7">[8]</ref>. The Fog Computing architecture can be seen as hierarchical with three layers: the IoT devices, the Fog nodes and the Cloud data center <ref type="bibr" target="#b9">[10]</ref>. Depending on the applications, the fog nodes are managed either in a decentralized or distributed way <ref type="bibr" target="#b9">[10]</ref>.</p><p>From the industrial point of view, the differences between both models are unclear and some actions such as the Open Glossary of Edge Computing initiated by the Linux Foundation aims at providing accurate definitions on this topic <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Energy models and simulation tools</head><p>Recent studies <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref> show that more than 20 Cloud and DC simulators have been proposed in the past decade, CloudSim <ref type="bibr" target="#b13">[14]</ref> being one of the most popular. Despite its advantages (e.g., modeling large-size DCs, federation model and supporting large number of virtual machines), CloudSim has several limitations, including limited communication and network energy models. Because of the extensible nature of CloudSim, a lot of works <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b16">[17]</ref> have been done for enriching it. Among them, a few works focused on energy model of CloudSim. For example, Li et al. <ref type="bibr" target="#b16">[17]</ref> proposed DartCSIM to enable the simulation of energy and network simultaneously. Other Cloud simulators have been proposed, like iCanCloud <ref type="bibr" target="#b17">[18]</ref>, but they are not designed to support distributed DC architectures <ref type="bibr" target="#b18">[19]</ref>. Malik et al. <ref type="bibr" target="#b18">[19]</ref> proposed CloudN etSim++ which is a GUI-Based framework for modeling and simulation of DCs in OMNeT++ including simulation models for network devices. Yet, this simulator does not consider effect of packet length on energy consumption in its models. Finally, the SimGrid toolbox proposes accurate modeling of virtual machines <ref type="bibr" target="#b19">[20]</ref>, and energy consumption of servers <ref type="bibr" target="#b20">[21]</ref>. But, the energy consumption of network components is not provided.</p><p>Despite existence of above mentioned tools, we could not find a simple model or simulator that easily supports different Cloud-related architectures, ranging from fully centralized to completely distributed, without going into the details of programming and extending the aforementioned simulators. For example, in order to compare different Cloud-related architectures, we need to consider the number and location of their control nodes, as discussed later in this article. Finally, a majority of the available simulators also does not produce accurate results of architectures components or do not consider their idle energy consumption part. For all these reasons, we design a generic energy model to compare different Cloudrelated architectures.</p><p>To the best of our knowledge, our work is the first one to propose a model that enables researchers to analyze (and so compare) energy consumption of different Cloud-related architectures. Although, Jalali et al. <ref type="bibr" target="#b21">[22]</ref> compare energy consumption of applications provided by a centralized DC and Fog Computing, several parts of their proposed energy models are not accurate enough to answer the questions of energy footprint of Cloud-related architectures. Li et al. <ref type="bibr" target="#b22">[23]</ref> compare the energy consumption of IoT applications provided by centralized Cloud and Edge computing. C. Fiandrino et al. <ref type="bibr" target="#b23">[24]</ref> also propose metrics to assess and compare energy efficiency of communication systems of Cloud Computing DCs. In all cases <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b23">[24]</ref>, the proposed models are incomplete for accurately analyzing the various Cloud-related architectures. For instance, as the size and intra-network topology of centralized DC are not considered, the part of intra-DC network cannot be analyzed. Moreover, they often focus on the impact of a given application or kind of applications <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED TAXONOMY</head><p>In recent years, many Cloud-related architectures have been proposed to satisfy both users and providers requirements. Putting architectures with several similar characteristics into the same group can noticeably simplify presentation and design of our energy model. To this end, we propose a taxonomy to appropriately cover and classify these architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Cloud-related Architectures</head><p>A Cloud-related architecture includes one or more DCs and a number of end users, all connected together through telecommunication networks. An end user is a sender of requests and a receiver of services. A DC offers different Cloud services to the end users and consists of a number of Compute Nodes (CNs) that host the Virtual Machines (VMs), and Service Nodes (SNs) that are either infrastructure management nodes or storage nodes. The main distinctions among Cloud-related architectures are location, number, size and role (e.g., controller, storage, compute together or part of them) of their DCs.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> shows our proposed taxonomy. Based on DC characteristics, we divide architectures into four main groups: Fully Centralized (FC), Partly Distributed (PD), Fully Distributed-Centralized Controller (FD-CC), and Fully Distributed (FD). Fully Centralized (FC) -The FC architecture includes a large-size DC. All end users connect to the central DC and receive services from it. Partly Distributed (PD) -In a PD architecture, several DCs are distributed through different locations and working together to serve the end users. A telecommunication network connects the Cloud DCs together. It also connects end users to DCs. In a PD architecture, the DCs are usually located closer to end users in comparison to the FC architecture, because of the higher number of DCs. However, the DCs are not located in end users premises.</p><p>Fully Distributed with Centralized Controller (FD-CC) -FD-CC architecture includes several DCs that are located on end users premises (i.e., one DC for one or a few end users). However, controller(s) (i.e., as SNs) are located in one or more DCs in the core of network. The DCs that are located in the end users premises are usually in size of a Physical Machine (PM). The remaining DCs, in core of network, are only used for management aspect and they are not used for computing and storage services.</p><p>Fully Distributed (FD) -In an FD architecture, unlike for FD-CC, the management system is also distributed on end users locations. It means there is no DC in the core of network in charge of controlling the resources (i.e., no independent SN).</p><p>The employed abbreviations are summarized in Table <ref type="table">I</ref>. The FC architecture represents centralized Cloud infrastructures. Examples of PD architectures can be found among decentralized Fog infrastructures <ref type="bibr" target="#b9">[10]</ref>. The FD-CC architecture gathers the hierarchical Fog and Edge infrastructures with distributed nodes and decentralized management nodes, hosting for instance Virtual Network Functions' (VNFs) orchestration <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b9">[10]</ref>. Finally, the FD architecture represents the fully distributed edge infrastructures <ref type="bibr" target="#b5">[6]</ref>. Note that in the context of this work, we do not consider the wide variety of wireless network technologies <ref type="bibr" target="#b25">[26]</ref>. It is considered as future work to include an architecture with mobile fog nodes.   Besides, DCs can be classified by their size: mega when the number of hosted PMs is higher than 10,000, micro when this number is less than 500, and finally nano when there is only a few PMs. In our case, we consider an extreme case where a nano DC consists of one single PM and does not have any extra additional ICT equipment such as the intra-DC network elements (i.e., switches and links). Moreover, it is noteworthy that all DCs but nano ones also have non-ICT equipment such as an independent cooling system. To reflect the energy consumption of non-ICT equipment available in DCs (i.e., from the micro to the mega ones), the Power Usage Effectiveness (PUE) is a well-known DC energy-efficiency indicator. It represents the ratio between the total facility and the IT equipment energy consumption <ref type="bibr" target="#b26">[27]</ref>. In other words, the overall energy consumption of a DC can be estimated by multiplying the energy consumption of its ICT equipment and its PUE value.</p><p>As Figure <ref type="figure" target="#fig_1">2</ref> shows, PMs can be classified into two main types: Type 1 PMs are specialized for computing purposes (e.g., Computing and Cloud management nodes). Type 2 PMs are used to store large data-sets thanks to their specific storage backends (i.e., storage node). Because of the additional storage devices, each type of PM presents a different energy profile. In the DC terminology, Compute Nodes (CNs) correspond to type 1, while Service Nodes (SN) correspond to type 1 if they manage the infrastructure, or to type 2 if they are used for storage purposes. In the extreme case of FD architecture, with a single CN-based PM, SN functions are simply served by a VM directly hosted on the CN and using local disks as the default storage backend.</p><p>In addition to PMs, ICT equipment of a mega or micro DC includes network elements, like routers, switches and links, to connect PMs together. The number and type of network elements to connect PMs inside a DC is determined by its network topology. More than thirty network topologies have been proposed for DCs <ref type="bibr" target="#b27">[28]</ref> since 2008. In this work, we consider a fat tree switch-centric architecture (i.e., n-ary fat tree topology) which corresponds to the network topology of many currently available DCs <ref type="bibr" target="#b28">[29]</ref>.</p><p>Utilizing small-size and identical switches is considered as one noticeable benefit of the fat tree topology. This enables to utilize cheap commodity parts for all of the switches in the communication architecture. Besides, it simplifies the system model and analysis compared to architectures with non identical switches. This topology is flexible and scalable, thus adaptable to different sizes of DCs. We consider a n-ary fat tree topology with three layers (i.e., core, aggregation and edge), (n/2) 2 core switches, and n pods (i.e., each pod has two layers of n/2 aggregation and n/2 edge switches) <ref type="bibr" target="#b29">[30]</ref>. This topology uses similar n-port switches, and can support up to n 3 /4 PMs. An example with n = 4 is provided in Figure <ref type="figure">3</ref>. Fig. <ref type="figure">3</ref>. 4-ary fat tree topology from <ref type="bibr" target="#b29">[30]</ref> Finally, the telecommunication network connects all DCs and end users together. It usually includes four main logical layers <ref type="bibr" target="#b30">[31]</ref>: core, backbone, metro and feeders (or end users). The metro layer provides access to the network for the end users. The backbone layer provides policy-based connectivity. The core layer offers high-speed transport to satisfy the requirements of the backbone layer devices. For the FC architecture, we assume the single DC to be connected directly to the core layer of the telecommunication network. For the PD architecture, the DCs are connected either to backbone or metro routers. For the FD-CC architecture, the DCs with CNs are connected either to backbone or metro routers and DCs with SNs are connected to the core layer. Finally, for the FD architecture, DCs are connected to the feeder layer. We assume that the routing policy always uses the shortest path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. THE ENERGY MODEL</head><p>In this section, we introduce our energy model defined for the different Cloud-related architectures. We consider a scenario with V active VMs requested by a set of U end users. Our goal is to provide a generic model in order to estimate the energy consumption of each aforementioned cloud-related infrastructures for a given time period T when the allocated VMs are running. We underline that we do not take into consideration the differences among these architectures in terms of Quality-of-Service (i.e., latency). Besides, only the energy consumption of the infrastructure itself is estimated: it includes the telecommunication network between DCs and users but not the end users' devices. In order to estimate energy consumption of an architecture, the model receives a set of inputs listed in Table <ref type="table" target="#tab_1">II</ref>, along with their definitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. General overview</head><p>As Figure <ref type="figure" target="#fig_3">4</ref> shows, our model divides energy consumption of an ICT equipment into static and dynamic parts <ref type="bibr" target="#b31">[32]</ref>. The static energy consumption is the energy consumption without considering any workload (i.e., resources are idle). The dynamic cost is calculated based on the current usage of Cloud resources by the active VMs.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Static energy part of the model</head><p>As Figure <ref type="figure" target="#fig_3">4</ref> shows, static energy part of a Cloud-related architecture includes static energy of PMs and switches. For a PM, the idle power consumption corresponds to the power consumed by the server when powered on but not running any task <ref type="bibr" target="#b31">[32]</ref>. Similarly, the energy consumption of loadindependent part of a switch is considered as its idle power consumption. It includes the power consumption of elements such as chassis power supply and fans <ref type="bibr" target="#b32">[33]</ref>.</p><p>For each device, PM or switch, its static energy consumption corresponds to idle power consumption over the considered time period T as defined in Table <ref type="table" target="#tab_1">II</ref>. As the idle power consumption is constant over time, multiplying it by T gives the energy consumption over the time period T . Consequently, the static energy consumption of DC i corresponds to:</p><formula xml:id="formula_0">E static DC i = a∈CN i (P idle a •T )+ b∈SN i (P idle b •T )+ c∈N E i (P idle c •T )<label>(1)</label></formula><p>In Equation <ref type="formula" target="#formula_0">1</ref>, CN i , SN i , and N E i correspond to the number of CN-based PMs, SN-based PMs, and intra-DC switches for DC i . P idle x corresponds to the idle power consumption of device x that can be: a PM type 1 if it belongs to CN i or SN i for some architectures; a PM type 2 if it belongs to SN i for some architectures; or an intra-DC switch if it belongs to N E i . For fully distributed architectures with nano DCs, consisting of one PM only, N E i = ∅ ∀i since nano DCs do not need switches.</p><p>For the telecommunication network part, the static energy consumption corresponds to the idle power consumption of routers that are employed to link the DCs and the end users. So the static energy consumption of the architecture's network can be expressed as:</p><formula xml:id="formula_1">E static N et = r∈RT (P idle r • T )<label>(2)</label></formula><p>If some devices are in sleep mode instead of being idle for energy-aware management purpose, then the idle power consumption of these devices should be replaced by their power consumption in sleep mode in Equations 1 and 2. This parameter is not included in the equations for clarity's sake.</p><p>Putting all pieces together, the total static energy consumption of an architecture is computed as follows:</p><formula xml:id="formula_2">E static total = N i=1 (E static DC i • P U E i ) + E static N et<label>(3)</label></formula><p>This equation gives the total static energy consumption as the sum of the static energy consumption of the telecommunication network devices and the static energy consumption of each DC including its cooling-related energy consumption (expressed by the PUE). In the following, we describe the dynamic energy consumption part attributed to PMs, intra-DC switches and telecommunication routers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. PMs dynamic energy consumption</head><p>Dynamic energy consumption of PMs depends mainly on CPU utilization <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b31">[32]</ref>. Based on previous work on multicore servers <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b33">[34]</ref>, we use a piecewise linear function to express the dependence of PM's dynamic energy consumption to its CPU utilization. This mapper function is instantiated with values taken from real energy measurements when fully loading the cores of a PM one by one. In <ref type="bibr" target="#b20">[21]</ref>, the authors show that this model is accurate to a few percent for the considered applications. So, for a PM x with k cores, average power consumption values are measured for 1, 2, and up to k fully loaded cores. Then, to these values are subtracted the idle power consumption of the PM P idle x to keep only the dynamic part. These dynamic power consumption values are denoted P cores x,j with j ∈ {0, . . . , k} and P cores x,0 = 0. The energy consumption mapper function is linear between each of these values. So, for a PM using a ratio u of its full CPU capacities, if j/k ≤ u ≤ (j + 1)/k with j ∈ {0, . . . , k -1}, then the dynamic energy consumption of a given PM x during time period T can be expressed as:</p><formula xml:id="formula_3">E dyn x = T •[(P cores x,j+1 -P cores x,j )•k•u+[(j+1)•P cores x,j -j•P cores x,j+1 ]]<label>(4</label></formula><p>) From the generic formula for a PM provided by Equation <ref type="formula" target="#formula_3">4</ref>, one can derive the formulas for our two categories of PMs in DC i by defining how to compute u CN and u SN respectively for CNs and SNs-based PMs. For SNs, we assume an average CPU utilization over time period T to determine their energy consumption, so u SN is a fixed constant value. Recall that, SN-based PMs may have more disks than the other PMs. This additional energy consumption is reflected in the static energy consumption part by a higher idle power consumption for these nodes (P idle in Equation <ref type="formula" target="#formula_0">1</ref>). Similarly, for distributed architectures, as CN nodes play both roles (computing and storage), they have a higher idle power consumption.</p><p>For CNs belonging to CN i for DC i , their CPU utilization depends on the services and VMs it runs. For the VMs, their size in number of virtual CPUs is not a good estimator of their actual CPU utilization. Indeed, typical Cloud users tend to over-provision their VMs. Indeed, they target peak usage and do not fully utilize resource elasticity, thus inducing a low CPU usage inside VMs <ref type="bibr" target="#b33">[34]</ref>. Moreover, Cloud providers resort to CPU over-commitment techniques for increasing their revenue without additional investment <ref type="bibr" target="#b33">[34]</ref>. Hence, estimating energy consumption of a PM based on reserved resources of its VMs can lead to overestimation (i.e., estimating even more than maximum power consumption of the PM). An alternative approach would consist in obtaining the actual CPU usage of PMs. Yet, it would be tedious to determine the exact CPU usage for each VM on each PM, and it might be difficult to acquire it on a production infrastructure. Furthermore, our model does not target a fine-grained computation of the energy consumption, but rather an overall estimation to compare Cloud-related architectures under the same initial workload conditions. Consequently, we consider here u V M the average ratio for the CPU utilization per VM. Similarly, since our goal does not consist in evaluating VM placement strategies, we consider here a uniform allocation of VMs over PMs. For instance, such an even distribution is the default scheduling behavior of the well-known cloud operating system OpenStack <ref type="bibr" target="#b34">[35]</ref>.</p><p>The values for the average CPU utilization per VM u CN and the number of VMs per CN provide an estimate of the CPU usage per CN. To this utilization, we add a fixed amount u H in order to account for the hypervisor energy consumption and all the Cloud-related processes for monitoring the PMs. The overall model for computing the dynamic energy consumption of a CN-based PM is depicted in Figure <ref type="figure" target="#fig_4">5</ref>. So we have: Finally, using Equation <ref type="formula" target="#formula_3">4</ref>, the dynamic energy consumption related to PMs in DC i is:</p><formula xml:id="formula_4">u CN = u H + u V M • V / N i=1 |CN i |<label>(5)</label></formula><formula xml:id="formula_5">E dyn DC i P M = a∈CN i E dyn a + b∈SN i E dyn b<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Intra-DC network dynamic energy consumption</head><p>For estimating dynamic energy consumption of an intra-DC network, we need to estimate dynamic load-dependent energy consumption of each switch inside each DC. This step is done for the Cloud-related architectures whose DCs possess switches (i.e., not fully distributed ones). When a switch carries traffic, it consumes additional load-dependent power for packet processing and also for storing and forwarding the payload across the switch fabric <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>. This additional load-dependent power consumption corresponds to the dynamic energy consumption of the switch.</p><p>As we consider a fat tree topology for the intra-DC network with identical switches, their energy profiles are identical. For a given switch belonging to a DC, we denote E pkt switch the energy to process a packet and E SF switch the energy for storing and forwarding a byte (from a packet). In <ref type="bibr" target="#b32">[33]</ref>, the authors show that this model based on two parameters (i.e., consumption per packet and per byte) presents less than 1% error compared to real measurements when correctly instantiated.</p><p>Similarly to the VM's CPU utilization, it would be tedious to keep trace of the size of each packet and this fine-grained accuracy is not required for our model. So, we assume packets to have an average length of L bytes for the entire infrastructure. Consequently, if the switch receives np T packets during a time period T , it has to process np T × L bytes during T .</p><p>So, for a given switch, during a time period T , its dynamic energy consumption is computed as follows:</p><formula xml:id="formula_6">E dyn switch = E pkt switch • np T + E SF switch • np T • L (7)</formula><p>Hence, we can express the dynamic energy consumption due to the switches in DC i during a time period T as follows: In order to estimate np T , we use the properties of the n-ary fat tree topology of the intra-DC network. As illustrated by Figure <ref type="figure" target="#fig_5">6</ref>, there are two types of traffic inside a data center DC i : internal traffic (i.e., traffic exchanged between PMs of the DC) denoted V in DC i , and external traffic (i.e., traffic between PMs of the DC and outside) V out DC i . For the external traffic, it is sent to or received from end-users or other data centers. First, we identify the paths taken by each type of traffic, then we quantify the data volumes for each of them.</p><formula xml:id="formula_7">E dyn DC i N E = E dyn switch • |N E i | = E dyn switch • 5n 2 /4<label>(8)</label></formula><p>A DC with a 3-level fat tree topology, using similar switches with n ports can embed up to n 3 /4 PMs and 5n 2 /4 switches <ref type="bibr" target="#b29">[30]</ref>. Due to the topology properties, each server can transmit at line speed if packets are uniformly distributed along the redundant paths. Furthermore, for such a topology, the longest path between PMs comprises 6 hops, and asymptotically, the number of hops also tends to 6 for a 3-level fat tree topology <ref type="bibr" target="#b37">[38]</ref>. Thus, we estimate that the traffic staying inside DC uses 5 switches on average. The traffic going out of the DC uses 3 switches (i.e., the shortest path, which includes 1 access, 1 aggregation and 1 core switches). Similarly, the traffic coming from outside the DC to PMs uses 3 switches.</p><p>As VMs are assumed to be evenly distributed among PMs and generate the same amount of traffic, we assume that the traffic generated per VM is also uniform on average. We denote λ the average traffic rate (in bps) of a PM. It depends on the average number of VMs hosted on the PM. So, during a time period T , each PM produces an average number of packets of (λ • T /8L) (with L being the average length of a packet in bytes). We denote q the average ratio of packets sent to end users per PM. The external traffic comprises the packets sent to end users and to PMs belonging to other DCs. A given DC i comprises pm i PMs with pm i = |CN i | + |SN i |. So, for DC i , (pm i • q • λ • T /8L) packets are sent to end users during T .</p><p>As a uniform distribution of VMs is assumed among PMs, the traffic from a given PM to other PMs is evenly distributed among PMs. This means that we can compute p the probability that the traffic generated by a PM for other PMs stays inside its host DC:</p><formula xml:id="formula_8">p = pm i -1 N i=1 pm i -1<label>(9)</label></formula><p>These packets have a probability p of staying inside the data center (internal traffic), and a probability (1 -p) of going outside the data center (external traffic). For nano DCs (containing only one node), p = 0. So, during T each PM of DC i sends (p • λ(1 -q)T /8L) packets that stay inside DC i , and ((1 -p)λ(1 -q)T /8L) packets that are on average uniformly distributed among the other DCs. Similarly, DC i receives packets from other DCs uniformly distributed.</p><p>For the traffic coming from end users, we denote µ the average traffic rate generated by each user to DCs (in bps). So, DC i receives (U •µ•T )/(8L•N ) from the end users during T with U the total number of end users and N the number of DCs. We can then express the overall traffic processed in a DC as the sum of: the traffic sent to end users, the internal traffic exchanged between its PMs, the traffic sent to other DCs, the traffic coming from other DCs and the traffic coming from end users. Then np T , the average number of packets processed by a switch during T , is equal to the overall traffic processed in DC i by all the switches during T divided by the number of switches of DC i and the average size of a packet (8L in bits):</p><formula xml:id="formula_9">npT = 3 • q • λ • pm i + 5 • p • λ • (1 -q) • pm i + 3 • (1 -p) • λ • (1 -q) • pm i + 3 • j∈{1...N }\{i} (1 -p) • λ • (1 -q) • pm j (N -1) + 3 • U • µ N 8 • L • 5 • n 2 4 (<label>10</label></formula><formula xml:id="formula_10">)</formula><p>Finally, combining Equations 6 and 8, we compute the overall dynamic energy consumption of DC i :</p><formula xml:id="formula_11">E dyn DC i = (E dyn DC i P M + E dyn DC i N E ) • P U E i<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Telecommunication network dynamic energy consumption</head><p>Now we detail how to compute the dynamic energy consumption of the telecommunication network that is linking DCs among them and with the users. We consider a full telecommunication network with four different types of routers: core, backbone, metro and feeder routers all included in RT . Similarly to the dynamic energy consumption of switches in Equation <ref type="formula">7</ref>, the dynamic energy consumption of the telecommunication network during T is equal to:</p><formula xml:id="formula_12">E dyn N et = r∈RT (E pkt r • np r,T + E SF r • np r,T • L) (12)</formula><p>with np r,T the average number of packets processed by a given router r during T , E pkt r the energy to process a packet and E SF r the energy for storing and forwarding a byte. These two last parameters depend on the router type since routers from different types have different architectures and energy profiles. We denote n C , n B , n M and n F respectively the number of Core, Backbone, Metro and Feeders routers (|RT | = n C + n B + n M + n F ). So, if we split Equation 12 to express it with each category of router, we obtain:</p><formula xml:id="formula_13">E dyn N et = nC • (E pkt r C • npr C ,T + E SF r C • npr C ,T • L) + nB • (E pkt r B • npr B ,T + E SF r B • npr B ,T • L) + nM • (E pkt r M • npr M ,T + E SF r M • npr M ,T • L) + nF • (E pkt r F • npr F ,T + E SF r F • npr F ,T • L)<label>(13)</label></formula><p>In order to estimate the average number of packets of each type of router, we need to detail the possible paths taken by traffic and estimate probability of each path. There are three types of traffic using the telecommunication network: we denote np DC DC T , np EU DC T and np DC EU T respectively the overall number of packets during T using the telecommunication network between DCs, from end users to DCs and from DCs to end users. From the previous subsection, we have:</p><formula xml:id="formula_14">np DC DC T = N i=1 (1 -p) • λ • (1 -q) • pm i • T (8 • L) np EU DC T = U • µ • T /(8 • L) np DC EU T = N i=1 q • λ • pm i • T (8 • L) (14)</formula><p>Now, for each traffic type, we have to estimate the different paths that it can take and their probability in order to determine np r,T for all the routers (r ∈ RT ). Note that while the volume is different, traffic from end users to DCs and from DCs to end users employs the same paths (in the other direction). Each path depends on the considered architecture, so we will detail them one by one for a given topology in order to determine the probabilities for each path. For the telecommunication network topology, we consider a recursive topology presented in <ref type="bibr" target="#b30">[31]</ref> as a realistic simplified version of a national Internet Service Provider. Figure <ref type="figure" target="#fig_6">7</ref> illustrates this topology. To simplify the model, we assume all core routers are directly connected together. For the FC architecture (fully centralized), the only DC is connected to one of the core routers (p = 0). So, there are only two possible paths for the traffic between DC and end users: CBMF or CCBMF (in case the user is not connected to the same core router), with C, B, M and F respectively standing for Core, Backbone, Metro and Feeder routers. As the core layer comprises n C routers and the users are assumed to be evenly distributed among the feeders, the first path is taken in one case over n C , and the second path in n C -1 cases over n C . It means that for the FC architecture, we have:</p><formula xml:id="formula_15">np F C r C ,T = ( 1 /n C + 2 • n C -1 /n C )(np EU DC T + np DC EU T )/nC np F C r B ,T = (np EU DC T + np DC EU T )/nB np F C r M ,T = (np EU DC T + np DC EU T )/nM np F C r F ,T = (np EU DC T + np DC EU T )/nF<label>(15)</label></formula><p>For the PD architecture (partially distributed), DCs can be connected to Metro or Backbone routers. Table <ref type="table" target="#tab_2">III</ref> indicates the possible paths and their probability (considering a uniform distribution of the allocated VMs). </p><formula xml:id="formula_16">/n M MBM 1 /2n M FMBCBM 1 /n C -1 /n M MBCBM 1 /2n C -1 /2n M FMBCCBM 3 /n C MBCCBM 3 /2n C FMB 1 /n M MB 1 /n M FMBCB 1 /n C -1 /n M MBCB 1 /n C -1 /n M FMBCCB 3 /n C MBCCB 3 /n C BB 1 /2n M BCB 1 /2n C -1 /2n M BCCB 3 /2n C</formula><p>Using Table <ref type="table" target="#tab_2">III</ref>, we can compute, for the PD architecture, the number of packets processed by a router during T for each type of router:</p><formula xml:id="formula_17">np P D r C ,T = ( 14 /n C -2 /n M ) • np DC DC T /nC + ( 14 /n C -2 /n M )(np EU DC T + np DC EU T )/nC np P D r B ,T = ( 16 /n C -3 /2n M ) • np DC DC T /nB + ( 16 /n C -3 /n M )(np EU DC T + np DC EU T )/nB np P D r M ,T = ( 8 /n C ) • np DC DC T /nM + (1 + 4 /n C -1 /n M )(np EU DC T + np DC EU T )/nM np P D r F ,T = (np EU DC T + np DC EU T )/nF<label>(16)</label></formula><p>For the FD architecture (fully distributed), DCs are connected to Feeder routers. It means that User-DC paths are identical to DC-DC paths. Table <ref type="table" target="#tab_3">IV</ref> indicates the possible paths and their probability. </p><formula xml:id="formula_18">/n F F 1 /n F FMF 2n M/n F -1 /n F FMF 2n M/n F -1 /n F FMBCBMF 2 /n C -2n M/n F FMBCBMF 2 /n C -2n M/n F FMBCCBMF 6 /n C FMBCCBMF 6 /n C</formula><p>Using Table <ref type="table" target="#tab_3">IV</ref>, we compute for FD the number of packets processed by a router during T for each type of router:</p><formula xml:id="formula_19">np F D r C ,T = ( 14 /n C -2n M/n F ) • np DC DC T /nC + ( 14 /n C -2n M/n F )(np EU DC T + np DC EU T )/nC np F D r B ,T = ( 16 /n C -4n M/n F ) • np DC DC T /nB + ( 16 /n C -4n M/n F )(np EU DC T + np DC EU T )/nB np F D r M ,T = ( 16 /n C -2n M -1 /n F ) • np DC DC T /nM + ( 16 /n C -2n M -1 /n F )(np EU DC T + np DC EU T )/nM np F D r F ,T = ( 16 /n C -1 /n F ) • np DC DC T /nF + ( 16 /n C -1 /n F )(np EU DC T + np DC EU T )/nF<label>(17)</label></formula><p>Finally, for the FD-CC architecture, DCs containing the CNs are located as for the FD architecture, but SNs are considered to be located in control DCs connected to the core. While the traffic between CN and SN is internal for all the other architectures (intra-DC), it is external for FD-CC. Thus, it represents an additional traffic compared to the FD architecture. We denote λ SN the average traffic sent by a CN to an SN (in bps). It means λ SN ≤ λ. The path for the DC-SN traffic is FMBC. Consequently, during T , each type of router has an additional traffic of N i=1 (λ SN pm i ) • T /(8 • L) packets compared to the FD architecture. For User-DC traffic, it is highly dominated by traffic between users and CNs.</p><p>Combining Equations 11 and 12 gives the total dynamic energy consumption of a Cloud-related architecture:</p><formula xml:id="formula_20">E dyn total = N i=1 E dyn DC i + E dyn N et<label>(18)</label></formula><p>Finally, for each architecture, its static energy consumption during T is given by Equation <ref type="formula" target="#formula_2">3</ref>and its dynamic energy consumption by Equation <ref type="formula" target="#formula_20">18</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. MODEL EXPLOITATION</head><p>This section analyzes and compares the four different categories of architectures together, using the proposed energy model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Model instantiation</head><p>In order to have a fair comparison, we consider the same number of CNs for all Cloud architectures: 1, 000 CNs, for a duration of one hour. Recall that, in FD and FD-CC architectures, CNs also support SN and/or storage services as well, so CNs of these architectures are more powerful. We consider a FC architecture with one large-size DC embedding the 1, 000 CNs. The PD infrastructure includes 8 mediumsize homogeneous DCs with 125 CNs each. The FD-CC architecture comprises 1, 000 nano DCs with 1 CN each, and 8 central small-size controller DCs with the SNs. Finally, the FD architecture, similar to FD-CC, consists of 1, 000 nano DCs with 1 CN each. Table <ref type="table">V</ref> summarizes the configuration for each architecture. The number of SN-based PMs is based on the number of CNs and the architecture characteristics. For a mega/micro DC in FC or PD architectures, we consider 3 global SNs (to ensure high availability) and 1 additional SN for each 100 CNs. Regarding FD-CC, we consider 3 SNs inside each of 8 small-size DCs in the core of network. For FD architecture, there is only one multi-purpose PM per nano DC.</p><p>To obtain realistic energy profiles for PMs, we did experiments on the French experimental testbed Grid'5000 <ref type="bibr" target="#b38">[39]</ref> on Taurus servers (12 cores, 32 GB memory and 598 GB/SCSI storage), used for PMs of FC and PD clouds, and Parasilo servers (with 16 cores, 128 GB memory and 5*600 GB HDD + 200 GB SSD/SAS storage) for PMs of FD and FD-CC clouds. We used stress benchmark to get the consumption values per loaded core (P cores x,j</p><p>). The Grid'5000 testbed provides power measurements based on external wattmeters on each of the Taurus servers with one value per second and a 0.125 Watts accuracy. Table <ref type="table">VI</ref> shows the results of these measurements.</p><p>For FC architecture with a large size DC (i.e., 1000 CNs and 13 SNs) a 16-ary Fat Tree switch topology (i.e., 320 switches) is considered. As a DC of PD architecture includes 125 CNs and 3 SNs, we consider a 8-ary Fat Tree topology. In FD-CC category, a central control DC includes 3 SN-based PMs. Thus, one switch is required per DC. Regarding FD category, it does not need any intra-DC network. Concerning telecommunication network topology, as described on Figure <ref type="figure" target="#fig_6">7</ref>, motivated by <ref type="bibr" target="#b30">[31]</ref>, we consider a real telecommunication network (i.e., a simplified version of a ISP). It comprises 8 core routers, 52 backbone routers, 52 metro routers for aggregation layer and 260 feeders in access layer (i.e., totally 372 routers connected with 718 links).</p><p>For VMs, we assume each VM reserves one CPU core (i.e., small-size homogeneous VMs) and a VM, on average, utilizes 15% of its reserved CPU (u V M ). This value was measured on a real Cloud provider <ref type="bibr" target="#b33">[34]</ref>. In addition, as there is not a visible difference between utilized CPU resource of one core of Taurus and one CPU core of Parasilo, we assume all CPU cores are similar (i.e., no difference between resources of a reserved VM on Taurus and a reserved VM on Parasilo). On the other hand, finding average CPU utilization of SNs (u SN ) is a challenge due to the variety of workloads and number of active PMs. For this reason, we simply assume an average CPU utilization of 40% for SN-based PMs for our simulations.</p><p>For the energy profile of routers, we consider the measurements presented in <ref type="bibr" target="#b39">[40]</ref>: 11, 000, 4, 000, 2, 000, and 2, 000 Watts for idle power consumption (P idle r ) of Core, Backbone, Metro and Feeder routers respectively. On the other side, for the switches inside DCs, we consider a 16-ports switch (i.e., 16-ary fat tree topology): Cisco WS-C6503 switch equipped with only one 16-port WS-X6516-GE-TX line card. It consumes around 280 Watts according to the Cisco Power Calculator <ref type="bibr" target="#b40">[41]</ref>. In addition, inspired by <ref type="bibr" target="#b41">[42]</ref>, we consider that 70% of total traffic of a mega and micro DC remains inside it. Real measurements in <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b35">[36]</ref> show that there is not a visible difference between E pkt r for various routers. Therefore, we simply assume the same value of 1, 300 nJ/pkt for all types of routers and switches. Similarly, we consider E SF r =14 nJ/Byte for all network elements.</p><p>We consider a PUE value of 1.2 for all mega and micro DCs in FC and PD architectures. As a comparison, Google currently exhibits an average PUE of 1.11 on its data centers <ref type="bibr">[43]</ref>. In order to eliminate effects of different energy management techniques (i.e., controlling sleep and active modes of devices) on evaluating clouds energy consumption, we assume that all PMs and network elements are always active. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Simulation results</head><p>We consider a general scenario where 10, 000 VMs are requested by a set of end users. The VMs have been allocated and are running for all the considered time period T (1 hour). It means that 10 VMs on average are hosted per CN. Based on the proposed model, we compute the energy consumption of each architecture. The variables consist in the average traffic generated by one PM (i.e., λ: 250, 500 and 1000 Mbps) and the average packet length (L: 100, 576 and 1000 bytes). Note that the packet length varies for a given amount of traffic, thus influencing the number of packets, not the total data volume.</p><p>Figure <ref type="figure">8</ref> shows the total energy consumption of the four Cloud-related architectures. In all cases, the FD architecture outperforms the others in terms of energy consumption. In particular, for the highest traffic rate (i.e., 1, 000 Mbps), it consumes between 14% and 25% less energy than FC and PD architectures respectively. FD-CC presents performance close to FD with the considered traffic rates (with maximum 1, 000 Mbps per PM). To have a more detailed view of the results, we consider the static energy part detailed in Table VII (provided by Equation <ref type="formula" target="#formula_2">3</ref>) and the dynamic part zoomed in Figure <ref type="figure">9</ref> (given by Equation <ref type="formula" target="#formula_20">18</ref>). Table <ref type="table" target="#tab_1">VII</ref> shows that the FD infrastructure consumes less energy than others. As expected, because of variety of PMs size (and therefore energy consumption), total static energy consumption of CNs in FD and FD-CC architectures is slightly more than the FC and PD architectures. Concerning SNs static energy, because of a higher number of utilized SNs, PD and FD-CC clouds consume more energy than the FC architecture in this part. However, the total static energy consumption of SNs in the FD-CC architecture is less than the FC Cloud despite using a higher number of SNs. This is because of a lower PUE for the FD-CC architecture. For the intra-DC network, the PD architecture consumes more static energy as it uses more switches than the others. Besides, the FD architecture can noticeably save energy in this part as it does not require any switch. Concerning telecommunication network routers, it is the same for all cases. We can observe that, although one Core router consumes the most, overall, the Feeder routers' consumption greatly dominates this static energy consumption due to their number.</p><p>For the static energy consumption part, the number of intra-DCs switches plays an important role on energy consumption of a cloud-related architecture. The other influencing factors on static energy efficiency are the number of SNs, the energy efficiency of PMs, and the PUE.</p><p>Figure <ref type="figure">9</ref> shows total dynamic energy consumption of the four architectures. While packet length does not play an important role on dynamic energy consumption in a low traffic (i.e., λ=250 Mbps), its effect at higher rates (i.e., 500 and 1000 Mbps) is noticeable. Figure <ref type="figure">9</ref> also indicates that the FD architecture consumes less dynamic energy than others mostly because of the absence of intra-DC network.</p><p>As FD-CC and FD architectures use more energyconsuming CNs, their dynamic energy consumption due to PMs is higher than the others. Besides, FD-CC architecture uses the highest number of SN nodes, and consequently consumes more energy than others. Concerning dynamic energy consumption of switches, it is null for the FD infrastructure. FD-CC cloud consumes less energy than FC and PD architectures since FD-CC only needs few switches to connect its SNs. Although, in general, there is a negligible difference between results of FC and PD architectures, PD slightly outperforms FC when increasing traffic. It is due to longer paths between PMs in larger size data centers.</p><p>Concerning dynamic energy consumption of routers, there is a direct relation between locations of DCs and traffic's impact on energy consumption. Although FD exhibits a slightly lower dynamic energy consumption for routers than FD-CC, a larger difference between them should be expected for applications with heavy traffic exchange between controllers (SNs) and CNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Discussion</head><p>In this part, we summarize the key findings. Telecommunication network: as we consider the entire consumption of the network between DCs and end users, its energy consumption heavily dominates the total consumption. This is consistent with literature stating that telecommunication networks constitute the predominant part (37% in 2014) in the overall ICT consumption including end-user devices <ref type="bibr" target="#b42">[44]</ref>. Future distributed Cloud architectures could reduce the need for network routers in keeping traffic as local as possible.</p><p>Packet length: the results show that packet length, in heavy traffic rate, has an important effect on dynamic energy consumption of all architectures.</p><p>PUE: PUE greatly impacts the energy consumption of the architectures with medium and large-size DCs. Gains on the energy efficiency of ICT devices can be wiped out by a high PUE. Energy consumption of intra-DC network: in FC and PD architectures, the intra-DC switches can consume more than 50% of total DC energy and even up to 20% of the total infrastructure energy. Selecting appropriate network architecture and switch size could significantly improve the energy efficiency of an infrastructure.</p><p>Overall energy consumption: FD architecture does not need intra-DC switches, nor DCs, and consequently, its PUE is equal to 1 (no need for air conditioning equipment). This makes FD and even FD-CC architectures more energy efficient than others. However, we consider here CNs with similar performance for all architectures. It may not be the case in some future Fog and edge computing infrastructures where heterogeneous end users devices are employed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>By increasing the number of Cloud-related architectures, ranging from fully centralized to completely distributed, many Cloud researchers and providers are interested to know which infrastructure can be more energy efficient. This paper tackled this issue.</p><p>First, a taxonomy has been proposed to categorize Cloudrelated architectures and to detect main topological differences between them. Inspired by this taxonomy, a comprehensive, easy-to-use and scalable energy model has been then proposed. The model accurately highlights architectural differences between the infrastructures in terms of energy consumption.</p><p>Four different Cloud-related architectures (i.e., FC, PD, FD-CC and FD) have been analyzed using the energy model. The results showed that a completely distributed architecture (FD) consumes between 14% and 25% less energy than fully centralized (FC) and partly distributed (PD) architectures respectively. Through the utilization of the Power Usage Effectiveness (PUE) metric, the proposed model captures the impact of cooling systems, that are currently non-negligible in terms of energy consumption.</p><p>As a result of this analysis, future work on greening emerging cloud architectures should focus on improving their telecommunication network use, the efficiency of their computing infrastructures (i.e., PUE) and exploiting heterogeneous infrastructures to better fit the users' needs.</p><p>Although the model considers many important technical points, several improvements can be considered as future work. For example, the model currently assumes an even distribution of end users. But, in real environments, end users can be unevenly distributed. We also plan to extend the model to support other technologies (containers, VNFs) and architectures (heterogeneous telecommunication networks, mobile networks).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>This work is supported by the Inria Project Lab program-DISCOVERY project (see http://beyondtheclouds.github.io). Experiments presented in this paper were partly carried out using the Grid 5000 testbed, supported by a scientific interest group hosted by Inria and including CNRS, RENATER and several Universities as well as other organizations (see https://www.grid5000.fr).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Considered architectures; ranging from fully centralized (FC) to fully distributed (FD).</figDesc><graphic coords="4,80.04,56.72,451.91,237.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2 presents a comprehensive overview of ICT equipment of all Cloud-related architectures. Any architecture includes two main parts: DC(s) and telecommunication network, that are described hereafter.</figDesc><graphic coords="4,311.97,569.40,251.06,111.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. ICT equipment composing the different architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. General view of the proposed energy model and the equations used in the following to express the different parts.</figDesc><graphic coords="5,311.97,550.31,251.05,167.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Model for dynamic energy consumption of a CN-based PM</figDesc><graphic coords="7,311.97,223.46,251.06,77.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Traffic model overview from the DCs point of view</figDesc><graphic coords="8,111.72,118.20,125.53,86.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Telecommunication network structure (Figure from [31])</figDesc><graphic coords="9,92.90,365.40,163.19,169.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .Fig. 9 .</head><label>89</label><figDesc>Fig. 8. Total energy consumption of different architectures for 1 hour</figDesc><graphic coords="12,74.67,56.72,462.67,179.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II LIST</head><label>II</label><figDesc>OF INPUTS FOR THE ENERGY MODEL DCs DC = {DC 1 , . . . , DC N } with N depending on the considered architecture pm i number of PMs in DC i with i ∈ {1, . . . , N } P U E i PUE of DC i CN i set of CNs located on DC i SN iset of SNs located on DC i (for FD architecture, SN i = ∅) P idle x power consumption of PM x belonging to DC i in idle mode (in Watts) where x ∈ {CN i SN i } ) Interfaces of switches are bi-directional, and capacities of uplink and downlink are similar. If there is no traffic in one direction, the entire interface is still active.</figDesc><table><row><cell></cell><cell></cell><cell>General Inputs</cell></row><row><cell>U</cell><cell cols="2">number of end users</cell></row><row><cell>V</cell><cell cols="2">number of VMs</cell></row><row><cell>T</cell><cell cols="2">considered time period (in s)</cell></row><row><cell></cell><cell></cell><cell>Compute Inputs</cell></row><row><cell cols="3">DC set of the N P cores dynamic power consumption of PM x when j of its k x,j cores are fully loaded (in Watts) with j ∈ {0, . . . , k} and</cell></row><row><cell></cell><cell>P cores x,0</cell><cell>= 0</cell></row><row><cell>u SN</cell><cell cols="2">average CPU utilization ratio per SN for service and storage</cell></row><row><cell></cell><cell cols="2">functions</cell></row><row><cell>u V M</cell><cell cols="2">average CPU utilization ratio per VM on CNs</cell></row><row><cell>u H</cell><cell cols="2">average CPU utilization ratio per PM for the hypervisor and</cell></row><row><cell></cell><cell cols="2">monitoring processes on CNs</cell></row><row><cell></cell><cell></cell><cell>Network Inputs</cell></row><row><cell>L</cell><cell cols="2">average length of a packet on the intra-DC networks and the</cell></row><row><cell></cell><cell cols="2">telecommunication network (in Bytes)</cell></row><row><cell>λ</cell><cell cols="2">average traffic rate generated by a PM belonging to a DC (in</cell></row><row><cell></cell><cell>bps)</cell></row><row><cell>q</cell><cell cols="2">average ratio of packets sent by a PM to end users</cell></row><row><cell>µ</cell><cell cols="2">average traffic rate generated by a user to DCs (in bps)</cell></row><row><cell>λ E pkt switch</cell><cell cols="2">dynamic energy consumption of a switch to process a packet (in Joules)</cell></row><row><cell>E S&amp;F switch</cell><cell cols="2">dynamic energy consumption of a switch to store and forward a Byte (in Joules)</cell></row><row><cell>RT</cell><cell cols="2">set of routers of the telecommunication network between</cell></row><row><cell></cell><cell cols="2">DCs, and between DCs and end users</cell></row><row><cell>n X</cell><cell cols="2">number of routers of category X in the telecommunication</cell></row><row><cell></cell><cell cols="2">network with X ∈ {C, B, M, F } where C, B, M and</cell></row><row><cell></cell><cell cols="2">F stands respectively for core, backbone, metro and feeder</cell></row><row><cell></cell><cell>routers</cell></row><row><cell>P idle r E pkt r X</cell><cell cols="2">power consumption in idle mode of router r with r ∈ RT dynamic energy consumption of a router to process a packet (in Joules) with X ∈ {C, B, M, F }</cell></row><row><cell>E SF r X</cell><cell cols="2">dynamic energy consumption of a router to store and forward a Byte (in Joules) with X ∈ {C, B, M, F }</cell></row><row><cell cols="3">Before presenting the static and dynamic parts of the energy</cell></row><row><cell cols="3">model, we introduce technical assumptions, that simplify the</cell></row><row><cell cols="3">model without loss of generality:</cell></row><row><cell cols="3">1) VMs are homogeneous in size (CPU and RAM). Model-</cell></row><row><cell cols="3">ing heterogeneous VMs can be done by assuming that a</cell></row><row><cell cols="3">large size VM includes a set of small-size VMs (i.e., a</cell></row><row><cell cols="3">set of the basic unit of resources).</cell></row><row><cell cols="3">2) All V VMs are running during the entire time period T .</cell></row><row><cell cols="3">3) For each architecture, VMs are uniformly distributed on</cell></row></table><note><p>SN average traffic rate from a CN to SNs in FD-CC architecture (in bps) N E i set of switches belonging to DC i with n ports each P idle c power consumption of switch c belonging to DC i in idle mode (in Watts) where c ∈ N E i all active CN-based PMs. This assumption is considered to simplify design and utilization of the model. It can be relaxed by providing a scheduling algorithm specifying the number of VMs on each CN and the traffic exchanged with other VMs. 4) The intra-DC network has a fat tree topology, and the telecommunication network follows a hierarchical topol-ogy as previously discussed. 5</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III USER</head><label>III</label><figDesc>-TO-DC AND DC-TO-DC PATHS IN A PD CLOUD; F: FEEDER, M: METRO, B: BACKBONE AND C: CORE ROUTERS</figDesc><table><row><cell cols="2">User-DC paths Probability</cell><cell>DC-DC paths Probability</cell></row><row><cell>FM</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV USER</head><label>IV</label><figDesc>-DC AND DC-DC PATHS IN A FD CLOUD; F: FEEDER, M: METRO,</figDesc><table /><note><p>B: BACKBONE AND C: CORE ROUTERS User-DC paths Probability DC-DC paths Probability F 1</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">United States Data Center Energy Usage Report</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shehabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Horner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Koomey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Masanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sartor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Herrlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lintner</surname></persName>
		</author>
		<idno>LBNL-1005775</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
			<pubPlace>Berkeley, California</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Lawrence Berkeley National Laboratory</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fog Computing: A Taxonomy, Survey and Future Directions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mahmud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kotagiri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Internet of Everything, Internet of Things (Technology, Communications and Computing</title>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">Di</forename><surname>Martino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Esposito</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Comprehensive Survey on Fog Computing: State-of-the-art and Research Challenges</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mouradian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Naboulsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yangui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Glitho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Morrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Polakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys and Tutorials</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Mobile-Edge Computing -Introductory Technical White Paper</title>
		<author>
			<persName><surname>Etsi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>ETSI White paper</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On Multi-Access Edge Computing: A Survey of the Emerging 5G Network Edge Cloud Architecture and Orchestration</title>
		<author>
			<persName><forename type="first">T</forename><surname>Taleb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Samdanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Flinck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sabella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1657" to="1681" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Survey on Mobile Edge Computing: The Communication Perspective</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Letaief</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2322" to="2358" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Edge Computing: Vision and Challenges</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="637" to="646" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fog computing and its role in the internet of things</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bonomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Milito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Addepalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MCC workshop on Mobile cloud computing</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="13" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<ptr target="https://www.openfogconsortium.org" />
		<title level="m">The OpenFog Consortium</title>
		<imprint>
			<date type="published" when="2018-12">December 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Survey on fog computing: architecture, key technologies, applications and open issues</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dhelim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="27" to="42" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Open Glossary of Edge Computing</title>
		<ptr target="https://github.com/State-of-the-Edge/glossary" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
		<respStmt>
			<orgName>The Linux Foundation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cloud Computing Simulators: A Detailed Survey and Future Direction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Saumya</forename><surname>Sabyasachi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Advance Computing Conference</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Simulation Tools for Cloud Computing: A Survey and Comparative Study</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fakhfakh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Hadj</forename><surname>Kacem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hadj</surname></persName>
		</author>
		<author>
			<persName><surname>Kacem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer and Information Science</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">CloudSim: A Toolkit for Modeling and Simulation of Cloud Computing Environments and Evaluation of Resource Provisioning Algorithms</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Calheiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beloglazov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A F</forename><surname>De Rose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software: Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="23" to="50" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">DynamicCloudSim: Simulating heterogeneity in computational clouds</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Leser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="85" to="99" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">FTCloudSim: support for cloud service reliability enhancement simulation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Web and Grid Services</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="347" to="361" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">DartCSim+: Enhanced CloudSim with the Power and Network Models Integrated</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Cloud Computing (CLOUD)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">iCanCloud: A Flexible and Scalable Cloud Infrastructure Simulator</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vzquez-Poletti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Caminero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Casta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carretero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Llorente</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Grid Computing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="185" to="209" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">CloudNetSim++: A GUI Based Framework for Modeling and Simulation of Data Centers in OMNeT++</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bilal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aziz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kliazovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">U</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Services Computing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="506" to="519" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">SimGrid VM: Virtual Machine Support for a Simulation Framework of Distributed Systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hirofuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lebre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pouilloux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cloud Computing</title>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Predicting the Energy Consumption of MPI Applications at Scale Using a Single Node</title>
		<author>
			<persName><forename type="first">C</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cornebize</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Degomme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Legrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Carpen-Amarie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hunold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-C</forename><surname>Orgerie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Quinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Cluster</title>
		<imprint>
			<biblScope unit="page" from="92" to="102" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fog Computing May Help to Save Energy in Cloud Computing</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jalali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ayre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Alpcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. on Selected Areas in Communications</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1728" to="1739" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">End-to-end Energy Models for Edge Cloud-based IoT Platforms: Application to Data Stream Analysis in IoT</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-C</forename><surname>Orgerie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rodero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Amersho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Menaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Performance and Energy Efficiency Metrics for Communication Systems of Cloud Computing Data Centers</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fiandrino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kliazovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bouvry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Zomaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cloud Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An energy-aware service composition algorithm for multiple cloud-based IoT applications</title>
		<author>
			<persName><forename type="first">T</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Asim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tawfik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Aldawsari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Network and Computer Applications</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="96" to="108" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">End-to-end energy models for Edge Cloud-based IoT platforms: Application to data stream analysis in IoT</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-C</forename><surname>Orgerie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rodero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lemma Amersho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Parashar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Menaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="667" to="678" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<idno>ISO/IEC 30134-2:2016</idno>
		<title level="m">Information technology -Data centres -Key performance indicators -Part 2: Power usage effectiveness (PUE)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The features, hardware, and architectures of data center networks: A survey</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="45" to="74" />
			<date type="published" when="2016">2016</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Cisco&apos;s Massively Scalable Data Center: Network Fabric for Warehouse Scale Computer</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Cisco Systems, Inc</publisher>
		</imprint>
		<respStmt>
			<orgName>Cisco</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Rethinking the Data Center Networking: Architecture, Network Protocols, and Resource Sharing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hamdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1481" to="1496" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Energy-aware Backbone Networks: a Case Study</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chiaraviglio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mellia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Neri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Green Communications</title>
		<meeting><address><addrLine>GreenComm</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">How much does a VM cost? Energy-proportional Accounting in VM-based Environments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kurpicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-C</forename><surname>Orgerie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sobe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Europicro PDP</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="651" to="658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Modeling Energy Consumption in high-capacity routers and switches</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W A</forename><surname>Ayre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on selected areas in communication</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1524" to="1532" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Opportunistic Scheduling in Clouds Partially Powered by Green Energy</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-C</forename><surname>Orgerie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Menaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GreenCom: IEEE Int. Conf. on Green Computing and Communications</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="448" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<ptr target="https://docs.openstack.org/mitaka/config-reference/compute/scheduler.html" />
		<title level="m">OpenStack Configuration Reference</title>
		<imprint>
			<date type="published" when="2018-05">May 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Profiling perpacket and per-byte energy consumption in the NetFPGA Gigabit router</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sivaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INFOCOM Workshops</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="331" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Simulation toolbox for studying energy consumption in wired networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Orgerie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Amersho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Haudebourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Quinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Pacheco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lefèvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Network and Service Management</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A comparative analysis of data center network architectures</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Venkataramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Communications (ICC)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3106" to="3111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Adding Virtualization Capabilities to the Grid&apos;5000 Testbed</title>
		<author>
			<persName><forename type="first">D</forename><surname>Balouek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cloud Computing and Services Science</title>
		<title level="s">Communications in Computer and Information Science</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Ivanov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sinderen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Leymann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Shan</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="page" from="3" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Energy Consumption of Cloud Computing and Fog Computing Applications</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jalali</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<pubPlace>Australia</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Melbourne</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<ptr target="http://tools.cisco.com/cpc" />
		<title level="m">Cisco&apos;s power consumption calculator</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m">Cisco Global Cloud Index: Forecast and Methodology, 2015-2020</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">Cisco publications</note>
	<note>Cisco</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Trends in worldwide ICT electricity consumption from 2007 to 2012</title>
		<author>
			<persName><forename type="first">W</forename><surname>Van Heddeghem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lanoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Colle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pickavet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Demeester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Communications</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="64" to="76" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
