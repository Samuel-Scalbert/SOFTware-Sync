<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reproducibility and Performance: Why Choose?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ludovic</forename><surname>Court√®s</surname></persName>
						</author>
						<title level="a" type="main">Reproducibility and Performance: Why Choose?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">78FEC1DEC35A56456186840618383276</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-06T15:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Research processes often rely on high-performance computing (HPC), but HPC is often seen as antithetical to "reproducibility": one would have to choose between software that achieves high performance, and software that can be deployed in a reproducible fashion. However, by giving up on reproducibility we would give up on verifiability, a foundation of the scientific process. How can we conciliate performance and reproducibility? This article looks at two performance-critical aspects in HPC: message passing (MPI) and CPU micro-architecture tuning. Engineering work that has gone into performance portability has already proved fruitful, but some areas remain unaddressed when it comes to CPU tuning. We propose package multi-versioning, a technique developed for GNU Guix, a tool for reproducible software deployment, and show that it allows us to implement CPU tuning without compromising on reproducibility and provenance tracking.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION.</head><p>It should come as no surprise that the execution speed of programs is a primary concern in high-performance computing (HPC). Many HPC practitioners would tell you that, among their top concerns, is the performance of high-speed networks used by the Message Passing Interface (MPI) and use of the latest vectorization extensions of modern CPUs. This article focuses on the latter: tuning code for specific CPU micro-architectures, to reap the benefits of modern CPUs. This question is particularly acute in the context of GNU Guix, a software deployment tool with strong support for reproducible deployment. We like to present Guix as a key element of the reproducible research toolbox: as more research output is produced by software, the ability to verify and validate research results depends on the ability to redeploy and re-run the software. We present a recently-introduced CPU-tuning option for Guix, the design choices we made, and how this affects reproducibility.</p><p>But let us first consider this central ques-tion in the HPC and scientific community: can "reproducibility" be achieved without sacrificing performance? Our answer is a resounding "yes", but that deserves clarifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reproducibility &amp; High Performance</head><p>The author remembers advice heard at the beginning of their career in HPC-advice still given today-: that to get optimal MPI performance, you would have to use the vendor-provided MPI library; that to get your code to perform well on this new cluster, you would have to recompile the complete software stack locally; that using generic, pre-built binaries from a GNU/Linux distribution will not give you good performance.</p><p>From a software engineering viewpoint, this looks like a sad situation and an inefficient approach, dismissing the benefits of automated software deployment as pioneered by Debian, Red Hat, and others in the 90's or, more recently, as popularized with container images. It also means doing away with reproducibility, where "reproducibility" is to be understood in two dif-ferent ways: first as the ability to re-deploy the same software stack on another machine or at a different point in time, and second as the ability to verify that binaries being run match the source code-the latter is what reproducible builds are concerned with <ref type="bibr" target="#b9">[10]</ref>.</p><p>But does it really have to be this way? Engineering efforts to support performance portability suggest otherwise. A mature MPI implementation like Open MPI, today, does achieve performance portability: it takes advantage of high-speed networking hardware by determining, at run-time, which drivers to use to obtain optimal performance for the network at hand-no recompilation is needed <ref type="bibr" target="#b3">[4]</ref>.</p><p>Likewise, generic, pre-built binaries can and indeed often do take advantage of modern CPUs by selecting at run-time the most efficient implementation of performance-sensitive routines for the host CPU <ref type="bibr" target="#b2">[3]</ref>. There are cases, though, where this is not the case; these are those we will focus on in the remainder of this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Jungle of SIMD Extensions</head><p>While major CPU architectures such as x86 64, AArch64, and POWER9 were defined years ago, CPU vendors regularly extend them. Extensions that matter most in HPC are vector extensions: single instruction/multiple data (SIMD) instructions and registers. In this area, a lot has happened on x86 64 CPUs since the baseline instruction set architecture (ISA) was defined. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, Intel and AMD have been tacking ever more powerful SIMD extensions to their CPUs over the years, from SSE3 to AVX-512, leading to a wealth of CPU "microarchitectures". This gives a high-level view, but just looking at generations of Intel processors by their code name-from "Nehalem" to "Skylake" via "Ivybridge"-shows an already more complicated story.</p><p>Linear algebra routines that scientific software relies on greatly benefit from SIMD extensions. For example, on a modest Intel CORE i7 processor (of the Skylake generation), the AVX2-optimized version of the dense matrix multiplication routines of Eigen (https://eigen.tuxfamily.org), built with GCC 10. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Portable Performance Through Function Multi-Versioning</head><p>How to create binaries that are portable, yet are able to get the most out of the CPU on which they are executed? This has been an important question for distributors of binaries. Distributions such as Debian and CentOS provide the convenience of fast automated deployment, thanks to pre-built binaries; asking users to either recompile part of their software stack or give up on performance is not a reasonable alternative.</p><p>To address this and achieve performance portability, developers have largely adopted function multi-versioning (FMV): the implementation multiple versions of "hot" routines, one for each relevant CPU micro-architecture, and picks the best one for the host CPU at run time. Many pieces of performance-critical software already use this technique: the C standard library (libc) contains multiple versions of its string handling and math routines, the GMP library for multi-precision arithmetic uses FMV, and so do software packages ranging from cryptography libraries (Libgcrypt, Nettle) to linear algebra (OpenBLAS, FFTW).</p><p>To make it easier for developers to adopt FMV, the GNU compilation tool chain (GCC, the Binary Utilities, and the C Library), which is widely used in HPC, provides helpers at different levels. Developers can annotate relevant functions with the target clone attribute to instruct the compiler to generate optimized versions of the function for each selected architecture. GCC not only generates these versions, but also generates code to choose the right function version for the host CPU at load time, with support from the dynamic linker, ld.so. That relieves developers from the need to implement their own ad-hoc machinery. From that perspective, it would seem that performance portability, via FMV, is a solved problem.</p><p>There is at least one common pattern though where FMV is not applicable, or at least is not applied: C++ header-only libraries. These are libraries that provide generic template code in header files; that code is specialized at build time in software that uses them. There is no shortage of C++ header-only math libraries providing efficient, optimized SIMD versions of their routines: Eigen, MIPP, xsimd and xtensor, SIMD Everywhere (SIMDe), Highway, and many more. All these, except Highway, have in common that they do not support FMV. Since they "just" headers, it is up to each package using them to figure out what to do in terms of performance portability.</p><p>In practice though, software using these C++ header-only libraries rarely makes provisions for performance portability. Thus, when compiling those packages for the baseline ISA, one misses out on all the vectorized implementations that libraries like Eigen provide. This is a known issue in search of a solution-see https://gitlab.com/libeigen/eigen/-/issues/2344. It can have a very concrete impact on performance since many scientific packages-the ARPACK-NG library for solving eigenvalue problems, the Ceres solver for optimization problems, the FEn-iCSx platform for solving differential equations, to name a few-depend on Eigen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reproducible Deployment</head><p>Distributions such as Debian and Fedora that provide pre-built binaries miss out on SIMD optimizations of C++ header-only libraries like Eigen because they provide binaries targeting the baseline CPU architecture so that those binaries run on any CPU. The Spack <ref type="bibr" target="#b6">[7]</ref> and EasyBuild <ref type="bibr" target="#b7">[8]</ref> package managers address that by rebuilding software on the target computer, which allows them to instruct the compiler to optimize for the host CPU.</p><p>Unfortunately, EasyBuild and Spack both have limited support for reproducible deployment-they do not, in general, guarantee that you can redeploy the same software environment on different machines, or at different points in time. This is because they build upon software provided by the host system-the compiler tool chain, "system" libraries, etc.-and that foundation differs from one system to another-e.g., CentOS might provide some version of GCC, and Ubuntu might provide another.</p><p>To avoid that, Guix builds software in isolated environments, as pioneered by Nix <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6]</ref>, and its package collection is self-contained-it does not rely on external software packages. This is what makes Guix builds reproducible bit-for-bit-or in other words, verifiable <ref type="bibr" target="#b9">[10]</ref>. Given binaries and provenance data, anyone can independently verify the binary/source-code correspondence.</p><p>Guix provides a command-line interface similar to that of other package managers: guix install python, for instance, installs the Python interpreter. Package management is peruser rather than system-wide and does not require system administrator privileges, which makes it suitable for multi-user HPC clusters <ref type="bibr" target="#b1">[2]</ref>. To offer the level of flexibility that HPC users expect, Guix lets users customize packages via package transformation options on the command line-for instance to swap two packages in the dependency graph-or through programming interfaces <ref type="bibr" target="#b1">[2]</ref>.</p><p>Quite uniquely, Guix supports "time traveling": with guix time-machine, users can run a specific revision of Guix and use it to deploy packages as they were defined in that revision. The typical use case is redeploying software that was used to produce computational results for a scientific publication <ref type="bibr">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11]</ref>. The command below deploys Python, NumPy, and their dependencies as they were defined in a Guix revision from October 2021:</p><formula xml:id="formula_0">guix time-machine --commit=b0735c79b0d1d341 --\ shell python python-numpy</formula><p>Whether you run it today or two years from now, it will deploy the exact same binaries, bitfor-bit, down to the C library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Package Multi-Versioning</head><p>With our packaging hammer, one could envision a solution to these CPU tuning problems: if we cannot do function multi-versioning, what about implementing package multi-versioning? Guix makes it easy to define package variants, so we can define package variants optimized for a specific CPU-compiled with -march=skylake, for instance. What we need is to define those variants "on the fly".</p><p>The recently-introduced --tune package transformation option works along those lines. Users can pass --tune to any of the commandline tools (guix install, guix shell, etc.) and that causes "tunable" packages to be optimized for the host CPU. For example, here is how you would run Eigen's matrix multiplication benchmark from the eigen-benchmarks package micro-architecture tuning:</p><p>$ guix shell --tune eigen-benchmarks --\ benchBlasGemm 240 240 240 guix shell: tuning for CPU skylake 240 x 240 x 240 cblas: 0.208547 (15.908 GFlops/s) eigen : 0.0720303 (46.06 GFlops/s) l1: 32768 l2: 262144 --tune determines the name of the host CPU as recognized by GCC's (and Clang's) -march option. Users can override auto-detection by passing a CPU name-e.g., --tune=skylake--avx512. As mentioned earlier, we made the conscious choice of letting --tune affect solely software that packagers explicitly marked as "tunable". This ensures Guix does not end up rebuilding packages that could not possibly benefit from micro-architecture-specific optimizations, which would be a waste of resources.</p><p>This implementation of package multiversioning does not sacrifice reproducibility. When --tune is used, from Guix's viewpoint, it is just an alternate, but well-defined dependency graph that gets built. Guix records package transformation options that were used so it can "replay" them. For example, one can export a manifest representing packages that have been deployed:</p><p>$ guix shell eigen-benchmarks --tune guix shell: tuning for CPU skylake [env]$ guix package --export-manifest \ -p $GUIX ENVIRONMENT (use-modules (guix transformations)) (define transform1 (options-&gt;transformation '((tune . "skylake"))))</p><p>(packages-&gt;manifest (list (transform1 (specification-&gt;package "eigen-benchmarks"))))</p><p>The manifest above is a code snippet that can be passed to guix shell or guix package to redeploy the package with the same tuning parameters. Like other transformation options, --tune is accepted by all the commands; for example, here is how you would build a Docker image tuned for a particular CPU: guix pack -f docker -S /bin=bin eigen-benchmarks --tune=skylake</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion and Outlook</head><p>We implemented what we call "package multi-versioning" for C/C++ software that lacks function multi-versioning and run-time dispatch, a notable example of which is optimized C++ header-only libraries. It is another way to ensure that users do not have to trade reproducibility for performance.</p><p>The scientific programming landscape has been evolving over the last few years. It is encouraging to see that Julia offers function multiversioning for its "system image", and that, similarly, Rust supports it with annotations similar to GCC's target clones. Hopefully these new development environments will support performance portability well enough that users and packagers will not need to worry about it.</p><p>But first and foremost, it is up to us, research software engineers and scientists, to dispel the myth that performance is a valid excuse for nonreproducible computational workflows.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Timeline of x86 64 SIMD extensions</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Published by the IEEE Computer Society ¬© IEEE</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Functional Package Management with Guix</title>
		<author>
			<persName><forename type="first">L</forename><surname>Court√®s</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Lisp Symposium</title>
		<imprint>
			<date type="published" when="2013-06">June 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reproducible and User-Controlled Software Environments in HPC with Guix</title>
		<author>
			<persName><forename type="first">L</forename><surname>Court√®s</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wurmus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Euro-Par 2015: Parallel Processing Workshops</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2015-08">August 2015</date>
			<biblScope unit="page" from="579" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Pre-Built Binaries vs</title>
		<author>
			<persName><forename type="first">L</forename><surname>Court√®s</surname></persName>
		</author>
		<ptr target="https://hpc.guix.info/blog/2018/01/pre-built-binaries-vs-performance/" />
		<imprint>
			<date type="published" when="2018-01">January 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Performance</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Optimized and Portable Open MPI Packaging</title>
		<author>
			<persName><forename type="first">L</forename><surname>Court√®s</surname></persName>
		</author>
		<ptr target="https://hpc.guix.info/blog/2019/12/optimized-and-portable-open-mpi-packaging/" />
		<imprint>
			<date type="published" when="2019-12">December 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Storage Tradeoffs in a Collaborative Backup Service for Mobile Devices</title>
		<author>
			<persName><forename type="first">L</forename><surname>Court√®s</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ReScience C</title>
		<imprint>
			<date type="published" when="2020-06">June 2020</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Nix: A Safe and Policy-Free System for Software Deployment</title>
		<author>
			<persName><forename type="first">E</forename><surname>Dolstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Jonge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Visser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Large Installation System Administration Conference (LISA &apos;04)</title>
		<meeting>the 18th Large Installation System Administration Conference (LISA &apos;04)</meeting>
		<imprint>
			<publisher>USENIX</publisher>
			<date type="published" when="2004-11">November 2004</date>
			<biblScope unit="page" from="79" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Spack Package Manager: Bringing Order to HPC Software Chaos</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Legendre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Collette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R D</forename><surname>Supinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;15</title>
		<meeting>the International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;15</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Modern Scientific Software Management Using EasyBuild and Lmod</title>
		<author>
			<persName><forename type="first">M</forename><surname>Geimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mclay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on HPC User Support Tools (HUST&apos;14)</title>
		<meeting>the First Workshop on HPC User Support Tools (HUST&apos;14)</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="41" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Staged Computation: The Technique You Did Not Know You Were Using</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hinsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="99" to="103" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reproducible Builds: Increasing the Integrity of Software Supply Chains</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zacchiroli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Software</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="62" to="70" />
			<date type="published" when="2022-03">March 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Challenge to Scientists: Does Your Ten-Year-Old Code Still Run?</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Perkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">584</biblScope>
			<biblScope unit="page" from="656" to="658" />
			<date type="published" when="2020-08">August 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Court √®s is a research software engineer at Inria</title>
		<author>
			<persName><surname>Ludovic</surname></persName>
		</author>
		<imprint>
			<pubPlace>France</pubPlace>
		</imprint>
	</monogr>
	<note>He has been contributing to the development of GNU Guix since its inception in 2012 and works on its use in support of reproducible research workflows. He holds a PhD in computer science from LAAS-CNRS. You can reach him at ludovic.courtes@inria.fr</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
