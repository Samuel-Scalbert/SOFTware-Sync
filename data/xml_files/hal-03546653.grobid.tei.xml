<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Intelligent Traffic Management in Next-Generation Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-01-28">28 January 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ons</forename><surname>Aouedi</surname></persName>
							<email>ons.aouedi@ls2n.fr</email>
							<idno type="ORCID">0000-0002-2343-0850</idno>
							<affiliation key="aff0">
								<orgName type="laboratory">LS2N-Laboratoire des Sciences du Numérique de Nantes</orgName>
								<orgName type="institution">Université de Nantes</orgName>
								<address>
									<postCode>44000</postCode>
									<settlement>Nantes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kandaraj</forename><surname>Piamrat</surname></persName>
							<email>kandaraj.piamrat@ls2n.fr</email>
							<idno type="ORCID">0000-0002-2343-0850</idno>
							<affiliation key="aff0">
								<orgName type="laboratory">LS2N-Laboratoire des Sciences du Numérique de Nantes</orgName>
								<orgName type="institution">Université de Nantes</orgName>
								<address>
									<postCode>44000</postCode>
									<settlement>Nantes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Benoît</forename><surname>Parrein</surname></persName>
							<email>benoit.parrein@ls2n.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LS2N-Laboratoire des Sciences du Numérique de Nantes</orgName>
								<orgName type="institution">Université de Nantes</orgName>
								<address>
									<postCode>44000</postCode>
									<settlement>Nantes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Intelligent Traffic Management in Next-Generation Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-01-28">28 January 2022</date>
						</imprint>
					</monogr>
					<idno type="MD5">D7A5A45FFBA439A7CFC823282E3E0C30</idno>
					<idno type="DOI">10.3390/fi14020044</idno>
					<note type="submission">Received: 31 December 2021 Accepted: 21 January 2022</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-07T09:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>machine learning</term>
					<term>deep learning</term>
					<term>networking</term>
					<term>software-defined networking</term>
					<term>resource management</term>
					<term>feature selection</term>
					<term>feature extraction</term>
					<term>deep neural network</term>
					<term>network traffic</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The recent development of smart devices has lead to an explosion in data generation and heterogeneity. Hence, current networks should evolve to become more intelligent, efficient, and most importantly, scalable in order to deal with the evolution of network traffic. In recent years, network softwarization has drawn significant attention from both industry and academia, as it is essential for the flexible control of networks. At the same time, machine learning (ML) and especially deep learning (DL) methods have also been deployed to solve complex problems without explicit programming. These methods can model and learn network traffic behavior using training data/environments. The research community has advocated the application of ML/DL in softwarized environments for network traffic management, including traffic classification, prediction, and anomaly detection. In this paper, we survey the state of the art on these topics. We start by presenting a comprehensive background beginning from conventional ML algorithms and DL and follow this with a focus on different dimensionality reduction techniques. Afterward, we present the study of ML/DL applications in sofwarized environments. Finally, we highlight the issues and challenges that should be considered.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>According to the latest Cisco forecast, by 2022, the number of devices connected to mobile networks will largely exceed the world's population, reaching 12.3 billion <ref type="bibr" target="#b0">[1]</ref>. This huge number of smart devices has made the Internet widely used and has, accordingly, triggered a surge in traffic and applications. This, in turn, has made network architecture highly resource-hungry and can create significant challenges for network operators. Therefore, it is not possible for network administrators to manage the network manually by processing a large amount of data accurately in a reasonable response time <ref type="bibr" target="#b1">[2]</ref>. Consequently, this requires ultra-efficient, fast, and autonomous resource management approaches. In this context, machine learning (ML) offers these benefits, since it can find a useful pattern from data in a reasonable period of time and eventually allows the network operator to analyze the traffic and gain knowledge out of it. Network traffic analysis includes network traffic classification, network traffic prediction using time-series data, and intrusion detection systems. Understanding network behavior can improve performance, security, quality of service (QoS) and help avoid violation of SLA (service-level agreements). For example, load traffic prediction plays an important role in network management, such as short-and long-term resource allocation (e.g., bandwidth), anomaly detection, and traffic routing.</p><p>To achieve the intelligent management of networks and services in the softwaredefined networking (SDN) environment, ML methods can be used. A centralized SDN controller has a global network view which facilitates the collection of the network traffic. Several researchers argue that, with the introduction of SDN, there is a high potential for collecting data from forwarding devices, which need to be handled by ML due to their complexity <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. Mestres et al. <ref type="bibr" target="#b2">[3]</ref> presented a new paradigm that combines ML and SDN which is called knowledge-defined networking (KDN). This architecture consists of knowledge, controller, and data planes in order to produce an automatic and intelligent process of network control. The adoption of ML with SDN for network management is an interesting area that requires further exploration (i.e., network slicing, traffic prediction). In addition, the availability of low-cost storage from the Cloud, edge computing, and the computer's evolution provide the high processing capabilities needed for training/testing ML and DL algorithms. Therefore, the combination of machine learning with SDN creates high-quality evidence in network traffic management. In this context, we provide a thorough overview of the research works in this area to gain deep insight into the significant role of ML/DL algorithms in the SDN environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Related Work</head><p>Driven by the recent advances in ML/DL in network traffic management, many studies have been conducted to survey the works on this domain. For example, Xie et al. <ref type="bibr" target="#b3">[4]</ref> have provided a comprehensive survey of ML techniques applied to SDN. Different types of ML/DL algorithms and their applications in the SDN environment are presented. Nevertheless, they did not review the traffic prediction application. Additionally, the paper lacks several recent approaches as well as a dataset in the literature review.</p><p>Latah and Toker <ref type="bibr" target="#b4">[5]</ref> briefly reviewed the application of AI with SDN. Then, in <ref type="bibr" target="#b5">[6]</ref>, they presented an extensive overview of AI techniques that have been used in the context of SDN. Additionally, Zhao et al. <ref type="bibr" target="#b6">[7]</ref> surveyed ML/DL algorithms and their applications in the SDN environment. However, these papers categorized the reviewed contribution based on the ML model (e.g., supervised, unsupervised) and not by the use case.</p><p>A review on the approaches of traffic classification in software-defined wireless sensor networks (SDWSN) using ML has been presented in <ref type="bibr" target="#b7">[8]</ref>. Mohammed et al. <ref type="bibr" target="#b8">[9]</ref> briefly surveyed traffic classification and traffic prediction using ML in SDN. Moreover, Boutaba et al. <ref type="bibr" target="#b9">[10]</ref> proposed a survey of the ML-based methods applied to fundamental problems in networking. In addition, a survey of SDN-based network intrusion detection systems using ML/DL approaches is presented in <ref type="bibr" target="#b10">[11]</ref>. Nguyen et al. <ref type="bibr" target="#b11">[12]</ref> proposed a survey on different security challenges related to the application of ML/DL in an SDN environment. As the main difference, these papers did not cover all the network traffic management applications in one paper. Furthermore, the research challenges in our paper are significantly different than those papers.</p><p>Table <ref type="table">1</ref> summarizes existing survey articles with similar topics as ours. We categorize these papers into (i) overviews of deep learning, (ii) overviews of other machine learning algorithms, (iii) reviews of dimensionality reduction methods, and (iv) reviews of works at the intersection between DL/ML and SDN. The previous surveys have focused on ML/DL approaches in the SDN environment. However, they did not cover the traffic analysis applications like traffic classification, prediction, and anomaly detection. Additionally, they are lacking some new approaches. such as federated learning. In addition, while DL has the ability to learn features automatically, conventional ML algorithms try to extract knowledge from a set of features or attributes, but they do not have the capability to extract these features automatically. Therefore, choosing the appropriate features to be used with ML models is a predominant challenge. In this context, one important objective of this paper is to provide an overview ranging from dimensionality reduction and machine learning techniques to deep learning used in the SDN environment. Then, we explore the network traffic management/analysis that has benefited from ML/DL algorithms and SDN architecture.</p><p>Table <ref type="table">1</ref>. Summary of existing surveys related to ML/DL, dimensionality reduction (DR), and SDN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ref. Topic</head><p>Scope DL Other ML Models DR SDN <ref type="bibr" target="#b12">[13]</ref> A survey of deep learning and its applications. <ref type="bibr" target="#b10">[11]</ref> A brief survey of SDN-based network intrusion detection system using machine and deep learning approaches.</p><p>[14] A tutorial on deep learning. <ref type="bibr" target="#b5">[6]</ref> An overview of AI techniques in the context of SDN.</p><p>[4] A survey of ML/DL applications in SDN. <ref type="bibr" target="#b14">[15]</ref> A brief survey of feature selection/extraction methods. <ref type="bibr" target="#b15">[16]</ref> A survey of the procedure of feature selection and its application. <ref type="bibr" target="#b16">[17]</ref> A survey of the software-defined wireless sensor networks.</p><p>[10] A survey of the ML-based model applied to fundamental problems in networking</p><p>Our paper A survey of DR, ML and DL in the SDN environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Contributions</head><p>This paper is intended for researchers and developers who want to build intelligent traffic management as well as learning solutions in the SDN realm using the emerging ML/DL approaches. This paper discusses the role of the dimensionality reduction technique for conventional ML models as well as DL algorithms in SDN and how these concepts improve network traffic management. We cannot claim to have looked at each and every work under this combination (SDN and ML/DL), but we have covered the major approaches presented in the literature. In brief, the contributions of this survey can be summarized as follows:</p><p>•</p><p>We provide a comprehensive view of the state-of-the-art machine/deep learning algorithms used in the SDN; •</p><p>We present the benefits of feature selection/extraction with conventional ML algorithms; • We review the approaches and technologies for deploying DL/ML on SDN ranging from traffic classification to traffic prediction and intrusion detection systems; •</p><p>We highlight the problems and challenges encountered when using DL/ML.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Paper Organization</head><p>As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, the rest of this paper is organized as follows. In Section 2, we present the main ML and DL-based models that have been used in the SDN environment and their strengths/weaknesses. Then, we present a comparison and summary table for the reviewed ML/DL algorithms. Section 2.3 presents a review of dimensionality reduction techniques, their advantages/disadvantages, and then we analyze how these techniques can be used to achieve the high performance of learning algorithms that ultimately improve the performance of the model. The main purpose of Section 3 is to provide a comprehensive survey of ML/DL applications with SDN for network traffic management/analysis. This survey also aims to highlight the list of challenges and issues of using ML/DL over SDN as presented in Section 4. Finally, Section 5 outlines the conclusions of this paper. For better comprehension, we summarize definitions of the abbreviations that will be used in this paper in Table <ref type="table" target="#tab_0">2</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Machine Learning</head><p>ML <ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref> is a branch of artificial intelligence (AI). Arthur Samuel was among the first researchers who applied machine learning to teach a computer to improve playing checkers based on training with a human counterpart in 1959. The increase in the amount of data made the ML algorithms popular in the 1990s. Nowadays, it is an emerging area that attracts the attention of academia and industry; Google, Apple, Facebook, Netflix, and Amazon are investing in ML and using it in their products <ref type="bibr" target="#b20">[21]</ref>. Its effectiveness has been validated in different application scenarios, i.e., healthcare, computer vision, autonomous driving, recommendation systems, network traffic management, etc. It addresses the question of how to build a computer system that improves automatically through experience <ref type="bibr" target="#b18">[19]</ref>. ML algorithms try to automate the process of knowledge extraction from training data to make predictions of unseen data. For example, historical traffic data are used to improve traffic classification and reduce congestion. In other words, ML models generally proceed in two phases: <ref type="bibr" target="#b0">(1)</ref> in the training process, a training set is used to construct a model; <ref type="bibr" target="#b1">(2)</ref> this model is then applied to predict or classify the unseen data. Therefore, the main idea of ML is to generalize beyond the examples in the training set and can be thought of as "programming by example". Hence, it is an intelligent method used to automatically improve performance through experience. Mitchell <ref type="bibr" target="#b19">[20]</ref> defined ML by saying, "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E".</p><p>The adoption of ML and DL approaches increased thanks to the computer's evolution, which has provided us with processing capabilities needed for training/testing their models, the availability of large datasets, and the cost-effectiveness of storage capabilities. In addition, the availability of open-source libraries and frameworks causes rapid diffusion within the research community and in our daily life. ML/DL algorithms can be implemented in various platforms and languages such as Weka (does not include DL algorithms), R, and Python. Python is one of the most popular environments for ML/DL as it provides various libraries to developers. Additionally, its simplicity helps developers to save more time, as they only require concentrating on solving the ML/DL problems rather than focusing on the technicality of language. The most commonly used tool for classical machine learning implementation is scikit-learn <ref type="bibr" target="#b21">[22]</ref>. Scikit-learn is an open-source ML library (e.g., Matplotlib, Pandas) and is not specific to DL. It covers all data mining steps from preprocessing to classification, regression, and clustering.</p><p>Within the field of machine learning, a broad distinction could be made between supervised, unsupervised, semi-supervised, and reinforcement learning (RL). The strengths and weaknesses of these learning approaches are presented in Table <ref type="table" target="#tab_1">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supervised learning</head><p>This type of learning process is the most commonly used. It operates when an object needs to be assigned into a predefined class based on several observed features related to that object <ref type="bibr" target="#b22">[23]</ref>. Therefore, supervised learning tries to find model parameters that best predict the data based on a loss function L(y, ŷ). Here, y is our output variable, and ŷ represents the output of the model obtained by feeding a data point x (input data) to the function F that represents the model. Classification and regression are examples of supervised learning: in classification, the outputs take discrete values; this is one of the most widely used methods. In regression, a learning function maps the data into a realvalue variable (the outputs are continuous values). Binary, multi-class, and multi-labeled classification are the three approaches of classification <ref type="bibr" target="#b23">[24]</ref>. In binary classification, only two possible classes, for example, classify the traffic as "attack" or "normal". Multi-class classification implies that the input can be classified into only one class within a pool of classes, such as classifying the traffic as "Chat", "Streaming", and "Game". Multi-labeled classification allows the classification of an input sample into more than one class in the pool of classes, like classifying the traffic as "Skype" and the traffic type as "Video". Classification examples include decision tree, support vector machine (SVM), and neural networks, while for regression, we have support vector regression (SVR), linear regression, and neural networks. In addition, an ensemble of different learning algorithms was developed to produce a superior accuracy than any single algorithm like random forest and boosting methods <ref type="bibr" target="#b24">[25]</ref>;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unsupervised learning</head><p>With the increasing size and complexity of data, unsupervised learning can be one promising solution. It has the ability to find a relationship between the instances without having any prior knowledge of target features. Specifically, unsupervised learning examines the similarity between the instances in order to categorize them into distinctive clusters. The instances within the same cluster have a greater similarity as compared to the instances in other clusters <ref type="bibr" target="#b25">[26]</ref>;</p><p>•</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semi-supervised learning</head><p>As the name implies, semi-supervised learning combines both supervised and unsupervised learning to get benefits from both approaches. It attempts to use unlabeled data as well as labeled data to train the model, contrary to supervised learning (data all labeled) and unsupervised learning (data all unlabeled). As labeling data (e.g., network traffic) is difficult, requires human effort, and is time-consuming to obtain, especially for traffic classification and attack detection, semi-supervised learning tries to minimize these problems, as it uses a few labeled examples with a large collection of unlabeled data <ref type="bibr" target="#b26">[27]</ref>. It is an appropriate method when large amounts of labeled data are unavailable. That is why, in the last few years, there has been a growing interest in semi-supervised learning in the scientific community, especially for traffic classification <ref type="bibr" target="#b27">[28]</ref>;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reinforcement learning (RL)</head><p>The main idea of reinforcement learning was inspired by biological learning systems. It is different from supervised and unsupervised learning; instead of trying to find a pattern or learning from a training set of labeled data, the only source of data for RL is the feedback a software agent receives from its environment after executing an action <ref type="bibr" target="#b28">[29]</ref>. That is why it is considered as a fourth machine learning approach alongside supervised, unsupervised, and semi-supervised learning. In addition, RL is defined by the provision of the training data by the environment. In other words, it is a technique that allows an agent to learn its behavior by interacting with its environment. Three important elements construct this learning approach, namely observations, reward, and action. Therefore, the software agent makes observations and executes actions within an environment, and receives rewards in return. The agent's job is to maximize cumulative reward. The most well-known reinforcement learning technique is Q-learning <ref type="bibr" target="#b29">[30]</ref>, and it is widely used for routing <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref>. Moreover, deep learning has been used to improve the performance of RL algorithms (i.e., allows reinforcement learning to be applied to larger problems). Therefore, the combination of DL and RL gives the so-called DRL. DRL began in 2013 with Google Deep Mind <ref type="bibr" target="#b32">[33]</ref>. A good survey that presents RL and DRL approaches is available in <ref type="bibr" target="#b33">[34]</ref> for more details. In Section 2.1, a synthesis of DL architecture and models is presented, followed by an overview of conventional ML models as well as feature reduction techniques. We only focus on the algorithms that have been used in the SDN environment and that are presented in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Deep Learning</head><p>Deep learning (DL), also known as deep neural networks (DNN) represents one of the most active areas of AI research <ref type="bibr" target="#b12">[13]</ref>. It is a branch of ML that evolved from neural network (NNs) which enables an algorithm to make predictions or classifications based on large datasets without being explicitly programmed. In many domains, DL algorithms are able to exceed human accuracy. Using conventional ML-based models requires some feature engineering tasks like feature selection <ref type="bibr" target="#b34">[35]</ref>, which is not the case with DL models, as these can hierarchically extract knowledge automatically from raw data by stacked layers <ref type="bibr" target="#b22">[23]</ref>.</p><p>The major benefits of DL over conventional ML models are its superior performance for large datasets <ref type="bibr" target="#b35">[36]</ref> and the integration of feature learning and model training in one architecture, as illustrated in Figure <ref type="figure" target="#fig_1">2</ref>. Therefore, it helps to avoid human intervention and time-wasting as maximum as possible. In the literature, DL has also been referred to as deep structured learning, hierarchical learning, and deep feature learning <ref type="bibr" target="#b36">[37]</ref>. This deep architecture enables DL to perform better than conventional ML algorithms; accordingly, DL can learn highly complicated patterns. It uses supervised and unsupervised learning to learn high-level features for the tasks of classification and pattern recognition. Several DL algorithms are presented in Table <ref type="table" target="#tab_2">4</ref>. The growing popularity of DL inspired several companies, and open-source initiatives have developed powerful DL libraries and frameworks that can be used to avoid building models from scratch <ref type="bibr" target="#b37">[38]</ref>. Many libraries have appeared, and we summarize the most popular ones in Table <ref type="table" target="#tab_3">5</ref>.</p><p>DL is capable of learning high-level features better than shallow neural networks. Shallow ANN contains very few hidden layers (i.e., with one hidden layer) while DL contains many more layers (deep). Each hidden layer comprises a set of learning units called neurons. These neurons are organized in successive layers, and every layer takes as input the output produced by the previous layer, except for the first layer, which consumes the input.   More specifically, the neuron receives a vector x as input and uses it to compute an output signal, which is transferred to other neurons. It is parameterized through {W, b}, where W is a weight vector, b is the bias, and f is referred to as an activation function. In modern networks, activation functions are referred to as non-linear functions. This non-linearity enables the DL model to learn complex patterns and avoid constraints associated with linear functions. The choice of activation function affects network training time <ref type="bibr" target="#b39">[40]</ref>. The most frequently used activation functions are the ReLU (rectified linear unit), sigmoid, and hyperbolic tangent functions (TanH). In fact, networks with ReLu show better convergence performance than sigmoid and tanh <ref type="bibr" target="#b39">[40]</ref>. For more details of ANN, readers can refer to the book written by Haykin <ref type="bibr" target="#b40">[41]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Conventional Machine Learning Models</head><p>Although DL-based models perform well for complex applications, there still remain several challenges. For example, the number of their hyperparameters grows exponentially with the depth of the model. Additionally, finding suitable DL architecture (i.e., number of hidden layers) and identifying optimal hyperparameters (i.e., learning rate, loss function, etc.) are difficult tasks. Furthermore, DL does not perform well when the data volume is small because it needs a large amount of data to find some patterns from the data. In such a context, conventional ML models (e.g., decision tree) can provide better results with a minimal fine-tuning process of the hyperparameters. In addition, compared to the conventional ML models, DL has a higher computational cost, which makes it hard to be used on machines with a simple CPU.</p><p>All this makes the conventional ML models still used. They can be broadly divided into two categories: (i) simple (i.e., single) machine models and (ii) ensemble models. The commonly used simple models include, for example, SVM, DT, and KNN, whereas ensemble models aim to combine heterogeneous or homogeneous simple models in order to obtain a model that outperforms every one of them and overcomes their limitations <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref>. The ensemble methodology imitates our nature to seek several opinions before making a decision <ref type="bibr" target="#b43">[44]</ref>. Bagging, boosting, and stacked generalization (or simply stacking) are the most popular ensemble models. Similar to single models, there are no best ensemble methods, as some ensemble methods work better than others in certain conditions (e.g., data, features). Several conventional ML methods used with SDN are presented in Table <ref type="table" target="#tab_4">6</ref>.</p><p>However, the performance of the conventional ML models depends on the amount and the quality of features. Moreover, extracting a large number of features from the coming flow in the SDN environment is time-consuming and, in turn, can decrease the QoS of the system <ref type="bibr" target="#b44">[45]</ref>. To solve these issues, effective pre-processing mechanisms can be applied to filter out the unrelated/noisy data that can reduce the dimensionality of the data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Description Strengths Weaknesses</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Decision tree (DT)</head><p>Decision tree is a tree-like structure, where every leaf (terminal) corresponds to a class label and each internal node corresponds to an attribute. The node at the top of the tree is called the root node. Tree splitting uses Gini Index or Information Gain methods <ref type="bibr" target="#b45">[46]</ref>.</p><p>Simple to understand and interpret, requires little data preparation, handles many types of data (numeric, categorical), easily processesdata with high dimension</p><p>Generates a complex tree with numeric data, requires large storage</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random forest (RF)</head><p>Random forest was developed nearly 20 years ago <ref type="bibr" target="#b46">[47]</ref> and is one of the most popular supervised machine learning algorithms that is capable to be used for regression and classification. As their name would suggest, random forests are constructed from decision trees. It uses the bagging method, which enhances the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Efficient against over-fitting</head><p>Requires a large training dataset, impractical for real-time applications Support vector machine (SVM)</p><p>SVM is a powerful classification algorithm which can be used for both regression and classification problems. However, it is mostly used as classification technique. It was initially developed for binary classification, but it could be efficiently extended to multiclass problems. It can be a linear and non-linear classifier by creating a splitting hyperplane in original input space to separate the data points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scalable, handles complex data</head><p>Computationally expensive, there is no theorem to select the right kernel function</p><formula xml:id="formula_0">K-nearest neighbour (KNN)</formula><p>KNN is a supervised model reason with the underlying principal "Tell me who are your friends, I will tell you who are you" <ref type="bibr" target="#b47">[48]</ref>. It classifies new instances using the information provided by the K nearest neighbors, so that the assigned class will be the most common among them (majority vote). Additionally, as it does not build a model and no work is done until an unlabeled data pattern arrives, it is thus considered as a lazy approach.</p><p>Easy to implement, has good performance with simple problems, non-expert users can use it efficiently</p><p>Requires large storage space, determining the optimal value of K is time consuming, K values varies depending on the dataset, testing is slow, and when the training dataset is large, it is not suitable for real-time classification K-means K-means is a well-known unsupervised model. It can partition the data into K clusters based on a similarity measure, and the observations belonging to the same cluster have high similarity as compared to those of other clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fast, simple and less complex</head><p>Requires a number of cluster in advance, cannot handle the outliers</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Boosting algorithms</head><p>The main idea of boosting is to improve the performance of any model, even weak learners (i.e., XGBoost, AdaBoost, etc). The base model generates a weak prediction rule, and after several rounds, the boosting algorithms improve the prediction performance by combining the weak rules into a single prediction rule <ref type="bibr" target="#b48">[49]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>High accuracy, efficient against under-fitting</head><p>Computationally expensive, hard to find the optimal parameters</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Feature Reduction</head><p>The success of conventional ML algorithms generally depends on the features to which they are applied. In other words, their performance depends not only on the parameters but also on the features, which are used to describe each object to the ML models <ref type="bibr" target="#b49">[50]</ref>. In this section, we provide an overview of basic concepts as well as the motivation of the dimensionality reduction technique.</p><p>In general, the dataset can contain irrelevant (a feature that provides no useful information) and redundant (a feature with predictive ability covered by another) features, which cause an extra computational cost for both storage and processing in an SDN environment and decreases the model's performance <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b51">52]</ref>. For example, the time complexity of many ML algorithms is polynomial in the number of dimensions; for example, the time complexity of logistic regression is O(mn 2 + n 3 ), where n represents the number of features and m represents the number of instances <ref type="bibr" target="#b52">[53]</ref>. These challenges are referred to as the curse of dimensionality, which is one of the most important challenges in ML. The curse of dimensionality was introduced by Bellman in 1961 <ref type="bibr" target="#b17">[18]</ref>.</p><p>In addition, each model is only as good as the given features. Additionally, the model accuracy depends not only on the quality of input data but also on the amount features. The model may perform poorly and can overfit if the number of features is larger than the number of observations <ref type="bibr" target="#b53">[54]</ref>. Moreover, the low-latency applications (e.g., anomaly detection) require fast analysis, especially in the context of the fifth-generation (5G) networks, and feature reduction can help to leverage heavy analysis at network levels. All these make feature reduction difficult tasks not only because of the higher size of the initial dataset but because it needs to meet two challenges, which are to maximize the learning capacity and to reduce the computational cost and delay by reducing the number of features.</p><p>In fact, there are many benefits of feature reduction techniques, such as (i) improving the performance of learning algorithms either in terms of learning speed or generalization capacity and (ii) reducing the storage requirement. It reduces the original data and retains as much information as possible that is valuable for the learning process. Therefore, in a dataset with a high number of features, the data reduction process is a must to produce accurate ML models in a reasonable time. It can be divided into feature selection (i.e feature elimination) and feature extraction, as shown in Figure <ref type="figure" target="#fig_2">3</ref>. The main difference is that feature selection selects a subset of original features, while feature extraction creates new features from the original ones. Table <ref type="table" target="#tab_5">7</ref> presents the advantages and disadvantages of each approach. Each approach can be used in isolation or in a combination way with the aim of improving performance, such as the accuracy, visualization, and comprehensibility of learned knowledge <ref type="bibr" target="#b54">[55]</ref>. Rangarajan et al. <ref type="bibr" target="#b55">[56]</ref> proposed bi-level dimensionality reduction methods that combine feature selection methods and feature extraction methods to improve classification performance. Then, they compared the performance of three-dimensionality reduction techniques with three datasets. Based on their results, these combinations improve the precision, recall, and F-measure of the classifier. Additionally, we can find feature construction, which is different from the feature reduction technique. It is one of the preprocessing tasks that tries to increase the expressive power of initial features when the initial features set do not help us classify our data well enough. It is the process of creating additional features instead of reducing the features from the initial features set, beginning with n features f 1 , f 2 , f 3 , . . . , f n . After feature construction, we will have new p features f n+1 , f n+2 , f n+3 , . . . , f n+p . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">Feature Selection</head><p>The feature selection technique has become an indispensable component of the conventional machine learning algorithms (e.g., SVM, decision tree, etc.) <ref type="bibr" target="#b63">[64]</ref>, and it is one of the simplest ways to reduce data size. It tries to pick a subset of features that "optimally" characterize the target variable. Feature selection is the process of selecting the best features in a given initial set of features that yield a better classification performance <ref type="bibr" target="#b64">[65]</ref> and regression as well as finding clusters efficiently <ref type="bibr" target="#b65">[66]</ref>. In this section, we will focus on feature selection for classification since there is much more work on feature selection for classification than for other ML tasks (e.g., clustering). The best subset contains the least number of dimensions that improve the accuracy the most. It helps us to identify the relevant features (contribute to the identification of the output) and discard the irrelevant ones from the dataset to perform a more focused and faster analysis. The feature selection process consists of four basic steps, which are:</p><formula xml:id="formula_1">1.</formula><p>Subset generation is a search procedure that generates candidate feature subsets for evaluation based on a search strategy (i.e., start with no feature or with all features); 2.</p><p>Evaluation of subset tries to measure the discriminating ability of a feature or a subset to distinguish the target variables; 3.</p><p>Stopping criteria determines when the feature selection process should stop (i.e., addition or deletion of any feature does not produce a better subset); 4.</p><p>Result validation tries to test the validity of the selected features.</p><p>Many evaluation criteria have been proposed in several research works to determine the quality of the candidate subset of the features. Based on their dependency on ML algorithms, evaluation criteria can be categorized into two groups: independent and dependent criteria <ref type="bibr" target="#b15">[16]</ref>. For independent measures, we have (1) information measures, (2) consistency measures, (3) correlation measures, (4) and distance measures; for dependent criteria, we have several measures, such as accuracy. Therefore, feature selection can be distinguished into two broad categories, which are filters and wrappers, as explained in the following.</p><p>Filter Method: finds the best feature set by using some independent criteria (i.e., information measures) before applying any classification algorithm. Due to the computational efficiency, the filter methods are used to select features from high-dimensional data sets. Additionally, it is categorized as a binary or continuous feature selection method depending on the data type. For example, information gain (IG) can handle both binary and nominal data, but the Pearson correlation coefficient can only handle continuous data. Moreover, it can be further categorized into two groups: feature-weighting algorithms and subset search algorithms, which evaluate the quality of the features individually or through feature subsets. Feature-weighting algorithms give weights to all the features individually and rank them based on their weights. These algorithms can be computationally inexpensive and do not consider feature interactions, which may lead to selecting redundant features. This is why subset search algorithms have become popular. Subset search algorithms search through candidate feature subsets using certain evaluation measures (i.e., correlation) that capture the goodness of each subset <ref type="bibr" target="#b66">[67]</ref>;</p><p>Wrapper Method: requires a learning algorithm and uses its performance as the evaluation criterion (i.e., classifier accuracy). It calculates the estimated accuracy of a single learning algorithm through a search procedure in the space of possible features in order to find the best one. The search can be done with various strategies, such as forwarding direction (the search begins with an empty set and successively adds the most relevant features) and backward direction (the search starts with the full set and successively deletes less relevant features), which is also known as recursive feature elimination. Wrapper methods are also more computationally expensive than the filter methods and feature extraction methods, but they produce feature subsets with very competitive classification accuracy <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b51">52]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">Feature Extraction</head><p>Feature extraction performs a transformation of the original variables to generate other features using the mapping function F that preserves most of the relevant information. This transformation can be achieved by a linear or non-linear combination of original features. For example, for n features f 1 , f 2 , f 3 , . . . , f n , we extract a new feature set f 1 , f 2 , f 3 , . . . , f m where m &lt; n and</p><formula xml:id="formula_2">f i = F( f 1 , f 2 , f 3 , . . . , f n ).</formula><p>With the feature extraction technique, the feature space can often be decreased without losing a lot of information on the original attribute space. However, one of its limits is that the information about how the initial features contribute is often lost <ref type="bibr" target="#b51">[52]</ref>. Moreover, it is difficult to find a relationship between the original features and the new features. Therefore, the analysis of the new features is almost impossible, since no physical meaning for the transformed features is obtained from feature extraction techniques. In this survey, we discuss three of the most frequently used methods.</p><p>Principal Component Analysis (PCA) is the oldest technique of multivariate analysis and was introduced by Karl Pearson in 1901. It is an unsupervised (it does not take into account target variable) and non-parametric technique that reduces the dimensionality of data from f to p, where p &lt; f , by transforming the initial feature space into a smaller space. However, PCA has some limitations, discussed below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>It assumes that the relations between variables are linear; • It depends on the scaling of the data (i.e., each variable is normalized to zero mean); •</p><p>We do not know how many PCs should be retained (the optimal number of principal components (PCs)); • It does not consider the correlation between target outputs and input features <ref type="bibr" target="#b22">[23]</ref>;</p><p>Autoencoder (AE) is an unsupervised learning model which seeks to reconstruct the input from the hidden layer <ref type="bibr" target="#b67">[68]</ref>. During the process, the AE tries to minimize the reconstruction error by improving the quality of the learned feature. It is frequently used to learn discriminative features of original data. Hence, AE is potentially important for feature extraction, and many researchers use it to generate reduced feature sets (code). In many cases, deep autoencoder (DAE) outperforms conventional feature selection methods and PCA <ref type="bibr" target="#b68">[69]</ref> since it consists of several layers with nonlinear activation functions to extract features intelligently;</p><p>Linear discriminant analysis (LDA) is a feature extraction method used as a preprocessing step for ML algorithms and was first proposed in <ref type="bibr" target="#b69">[70]</ref>. It is similar to PCA, but LDA is a supervised method. In other words, it takes the target variable into account. It consists of three main steps, as mentioned in <ref type="bibr" target="#b70">[71]</ref>. Firstly, it calculates the between-class variance using the distance between the means of the classes. Secondly, it calculates the within-class variance using the distance between the mean and the observations of each class. Finally, it constructs the lower dimensional space, which maximizes the between-class variance and minimizes the within-class variance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Federated Learning</head><p>Federated learning (FL) is a decentralized learning approach used to ensure data privacy and decrease the exchange message between the server and clients <ref type="bibr" target="#b71">[72]</ref>. As shown in Figure <ref type="figure" target="#fig_4">4</ref> Since the traffic data has been increased, FL can be a promising solution for traffic management. For example, FL helps to detect the attack without communicating the packet/flow to a central entity <ref type="bibr" target="#b72">[73]</ref>. It keeps the traffic where it was generated. As a result, FL has started to attract the attention of researchers for intrusion detection <ref type="bibr" target="#b73">[74]</ref> and prediction <ref type="bibr" target="#b74">[75]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DL/ML Applications in Software-Defined Networking</head><p>Thanks to the main features of SDN, including the global network view, separation of the data plane from the control plane, and network programmability, SDN provides a new opportunity for ML/DL algorithms to be applied for network traffic management. In this section, we present the different application cases in the SDN environment using ML/DL algorithms in detail. According to the different application scenarios, we divide the existing application cases into three categories: traffic classification, traffic prediction, and intrusion detection systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Traffic Classification</head><p>The explosion in the number of smart devices has resulted in significant growth of network traffic as well as new traffic types. For example, mobile data traffic will be 77 exabytes per month, which is 7 times that in 2017 <ref type="bibr" target="#b0">[1]</ref>. In this context, the purpose of traffic classification is to understand the type of traffic carried on the Internet <ref type="bibr" target="#b75">[76]</ref>. It aims to identify the application's name (YouTube, Netflix, Twitter, etc.) or type of Internet traffic (streaming, web browsing, etc.). Therefore, traffic classification has significance in a variety of network-related activities, from security monitoring (e.g., detecting malicious attacks) and QoS provisioning to providing operators with useful forecasts for long-term and traffic management. For example, identifying the application from the traffic can help us to manage bandwidth resources <ref type="bibr" target="#b23">[24]</ref>. Additionally, network operators need to know what is flowing over their networks promptly so they can react quickly in support of their various business goals <ref type="bibr" target="#b76">[77]</ref>. Thereby, traffic classification has evolved significantly over time. It tries to separate several applications based on their feature "profile". Because of its importance, several approaches have been developed over the years to accommodate the diverse and changing needs of different application scenarios. There are three major approaches to achieve application identification and classification: (i) port-based, (ii) payload-based (deep packet inspection), and (iii) ML-based <ref type="bibr" target="#b49">[50]</ref>. Since this paper focuses on the application of ML/DL in softwarized networks, we will present only the approaches based on ML and DL models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Existing Solutions</head><p>In this subsection, we study several works that try to achieve different traffic classification objectives. We have divided traffic classification solutions into two broad categories according to classification level: (i) coarse-grained and (ii) fine-grained. The coarse-grained level classifies the traffic based on the traffic type, while the fine-grained level aims to classify based on the exact application. At the end, we also highlight some other recent approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coarse-grained traffic classification</head><p>With the intensive growth of online applications, it has become time-consuming and impractical to identify all the applications manually. Therefore, coarse-grained traffic classification aims to identify the QoS classes of traffic flows (e.g., streaming, web browsing, chat, etc.). Coarse-grained traffic classification is used to satisfy the QoS requirements of the network application at the same time.</p><p>Parsaei et al. <ref type="bibr" target="#b77">[78]</ref> introduced a network traffic classification in the SDN environment where several variants of neural networks were applied to classify traffic flows into different QoS classes (instant messaging, video streaming, FTP, HTTP, and P2P). These classifiers provided 95.6%, 97%, 97%, and 97.6% in terms of accuracy. However, the authors did not mention information on the architecture of the different neural network algorithms.</p><p>Xiao et al. <ref type="bibr" target="#b78">[79]</ref> proposed a classification framework based on SDN. It consists of two modules, which are the flow collector and spectral classifier. First, the flow collector module scans the flow tables from SDN controllers to collect traffic flows. Then, the spectral classifier module receives the flow from the flow collector module to create the clusters through spectral clustering. They fixed k = 6 as the number of flow classes (HTTP, SMTP, SSH, P2P, DNS, SSL2). Then, to evaluate their results, a comparative analysis with the K-means method in terms of accuracy, recall, and classification time was done. However, the authors did not mention information on the features and preprocessing methods used during their experiments.</p><p>Da Silva et al. <ref type="bibr" target="#b58">[59]</ref> focused on the identification and selection of flow features to improve traffic classification in SDN. The authors introduced architecture to compute additional flow features and select the optimal subset of them to be applied in traffic classification. This architecture is composed of flow feature manager and flow feature selector. Flow feature manager is responsible for gathering information through the controller and extending this information to complex flow features. Then, the flow feature selector finds the optimal subset of flow features using principal component analysis (PCA) and genetic algorithm (GA), followed by the classifier (SVM) to evaluate this subset. Based on the experimental results, we can reveal some conclusions: this feature selection technique can improve traffic classification and the features generated in this paper can give good accuracy.</p><p>In the same direction, Zaki and Chin <ref type="bibr" target="#b79">[80]</ref> compared four classifiers, C4.5, KNN, NB, and SVM. Those classifiers were trained with features selected by their proposed hybrid filter wrapper feature selection algorithm named (FWFS). FWFS evaluates the worth of the features with respect to the class, and the wrappers use an ML model to measure the feature subset. The experimental results demonstrate that the selected features through FWFS improve the performance of the classifiers.</p><p>Recently, the pattern of network traffic has become more complex, especially with the 5G network. This has made simple classifiers unable to provide an accurate model. To solve this issue, researchers in the field of networking started to use ensemble learning for network traffic classification. One of the main advantages of ensemble learning is its ability to allow the production of better predictive performance compared to a single model. In this context, Eom et al. <ref type="bibr" target="#b80">[81]</ref> applied four ensemble algorithms (RF, gradient boosting machine, XGBoost, LightGBM) and analyzed their classification performance in terms of accuracy, precision, recall, FI-score, training time, and classification time. The experiment results demonstrate that the LightGBM model achieves the best classification performance.</p><p>Yang et al. <ref type="bibr" target="#b81">[82]</ref> proposed a novel stacking ensemble classifier which combines seven models in two-tier architecture (Figure <ref type="figure" target="#fig_5">5</ref>). Specifically, on the first tier, KNN, SVM, RF, Ad-aBoost, and gradient boosting machine are trained independently on the same training set. Then, on the second tier, XGboost uses the prediction of the first-tier classifiers in order to improve the final prediction results. The comparative analysis against the individual single classifier and voting ensemble demonstrates the effectiveness of the proposed ensemble. As DL helps to eliminate the manual feature engineering task, Hu et al. <ref type="bibr" target="#b82">[83]</ref> proposed a CNN-based deep learning method to address the SDN-based application awareness called CDSA. As shown in Figure <ref type="figure" target="#fig_6">6</ref>, CDSA consists of three components, which are traffic collection, data pre-processing, and application awareness. To evaluate the performance of this framework, the open Moore dataset <ref type="bibr" target="#b83">[84]</ref> has been used. This dataset was released by the University of Cambridge. As new types of traffic emerge every day (and they are generally not labeled), this opens a new challenge to be handled. In fact, labeling data is often difficult and timeconsuming <ref type="bibr" target="#b27">[28]</ref>. Therefore, researchers started to reformulate traffic classification into semisupervised learning, where both supervised learning (using labeled data) and unsupervised learning (no label data) were combined.</p><p>In such a context, a framework of a semi-supervised model for network traffic classification has been proposed in <ref type="bibr" target="#b60">[61]</ref>. Specifically, DPI has been used to label a part of traffic flows of known applications. Each labeled application is categorized into four QoS classes (voice/video conference, interactive data, streaming, bulk data transfer). Then, this data is used by Laplacian SVM as a semi-supervised learning model in order to classify the traffic flows of unknown applications. Here, only "elephant" flows are used in the traffic classification engine. The proposed framework is fully located in the network controller and exceeds 90% accuracy. Additionally, the Laplacian SVM approach outperforms a previous semi-supervised approach based on the K-means classifier. Therefore, based on the experimental results presented in their paper, we can reveal some conclusions: by combining the DPI and ML method, traffic flows could be categorized into different QoS classes with acceptable accuracy. However, the authors did not present any detail about the complexity of the proposed framework.</p><p>Similar work is done by Yu et al. <ref type="bibr" target="#b85">[86]</ref>, where the authors proposed a novel SDN flow classification framework using DPI and semi-supervised ensemble learning. The significant difference is the ML algorithm used for the classification. Firstly, they used DPI to generate a partially labeled dataset with the QoS type of flow according to the application type. To train the classifier, they used the heteroid tri-training algorithm. This algorithm is a modified version of tri-training, which is a classic semi-supervised learning mechanism that uses three identical classifiers to enable iterative training. However, they used three heterogeneous classifiers (SVM, Bayes classifier, K-NN) instead of three identical classifiers to increase the difference among classifiers. To verify the performance of their framework, they used a real dataset and trained the classifier with different ratios of unlabeled application flows. However, the authors did not mention information about the feature selection method and the dataset used during the experiments.</p><p>In addition, Zhang et al. <ref type="bibr" target="#b62">[63]</ref> proposed a DL-based model in the SDN-based environment to classify the traffic to one of several classes (Bulk, Database, Interactive, Mail, Services, WWW, P2P, Attack, Games, Multimedia). It consists of the stacked autoencoder (SAE) and softmax classifier. SAE was used for feature extraction and softmax was used as a supervised classifier. The experimental results show that the proposed model outperforms the SVM. However, the authors proposed only the framework without testing its performance in the SDN environment.</p><p>Finally, to avoid data labeling, K-means has been proposed by Kuranage et al. <ref type="bibr" target="#b86">[87]</ref>. In this paper, several supervised learning methods were trained and evaluated individually, including SVM, DT, RF, and KNN. The results demonstrate that SVM has the highest accuracy with 96.37%. For this paper, the "IP Network Traffic Flows, Labeled with 75 Apps" dataset was used <ref type="bibr" target="#b87">[88]</ref>. However, the features used for the models' training are selected manually;</p><p>•</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fine-grained traffic classification</head><p>Fine-grained classification aims to classify the network traffic by application (the exact application generating the traffic) and facilitates the operators to understand users' profiles and hence provide better QoS.</p><p>Qazi et al. <ref type="bibr" target="#b88">[89]</ref> presented a mobile application detection framework called Atlas. This framework enables fine-grained application classification. The netstat logs from the employee devices are collected by the agents to collect ground truth data and are sent to the control plane, which runs the decision tree algorithm (C5.0) to identify the application. Their framework is capable of detecting a mobile application with 94% accuracy for the top 40 Android applications. However, the authors did not present the features used in this framework.</p><p>Li and Li <ref type="bibr" target="#b89">[90]</ref> presented MultiClassifier, an application classifier, by combining both DPI and ML to do classification in SDN. They try to exploit the advantage of both methods to achieve a high speed with acceptable accuracy. When a new flow arrives, MultiClassifier gives ML a higher priority to classify because it is much faster than DPI. If the reliability of the ML result is larger than a threshold value, its result will be the MultiClassifier results. If not and if DPI does not return "UNKNOWN", MultiClassifier will take the DPI result. This combination succeeded in reaching more than 85% accuracy. Based on the experimental results presented in their paper, we can reveal some conclusions: (i) ML runs four times faster than DPI, and (ii) DPI gives high accuracy. However, the authors did not present the features nor the ML algorithm used for the classification. Moreover, the simulations were not scaled, since they used only two hosts, and thus we cannot confirm the quality of this combination.</p><p>Raikar et al. <ref type="bibr" target="#b90">[91]</ref> proposed a traffic classification using supervised learning models in the SDN environment. Specifically, a brief comparative analysis of SVM, Naïve Bayes, and KNN has been done, where the accuracy of traffic classification is greater than 90% in all the three supervised learning models. However, the authors used only three applications (SMTP, VLC, HTTP), which is therefore not enough to verify the performance of the models.</p><p>In addition, Amaral et al. <ref type="bibr" target="#b61">[62]</ref> introduced a traffic classification architecture based on an SDN environment deployed in an enterprise network using ML. In this architecture, the controller collected the flow statistics from the switches, and then the preprocessing step was used, followed by several classifiers individually, including RF, stochastic gradient boosting, and extreme gradient boosting. The accuracy of each application is used as an evaluation metric. However, the study lacks the exploration of the other performance metrics (e.g., f-measure). Additionally, there is no information on the distribution of applications in the dataset. As each application can have several types of flows, like voice and chat, a fine-grained traffic classiication is needed. To solve this issue, Uddin and Nadeem <ref type="bibr" target="#b91">[92]</ref> introduced a traffic classification framework called TrafficVision that identifies the applications and their corresponding flow-type in real-time. TrafficVision is deployed on the controller, and one of the kernel modules of TrafficVision is named TV engine, which has three major tasks: (i) collecting, storing, and extracting flow statistics and ground-truth training data from end devices; (ii) building the classifiers from the training data; and (iii) applying these classifiers to identify the application and flow-types in real-time and providing this information to the upper layer application. As a proof of concept, the authors developed two prototypes of "network management" services using the TrafficVision framework. The classification task of the TV engine has two modules, which are application detection using decision tree (C5.0) and flow-type detection using KNN with K = 3. Both of these classifiers show more than 90% accuracy. The shortcoming in this paper is the classification of the 40 popular applications and the ignorance of other applications; this can cause problems in an enterprise or university network.</p><p>Amaral et al. <ref type="bibr" target="#b92">[93]</ref> proposed an application-aware SDN architecture, and the experimental results demonstrate that the semi-supervised classifier outperforms the supervised classifier (random forest classifier) with the same amount of labeled data. This is attributed to the fact that the incorporation of unlabeled data in the semi-supervised training process boosts the performance of the classifiers.</p><p>Nakao and Du <ref type="bibr" target="#b93">[94]</ref> used deep NN to identify mobile applications. Mobile network traffic was captured from the mobile virtual network operator (MVNO). Five flow features (i.e., a destination address, destination port, protocol type, TTL, and packet size) were selected to train an 8-layer deep NN model. DL achieves 93.5% accuracy for the identification of 200 mobile applications. The features used for classification are selected filter methods in order to train and improve the performance of the DL model.</p><p>Wang et al. <ref type="bibr" target="#b94">[95]</ref> developed an encrypted data classification framework called DataNet which is embedded in the SDN home gateway. This classification was achieved through the use of several DL techniques, including multilayer perceptron (MLP), stacked autoencoder (SAE), and convolutional neural networks (CNN). They used the "ISCX VPN-nonVPN" encrypted traffic dataset <ref type="bibr" target="#b95">[96]</ref>, which consists of 15 encrypted applications (i.e., Facebook, Skype, Hangout, etc.) and more than 200,000 data packets. However, they used only 73,392 flows after adopting the under-sampling method to balance the classes' distribution. This framework helps them to classify the traffic without compromising the security/privacy of services providers or users.</p><p>Chang et al. <ref type="bibr" target="#b96">[97]</ref> proposed an application for offline and online traffic classification. More specifically, the authors used three DL-based models, including CNN, MLP, and SAE models. Using the Tcpreplay tool, the traffic observations are re-produced and analyzed in an SDN testbed to emulate the online traffic service. The experimental results show that the offline training results have achieved more than 93% accuracy, whereas the online testing prediction achieved 87% accuracy for application-based detection. This may be attributed to the limitation of the processing speed leading to the dropping of statistics packets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Other Approaches for Traffic Classification</head><p>Video surveillance traffic increased sevenfold between 2016 and 2021 <ref type="bibr" target="#b97">[98]</ref>. Due to these changes, multimedia traffic must be managed as efficiently as possible. SDN and ML can be promising solutions to manage video surveillance traffic. Therefore, by applying SDN and ML, we are able to increase efficiency and reduce the cost of management. In this context, Rego et al. <ref type="bibr" target="#b98">[99]</ref> proposed an intelligent system for guaranteeing QoS of video traffic in surveillance IoT environments connected through SDN using the AI module, which is integrated into SDN. The traffic classification that detects whether the incoming flow is critical or not is based on the packets sent by the SDN controller to the AI system. This detection is performed through the use of SVM as a classifier and is able to detect critical traffic with 77% accuracy, which is better than other tested methods (i.e., NN or KNN).</p><p>Xiao et al. <ref type="bibr" target="#b59">[60]</ref> proposed a real-time elephant flow detection system which includes two main stages. In the first one, suspicious elephant flows are distinguished from mice flows using head packet measurement. In the second stage, the correlation-based filter (CFS) is used to select the optimal features to build a robust classifier. Then, elephant flows are used for improving the classification accuracy, and the decision tree (C4.5) classifies them as real elephant flows or suspicious flows. To maximize the detection rates and minimize the misclassification costs of elephant flows, they used the cost-sensitive decision trees as classifiers.</p><p>Indira et al.</p><p>[100] proposed a traffic classification method using a deep neural network (DNN) which classifies the packets based on the action (accept/reject). As a proof concept, the performance of DNN is compared with two classifiers, which are SVM and KNN.</p><p>In addition, <ref type="bibr">Abidi et al. [101]</ref> proposed a network slicing classification framework. Given network features, the proposed framework tries to find the network slices, such as enhanced mobile broadband (eMBB), massive machine-type communication (mMTC), or ultra-reliable low-latency communication (URLLC) by combined deep belief network and neural network models as well as meta-heuristic algorithms in order to enhance the classification performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Public Datasets</head><p>The evaluation and the success of ML/DL models depend on the dataset used. In this section, we present some well-known datasets used for network traffic classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>VPN-nonVPN dataset <ref type="bibr" target="#b95">[96]</ref>  Dataset-Unicauca <ref type="bibr" target="#b87">[88]</ref> is released by the Universidad Del Cauca, Popayán, Colombia. It was collected through packet captures at different hours during the morning and afternoon over 6 days in 2017. This dataset consists of 87 features, 3,577,296 observations, and 78 classes (Twitter, Google, Amazon, Dropbox, etc.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Discussion</head><p>This subsection presents several ML-based solutions for traffic classification in SDN, as summarised in Table <ref type="table" target="#tab_7">8</ref>. It has been divided into two tasks: coarse-grained and finegrained. Nowadays, as new applications emerge every day, it is not possible to have all the flows labeled in a real-time manner. Therefore, one of the most promising approaches is semi-supervised learning for fine-grained classification, which is closer to reality, as it profits through the use of labeled and unlabeled data. Moreover, DT-based models are the most frequently used for traffic classification where RF shows a good trade-off between performance and complexity. Furthermore, it requires less hyperparameter tuning <ref type="bibr">[104]</ref>. Additionally, DL models, as with different domains, verify their effectiveness for network traffic classification. In addition, most of the researchers used a single classical approach for traffic classification. However, using ensemble learning by combining several classifiers achieves better accuracy than any single classifier. Nevertheless, multi-classifier approaches (i.e., ensemble learning) can increase the computational complexity of the model and the classification time. To solve this issue, we can reduce the number of captured packets per flow in order to reduce the classification time. For example, we can use a set of three packets instead of five packets as used in some works <ref type="bibr" target="#b61">[62]</ref>. Additionally, based on the literature, each classifier is tested on its environment (i.e., data), and no paper explores all the classifiers with a deep comparison among them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Traffic Prediction</head><p>The objective of network traffic prediction is to forecast the amount of traffic expected based on historical data in order to avoid future congestion and maintain high network quality <ref type="bibr">[105]</ref>. It helps to keep the over-provisioning of the resources as low as possible, avoid congestion and decrease communication latency <ref type="bibr">[106,</ref><ref type="bibr">107]</ref>. Network traffic prediction can be formulated as the prediction of the future traffic volume ( ŷt+l ) based on the historical and current traffic volumes (X t-J+1 , X t-J+2 ,. . . , X t ). Therefore, the objective of the ML/DL models is to find the parameters that minimize the error between the predicted and observed traffic with respect to X t-J+1 , X t-J+2 ,. . . , X t (Equations ( <ref type="formula">1</ref>) and ( <ref type="formula" target="#formula_3">2</ref>)).</p><formula xml:id="formula_3">W * = argmin W * L(y t+l , ŷt+l ; W * ) (1) ŷt+l = f ([X t-J+1 , X t-J+2 , . . . , X t ])<label>(2)</label></formula><p>where y t+l and ŷt+l are the observed and predicted value at time t + l, respectively, f (.) is the activation function, L is the loss function, and W * is the optimal set of parameters. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Existing Solutions</head><p>In this section, we present the recent works concerning traffic prediction. <ref type="bibr">Kumari et al. [108]</ref> presented a framework for SDN traffic prediction. To do so, two prediction models, namely ARIMA and SVR (support vector regression) have been used. The results showed that SVR outperforms the ARIMA method, where the average performance improve-ment is 48% and 26%. However, the temporal and spatial variation of network traffic made the accurate prediction of flows challenging. Consequently, learning highly complicated patterns requires more complicated models, like deep learning-based models.</p><p>From the recent literature, we can find representative DL methods that are frequently used for network prediction tasks in the SDN environment. For example, Azzouni and Pujolle [109] proposed a framework called neuTM to learn the traffic characteristics from historical traffic data and predict the future traffic matrix using LSTM (long short-term memory). They implemented their framework and deployed it on SDN, then trained it on a real-world dataset using different model configurations. The experimental results show that their model converges quickly and can outperform linear forecasting models and feed-forward deep neural networks. <ref type="bibr">Alvizu et al. [110]</ref> applied a neural network model to predict network traffic load in a mobile network operator. The prediction results are used to make online routing decisions. The authors in this work train a real dataset for mobile network measured during November and December 2013 in Milano, Italy. Similarly, based on ANN, Chen-Xiao and Ya-Bin <ref type="bibr">[111]</ref> proposed a solution to keep network load balanced using SDN. This solution aims to select the least-loaded path for newcomer data flow. They take advantage of the global view of SDN architecture to collect four features of each path, which are bandwidth utilization ratio, packet loss rate, transmission latency, and transmission hop, and use ANN to calculate the load condition of each path.</p><p>In addition, network traffic prediction is even important for the IoT network given the huge amount of IoT devices widely used in our daily life. To improve the transmission quality for such a network, an efficient deep learning-based traffic load prediction algorithm to forecast future traffic load was proposed by <ref type="bibr">Tang et al. [112]</ref>. The authors presented the performance of their algorithms with three different systems (centralized SDN system, semi-centralized, and a distributed conventional control system without centralized SDN). For the centralized SDN system, the authors used M deep CNN where each deep CNN is only used to predict the traffic load of one switch. In each switch, the traffic load consists of two parts: (i) the relayed traffic flow from other switches, and (ii) the integrated traffic flow composed by the sensing data from devices. However, for the semi-centralized SDN system, each switch uses just a deep belief network to predict the traffic generated by connected sensing devices; then, centralized SDN uses Deep CNN to make the final prediction. Based on the obtained results, the accuracy with a centralized SDN system is always better than the two other systems (more than 90%).</p><p>Due to the volatile nature of network traffic in smaller time scales, Lazaris et al.</p><p>[113] focused on network traffic prediction over short time scales using several variations of the LSTMs model. To evaluate the performance of their solution, the authors used real-life traffic (CAIDA Anonymized Internet Traces 2016 Dataset) <ref type="bibr">[114]</ref>. The experimental results demonstrate that the LSTM models perform much better than the ARIMA models in all scenarios (e.g., various short time scales).</p><p>Le et al.</p><p>[115] proposed a DL-based prediction application for an SDN network. Specifically, the authors have used three RNN variants models, which are long short-term memory (LSTM), gated recurrent units (GRU), and BiLSTM. Their experiments show that all three models, especially the GRU model, perform well but still produce significant predicting errors when the traffic is suddenly shot. However, BiLSTM consumes the most resources in training and predicting.</p><p>Additionally, to ensure dynamic optimization of the allocation of network resources in a proactive way, <ref type="bibr">Alvizu et al. [106]</ref> proposed machine-learning-based traffic prediction. Specifically, the GRU model was used in order to predict the mobile network traffic matrix in the next hour.</p><p>Moreover, with the scale and complexity expected for the networks, it is essential to predict the required resources in a proactive way. To do so, network traffic forecasting is the need of the hour. In this context, <ref type="bibr">Ferreira et al. [116]</ref> used both linear and non-linear forecasting methods, including machine learning, deep learning, and neural networks, to improve management in 5G networks. Through these forecasting models, a multi-slice resource management approach has been proposed, and the experimental results show that it is possible to forecast the slices' needs and congestion probability efficiently and, accordingly, maintain the QoS of the slice and the entire network.</p><p>Last but not least, since the ML/DL-based models need continuous training because the network situation changes quickly, sending all raw data to a central entity can slow the convergence of the models as well as introduce network congestion. To solve these issues, Sacco et al. <ref type="bibr" target="#b74">[75]</ref> used the LSTM model in a collaborative way in order to predict the future load to optimize routing decisions (i.e., select the best path). More specifically, the authors used federated architecture with a multi-agent control plane, where each controller trains the LSTM model locally then sends only its model parameters to the Cloud for global aggregation (Figure <ref type="figure" target="#fig_7">7</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Public Datasets</head><p>The dataset is an important component in the process of traffic prediction, as it has a direct impact on the accuracy and applicability of the model. Here, we identify some public datasets that can be used for network traffic prediction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Discussion</head><p>In the above subsection, several ML-based solutions for traffic prediction in SDN have been presented, as summarized in Table <ref type="table">9</ref>. Mobile communication faces many challenges when the number of smart devices increases, and hence, the load in the network can lead to network congestion. In this context, ML models can be used to predict the network situation and help the operator to anticipate exceptional resource demand or reduce resources when no longer needed. Traffic prediction is considered a regression problem (i.e., dataset outputs have continuous values). Therefore, supervised learning can be used for traffic prediction. Based on the literature, DL algorithms, especially LSTM, are widely adopted and can be considered a promising solution for network traffic prediction. However, building an LSTM model does not mean successful results, since several factors can affect the performance of the model, such as the model hyperparameters and the size of the dataset used during the training process. Additionally, the model needs continuous training, since the network situation changes quickly. Moreover, the exchange of information between the controller and the forwarding devices can overload the system and can pose security and data privacy problems. Therefore, federated learning seems to be an efficient solution. This method can optimize the communication between SDN and the involved forwarding devices by keeping the data where it was generated. This leads to preserving the bandwidth for the application traffic, reducing costs of data communication, and ensuring data security. Thus, more attention should be given to this research direction.</p><p>Additionally, as SDN and ML-based models are considered the enablers of the realization of the 5G network, <ref type="bibr">Li et al. [124]</ref> proposed an intelligent attack classification system in an SD-5G network using RF for feature selection and AdaBoost for attack classification with the selected features. The 10% of the KDD Cup 1999 dataset was used to evaluate the proposed system. The results demonstrate that, using the selected features, the classifier can better differentiate the attack traffic and produce a low overhead system. Similarly, <ref type="bibr">Li et al. [125]</ref> proposed a two-stage intrusion detection and attack classification system in an SD-IoT network. In the first stage, they selected the relevant features, which were used in the second stage for attack anomaly detection. The experiments on the KDD Cup 1999 dataset show that random forest achieved a higher accuracy with an acceptable complexity time compared to the existing approaches.</p><p>However, as conventional ML models have difficulties detecting attacks in largescale network environments [126], DL models have been used. They can give better performance for intrusion detection, as with network traffic classification and prediction (Sections 3.1 and 3.2) without the need to extract the features manually. In this context, Tang et al. <ref type="bibr" target="#b44">[45]</ref> proposed a DNN model for anomaly detection using only six features that can be easily obtained in an SDN environment. The experimental results on the NSL-KDD dataset show that the deep learning approach outperforms the conventional ML models. Then, <ref type="bibr">Tang et al. [127,</ref><ref type="bibr">128]</ref> proposed, for the first time, the GRU-RNN model for anomaly detection in SDN, which is an extension of their previous work <ref type="bibr" target="#b44">[45]</ref>. This model has the ability to learn the relationship between current and previous events. Using the NSL-KDD dataset, the GRU-RNN model achieved 89% accuracy using the 6 features. Additionally, the experimental results demonstrate that the GRU-RNN model outperforms VanilaRNN, SVM, and DNN.</p><p>To also improve the detection rate of the attack or the intrusion, some researchers have started to combine DL-based models and conventional or classical ML models. More specifically, they take advantage of the benefits of the deep features extracted through deep learning, which can be used with conventional models for classification or attack detection. In this context, <ref type="bibr">Elsayed et al. [129]</ref> combined CNN architecture with conventional ML-based models, including SVM, KNN, and RF. Specifically, CNN extracts the deeper representations from the initial features, while the classification task is performed through SVM, KNN, and RF. To evaluate the performance of their approach, the authors used a novel dataset, called InSDN, which is specific to an SDN network [130], along with UNSW-NB15, and CIC-IDS2018 datasets. The results demonstrate the potential of CNN for anomaly detection even with a few amount of features (9 features). Also, the combination of CNN and SVM, KNN, and especially the RF algorithm provide higher performance compared to a single CNN.</p><p>Unlike the centralized architecture, distributed SDN can deploy multiple IDS for the active detection of attacks. In contrast to the other IDS approaches, <ref type="bibr">Shu et al. [131]</ref> proposed a collaborative IDS based on distributed SDN in VANETs, called CIDS. In other words, CIDS enables all the distributed SDN controllers to collaboratively train a stronger detection model based on the whole network flow. To do so, generative adversarial networks (GAN) have been used, wherein a single discriminator is trained on the Cloud server and several generators are trained on the SDN controllers. Using the KDD99 and NSL-KDD datasets, the evaluation results show that the proposed method achieves better performance as compared to centralized detection methods.</p><p>Although distributed SDNs are trained on richer data, they are limited in terms of collaboration. Consequently, the FL started to attract researchers since there is a need for collaboration among the domain. In this context, Thapa et al. <ref type="bibr" target="#b73">[74]</ref> proposed an FL model for the detection and mitigation of ransomware attacks in the healthcare system called FedDICE. Specifically, FedDICE integrates FL in an SDN environment to enable collaborative learning without data exchange. The performance of the FedDICE framework is similar to the performance achieved by centralized learning. Similarly, <ref type="bibr">Qin et al. [132]</ref> used FL for intrusion detection in the SDN environment. They combined FL and binarized neural networks for intrusion detection using programmable network switches (e.g., the P4 language). Using programmable switches and FL enables the incoming packet to be classified directly in the gateway instead of forwarded to the edge controller or Cloud server. The results demonstrate that FL leads to more accurate intrusion detection compared with training each gateway independently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DDoS attack detection/classification</head><p>A DDoS attack is a complex form of denial of service attack (DoS). It generates a huge amount of source IP address and destination IP address packets, and in turn, the switches send a large number of packets to the controller. This may exhaust the networking, storage, and computing resources of the controller <ref type="bibr">[133]</ref>. Therefore, detection and mitigation of DDoS attacks in real-time is necessary. As a result, several ML models have been used for DDoS attack detection in the SDN environment. In this context, <ref type="bibr">Ahmad et al. [134]</ref> evaluated different well-known models, including SVM, naive Bayes, DT, and logistic regression. The results show that the SVM performed better than other algorithms, since the classifiers were used for the binary classification scenarios.</p><p>Chen et al.</p><p>[135] used XGBoost as a detection method in a SDN-based Cloud network. Then, they evaluated the efficiency of XGBoost through the Knowledge Discovery and Data mining (KDD) Cup 1999 dataset. The evaluation was done considering a binary classification scenario (DDoS/benign traffic). A final comparison was made between XGBoost, Random Forest, and SVM. Additionally, to detect the anomaly in the data plane level and to minimize the load on the control plane, Da el al.</p><p>[107] proposed a framework for the detection, classification, and mitigation of traffic anomalies in the SDN environment called ATLANTIC. It consists of two phases, which are (i) the lightweight phase and (ii) the heavyweight phase. The lightweight phase is responsible for anomaly detection by calculating the deviation in the entropy of flow tables, whereas the heavyweight phase uses the SVM model for anomaly classification.</p><p>Recently, like the other domains, DL models have been used for DDoS attack detection. For example, <ref type="bibr">Niyaz et al. [136]</ref> proposed a DL-based system for DDoS attack detection in an SDN environment. Specifically, SAE has been used for feature reduction in an unsupervised manner. Then, the traffic classification was performed with the softmax layer in the scenario of two classes (DDoS/benign traffic) and the eight classes, which included normal traffic and seven kinds of DDoS attacks. The experimental results show that the SAE model achieved higher performance compared to the neural network model using their own private dataset.</p><p>Other DL models have been used for DDoS attack detection like CNN, RNN, and LSTM. For example, <ref type="bibr">Li et al. [137]</ref> used CNN, RNN, and LSTM as neural network models to realize the detection of DDoS attacks in the SDN environment. The evaluation and training tasks of the used models were done on the ISCX2012 dataset. Similarly, <ref type="bibr">Haider et al. [138]</ref> used the same DL-based model for DDoS attack detection using a benchmark dataset (CI-CIDS2017 dataset). More specifically, four DL-based models were applied in an ensemble (RNN+RNN, LSTM+LSTM, CNN+CNN) or in a hybrid way (e.g., RNN+LSTM). The results show the capability of DL models and especially the ensemble CNN model in detecting DDoS very well. Ensemble CNN provides high detection accuracy (99.45%); however, it takes more time for the training and classification tasks.</p><p>Moreover, Novaes et al.</p><p>[120] proposed a detection and mitigation framework against DDoS attacks in SDN environments. To do so, they used the generative adversarial Network (GAN) model in order to make the proposed framework less sensitive to adversarial attacks. The experiments were conducted on emulated data and the public dataset CICD-DoS 2019, where the GAN obtained superior performance compared to the CNN, MLP, and LSTM models.</p><p>Although the DL-based models are efficient for the DDoS attack detection/classification, combining deep and conventional ML models can take advantage of both techniques and hence further improve the performance of the security system. <ref type="bibr">Krishnan et al. [139]</ref> proposed a hybrid ML approach by combining DL and conventional ML models called VARMAN. AE was used to generate 50 new reduced features from the CICIDS2017 dataset as well as to optimize the computation and memory usage. Then, random forest acts as the main DDoS classifier. The experiments demonstrate that VARMAN outperforms the deep belief networks model, and this is attributed to the combination of different models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Public Datasets</head><p>As the performance of the IDS techniques relies on the quality of the training datasets, in this subsection, we review the publicly widely used datasets to evaluate the performance of the ML/DL-based model for intrusion detection. Different ML/DL-based models have been used for intrusion detection/classification. Despite the performance of DL models, many solutions use conventional ML models (shown from Table <ref type="table">10</ref>) due to their simplicity. However, these models are usually accompanied by some dimensionality reduction methods. Additionally, as seen in the literature review, the detection of DDoS attacks has attracted many researchers. In other words, since the SDN controller represents the central brain of the network that stores and processes the data from all forwarding devices, it can be targeted by DDoS attacks. Moreover, FL can be used to improve the security and privacy of the end-users by keeping the traffic at the level of the data plane without damaging the controller. It is able to involve a massive number of forwarding devices which are important for training DL models. Therefore, by only sharing the local update of the global model between the forwarding devices and the controller, the communication overhead may be reduced, hence speeding up the attack detection/classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Research Challenges and Future Directions</head><p>Research works on the use of ML techniques with networks have produced a multitude of novel approaches. The application of ML/DL models to networking brings several use cases and solutions. However, these solutions suffer from some issues and challenges in practice <ref type="bibr" target="#b49">[50,</ref><ref type="bibr">148]</ref>. Many important factors should be considered when designing an ML-based system in an SDN environment. In this context, this section discusses the key challenges and the issues of using ML/DL algorithms for network management in the SDN environment. Then, we present some research opportunities in related areas.</p><p>Imbalanced data samples: Class imbalances are one of the critical problems in traffic classification/intrusion detection. For example, most of the time, the samples of the anomaly are rare, and there is a great imbalance between the amount of several applications' traffic (i.e., Google, Facebook, Skype) compared to other traffic. A two-class dataset is said to be imbalanced if one of the classes (the minority one) is represented by a very small number of instances in comparison to the other (majority) class. The classifier tends to be biased toward the larger groups that have more observations in the training sample <ref type="bibr">[149]</ref>. Therefore, ignoring the unequal misclassification risk for different groups may have a significant impact on the practical use of the classification <ref type="bibr" target="#b22">[23]</ref>. Several methods have been proposed as solutions to imbalance class problems, such as under-sampling, over-sampling, synthetic minority over-sampling techniques (SMOTE), or using boosting methods <ref type="bibr">[150]</ref>.</p><p>Identifying DL architecture: Engineering the right set of features for a given scenario is often key to the success of a machine-learning project and is not an easy-to-solve question. Therefore, one of the challenges of ML is to automate more and more of the feature engineering process. DL is currently the most active topic of ML. It can process raw data and generate relevant features autonomously. These features are automatically extracted from the training data by DL. However, it is computationally demanding, especially if computing resources are limited. DL has many hyperparameters and their number grows exponentially with the depth of the model. Therefore, it requires a lot of tuning, and there is no clear mathematical proof to interpret its architecture. Finding suitable architecture (i.e., number of hidden layers) and identifying optimal hyperparameters (i.e., learning rate, loss function, etc.) are difficult tasks and can influence the model performance.</p><p>Available datasets: Note that the model training performance is highly dependent on the dataset. Therefore, it is one important component for ML/DL models training, as it has a direct impact on the accuracy and applicability of classifiers <ref type="bibr" target="#b85">[86]</ref>. Although there are a few recent public datasets available for traffic classification <ref type="bibr" target="#b87">[88,</ref><ref type="bibr" target="#b95">96]</ref>, there is no commonly agreed-upon dataset for most traffic-related classification problems. Additionally, choosing the right dataset is difficult because ML models can only identify applications based on what it has known (existing in the training set). ML algorithms, and especially DL models, can further benefit from training data augmentation. This is indeed an opportunity for using ML/DL algorithms to improve QoS, as the networks generate tremendous amounts of data and the intensive growth of applications on the Internet. However, due to privacy and lack of shareable data, there is difficulty in progressing on traffic classification. To solve these issues, distributed learning and, especially, FL have started to attract more and more researchers for network traffic management. Moreover, due to the huge number of applications on the Internet, the dataset cannot contain all of them. Therefore, the amount of available data could still be insufficient to train ML algorithms effectively, especially DL algorithms. For these reasons, many researchers try to use old datasets to test their solutions. However, this solution is inefficient, as the behaviors of modern applications change, and their complexity increases every day. Furthermore, most network data are unlabeled; hence, fine-grained classification becomes impractical, and it is unrealistic to achieve low complexity classification based on unsupervised learning.</p><p>Selection of ML models: ML/DL models are constructed and tested in their environment (i.e., dataset, features). However, average high performance does not guarantee high performance with other problems. Additionally, the choice of the appropriate model is a daunting task, since it depends on many parameters such as the types of data, the size of the data samples/features, the time, and computing resource constraints, as well as the type of prediction outcomes. Therefore, in light of the diversity of ML/DL models, choosing the appropriate one is a difficult task because a single wrong decision can be extremely costly.</p><p>Selection of flow features: Besides the selection of the suitable ML model, the performance of this model relies on the collection of features used for the flow classification. Thus, one of the most challenging aspects of flow-based techniques is how to select the appropriate flow of statistical features. Researchers try to only use features which are easy to be obtained with the SDN controller to train the model, but this solution can decrease the performance of ML models <ref type="bibr" target="#b44">[45]</ref>. Additionally, some features can have a continuous or discrete value. However, several ML models cannot learn with two types of features at the same time, such as SVM and XGBoost.</p><p>Scalable traffic classification: In recent years, we have observed enormous growth in Internet traffic. Increased traffic volume makes traffic classification tasks computationally intensive and imposes several challenges to implement in real-time. Distributed architecture can solve this issue and rapidly query, analyze, and transform data at scale. Spark performs 100x faster computation than Hadoop <ref type="bibr">[151]</ref>. It also provides a fast machine learning library, MLib, that leverages high-quality learning algorithms. However, based on Table <ref type="table" target="#tab_7">8</ref>, no study has carried out an experimental evaluation on the scalability of ML-based traffic classification in SDN. Moreover, FL can be used in order to take advantage of the end-user and edge devices by training the model locally in a distributed way on such devices.</p><p>Variance and bias: The most important evaluation criterion for a learner is its ability to generalize. Generalization error can be divided into two components, which are variance and bias. Variance defines the consistency of a learner's ability to predict random things (over-fitting), and bias describes the ability of a learner to learn the wrong thing (underfitting) <ref type="bibr" target="#b17">[18]</ref>. A learner with the lowest bias, however, is not necessarily the optimal solution, because the ability to generalize from training data is also assessed by a second parameter termed variance. A major challenge for ML/DL models is to optimize the trade-off between bias and variance. Therefore, to prevent this problem, we can split our data into three subsets, which are training, validation, and testing. The training set is used for the learning task, validation helps to find the parameters of the learner, and then the testing set is used to evaluate the performance of the constructed model. Additionally, another method named K-fold cross-validation can be used to avoid the problem of over-fitting. In this method, the data is divided into k folds; then, k -1 folds are used as the training set, and the remaining fold is used as the test set. However, it is expensive in terms of training time and computation.</p><p>Network Slicing: As presented in the literature, the definition of a slice is based on the QoS requirement proposed by NGMN, and no intelligence has been applied in this context. Currently, new online applications are emerging every day, and network behavior is constantly changing. Additionally, the explosion of smart devices and the surge in traffic will need different requirements for their performance. Therefore, the ML concepts can help to find more behaviors and better slices even with a single network infrastructure.</p><p>Knowledge transfer in multiple SDN controllers: The model trained by some SDN controllers can capture common features with other SDN controllers (e.g., domain). This means the data can be transferable between the domain and hence can provide a more general model. For this purpose, transfer learning can be used in order to transfer the knowledge between the different SDN controllers. It helps the model to avoid being trained from scratch, thus accelerating the model convergence and solving the problem of insufficient training data <ref type="bibr">[152]</ref>.</p><p>Privacy: In recent years, privacy has been one of the most important concerns in the network domain. ML models, especially DL models, may benefit from training data augmentation. However, the end-users or clients refuse to provide their data due to the risk of data misuse or inspection by external devices. To solve this issue and guarantee that training data remains on its owners, a distributed learning technique like FL can be a promising solution. It enables the operators to benefit through the data of clients without sacrificing their privacy. In this context, FL can be the appropriate approach for network traffic management, especially with SDN architecture, as it reduces the data exchange between the data plane and SDN controller. Therefore, it guarantees data confidentiality, minimizes costs of data communication, and relieves the burden on the SDN controller. Additionally, it can be used with network slicing for user prediction for each slice to enable the local data training without the need of sharing the data between the slices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this survey, we examined the integration of machine and deep learning in next generation networks, which is becoming a promising topic and enables intelligent network traffic management. We first provide an overview of ML and DL along with SDN in which the basic background and motivation of these technologies were detailed. More specifically, we have presented that SDN can benefit from ML and DL approaches. Furthermore, we have summarized basic concepts and advanced principles of several ML and DL models, as well as their strengths and weaknesses. We have also presented dimensionality reduction techniques (i.e., feature selection and extraction) and their benefits with the conventional ML models. In addition, we have shown how ML/DL models could help various aspects of network traffic management, including network traffic classification, prediction, and network security. However, the combination of SDN and ML can suffer from various issues and challenges. Therefore, we discussed those which need the researcher's attention both in industry and academia. In summary, research on the integrated SDN and ML for intelligent traffic network management in next-generation networks is promising, and several challenges lay ahead. This survey attempts to explore essential ingredients related to the integration of ML in SDN and aims to become a reference point for the future efforts of researchers who would like to delve into the field of intelligent traffic networks and their applications. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Conceptual map of survey.</figDesc><graphic coords="5,166.39,94.86,303.00,171.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Conventional ML and DL.</figDesc><graphic coords="9,166.39,273.72,329.40,231.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The classification of dimensionality reduction approaches.</figDesc><graphic coords="11,166.39,533.83,396.86,113.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>, the training process is divided into two steps: (i) local model training and (ii) global aggregation of updated parameters in the FL server. For more details, first, the central server specifies the hyperparameters of the global model and the training process. Then, it broadcasts the global model to several clients. Based on this model, each client trains the global model for a given number of epochs using its own data. Then, they send back the updated model to the FL server for the global aggregation. These steps are repeated until the global model is achieved for a selected number of rounds in order to achieve satisfactory performance. As a result, FL helps the final model to take advantage of the different clients without exchanging their data. Additionally, it may decrease the communication overhead by exchanging the model parameters instead of the clients' data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. General federated learning architecture [73], local model training on the client-side and global aggregation of updated parameters in the FL server.</figDesc><graphic coords="14,176.11,434.65,54.68,51.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Flowchart for the proposed ensemble classifier discussed in Yang et al. [82].</figDesc><graphic coords="16,166.39,295.33,213.60,186.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Framework of CDSA, which consists of traffic collection, data pre-processing and application awareness [83]. Malik et al. [85] introduced an application-aware classification framework for SDNs called Deep-SDN. The performance of Deep-SDN was evaluated on the Moore dataset [84], which is real-world traffic. The experimental results demonstrate that the Deep-SDN outperformed the DL model proposed in [63] by reporting 96% overall accuracy.</figDesc><graphic coords="16,166.39,590.01,305.64,97.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. A federated learning approach with SDN-enabled edge networks [75].</figDesc><graphic coords="23,166.39,238.15,261.12,193.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>•</head><label></label><figDesc>Abilene dataset [117] contains the real trace data from the backbone network located in North America consisting of 12 nodes and 30 unidirectional links. The volume of traffic is aggregated over slots of 5 min starting from 1 March 2004 to 10 September 2004; • GEANT [118] has 23 nodes and 36 links. A traffic matrix (TM) is summarized every 15 min starting from 8 January 2005 for 16 weeks (10,772 TMs in total); • Telecom Italia [119] is part of the "Big Data challenge". The traffic was collected from 1 November 2013 to 1 January 2014 using 10 min as a temporal interval over Milan. The area of Milan is divided into a grid of 100 × 100 squares, and the size of each square is about 235 × 235 m. This dataset contains three types of cellular traffic: SMS, call, and Internet traffic. Additionally, it has 300 million records, which comes to about 19 GB.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Funding:</head><label></label><figDesc>This research received no external funding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc>List of abbreviations.</figDesc><table><row><cell>Acronym</cell><cell>Definition</cell><cell>Acronym</cell><cell>Definition</cell></row><row><cell>SDN</cell><cell>Software-defined networking</cell><cell>MLP</cell><cell>Multi-layer perceptron</cell></row><row><cell>SDWSN</cell><cell>Software-defined wireless sensor networks</cell><cell>CNN</cell><cell>Convolutional neural network</cell></row><row><cell>ML</cell><cell>Machine learning</cell><cell>LSTM</cell><cell>Long short-term memory</cell></row><row><cell>DL</cell><cell>Deep learning</cell><cell>MVNO</cell><cell>Mobile virtual network operator</cell></row><row><cell>KDN</cell><cell>Knowledge-defined networking</cell><cell>AE</cell><cell>Autodncoder</cell></row><row><cell>AI</cell><cell>Artificial intelligence</cell><cell>DR</cell><cell>Dimensionality reduction</cell></row><row><cell>QoS</cell><cell>Quality of service</cell><cell>QoE</cell><cell>Quality of experience</cell></row><row><cell>ANN</cell><cell>Artificial neural network</cell><cell>RL</cell><cell>Reinforcement learning</cell></row><row><cell>ONF</cell><cell>Open network foundation</cell><cell>OF</cell><cell>OpenFlow</cell></row><row><cell>NFV</cell><cell>Network function virtualisation</cell><cell>FL</cell><cell>Federated learning</cell></row><row><cell>DBN</cell><cell>Deep belief network</cell><cell>DRL</cell><cell>Deep Reinforcement Learning</cell></row><row><cell>GRU</cell><cell>Gated recurrent units</cell><cell>NGMN</cell><cell>Next Generation Mobile Networks</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Comparison of ML approaches.</figDesc><table><row><cell>Method</cell><cell>Strengths</cell><cell>Weaknesses</cell></row><row><cell>Supervised learning</cell><cell>Low computational cost, fast, scalable</cell><cell>Requires data labeling and data training, behaves poorly with highly imbalanced data</cell></row><row><cell>Unsupervised learning</cell><cell>Requires only the data samples, can detect unknown patterns, generates labeling data</cell><cell>Cannot give precise information</cell></row><row><cell>Semi-supervised</cell><cell>Learns from both labeled and</cell><cell>May lead to worse performance when we</cell></row><row><cell>learning</cell><cell>unlabeled data</cell><cell>choose the wrong rate of unlabeled data</cell></row><row><cell></cell><cell>Can be used to solve complex problems,</cell><cell></cell></row><row><cell>Reinforcement</cell><cell>efficient when the only way to collect</cell><cell>Slow in terms of convergence, needs a lot</cell></row><row><cell>learning</cell><cell>information about the environment is to</cell><cell>of data and a lot of computation</cell></row><row><cell></cell><cell>interact with it</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .</head><label>4</label><figDesc>Summary of different deep learning models used in SDN.</figDesc><table><row><cell cols="2">Method Learning Model</cell><cell>Description</cell><cell>Strengths</cell><cell>Weaknesses</cell></row><row><cell></cell><cell></cell><cell>MLP is a simple artificial neural network (ANN)</cell><cell></cell><cell></cell></row><row><cell>MLP</cell><cell>Supervised, unsupervised</cell><cell>which consists of three layers. The first layer is the input layer. The second layer is used to extract features from the input. The last layer is the output</cell><cell>Easy to implement.</cell><cell>Modest performance, slow convergence, occupies a large amount of memory.</cell></row><row><cell></cell><cell></cell><cell>layer. The layers are composed of several neurons.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Autoencoder consists of three parts: (i) encoder,</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>(ii) code, and (iii) decoder blocks. The encoder</cell><cell>Works with big and</cell><cell>The quality of features</cell></row><row><cell></cell><cell></cell><cell>converts the input features into an abstraction,</cell><cell>unlabeled data, suitable for</cell><cell>depends model architecture</cell></row><row><cell>AE</cell><cell>Unsupervised</cell><cell>known as a code. Using the code, the decoder tries</cell><cell>feature extraction and used</cell><cell>and its hyperparameters,</cell></row><row><cell></cell><cell></cell><cell>to reconstruct the input features. It uses some</cell><cell>in place of manual</cell><cell>hard to find the code</cell></row><row><cell></cell><cell></cell><cell>non-linear hidden layers to reduce the</cell><cell>engineering.</cell><cell>layer size.</cell></row><row><cell></cell><cell></cell><cell>input features.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>CNN is a class of DL which consists of a number</cell><cell></cell><cell></cell></row><row><cell>CNN</cell><cell>Supervised, Unsupervised</cell><cell>of convolution and pooling (subsampling) layers followed by a fully connected layers. Pooling and convolution layers are used to reduce the dimensions of features and find useful patterns. Next, fully connected layers are used for classification. It is widely used for image</cell><cell>Weight sharing, extracts relevant features, high competitive performance.</cell><cell>High computational cost, requires large training dataset and high number of hyperparameter tuning to achieve optimal features.</cell></row><row><cell></cell><cell></cell><cell>recognition applications.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>LSTM is an extension of recurrent neural network</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>(RNNs) and was created as the solution to</cell><cell></cell><cell></cell></row><row><cell>LSTM</cell><cell>Supervised</cell><cell>short-term memory. It has internal mechanisms called gates (forget gate, input gate, and output gate) that can learn which data in a sequence is important to keep or throw away. Therefore, it</cell><cell>Good for sequential information, works well with long sequences.</cell><cell>High model complexity, high computational cost.</cell></row><row><cell></cell><cell></cell><cell>chooses which information is relevant to</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>remember or forget during sequence processing.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>GRU was proposed in 2014. It is similar to LSTM</cell><cell></cell><cell></cell></row><row><cell>GRU</cell><cell>Supervised</cell><cell>but has fewer parameters. It works well with sequential data, as does LSTM. However, unlike LSTM, GRU has two gates, which are the update</cell><cell>Computationally more efficient than LSTM.</cell><cell>Less efficient in accuracy than LSTM.</cell></row><row><cell></cell><cell></cell><cell>gate and reset gate; hence, it is less complex.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>DRL takes advantage of both DL and RL to be</cell><cell></cell><cell></cell></row><row><cell>DRL</cell><cell>Reinforcement</cell><cell>applied to larger problems. In others word, DL enables RL to scale to decision-making problems</cell><cell>Scalable (i.e., can learn a more complex environment).</cell><cell>Slow in terms of training.</cell></row><row><cell></cell><cell></cell><cell>that were previously intractable.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Training is unsupervised,</cell><cell></cell></row><row><cell></cell><cell></cell><cell>DBN is stacked by several restricted Boltzmann</cell><cell>which removes the necessity</cell><cell></cell></row><row><cell>DBN</cell><cell>Unsupervised, supervised</cell><cell>machines. It takes advantage of the greedy and then fine-tunes the whole model using learning process to initialize the model parameters</cell><cell>of labelling data for training network, which can avoid or properly initializing the</cell><cell>High computational cost.</cell></row><row><cell></cell><cell></cell><cell>the label.</cell><cell>the local optima, extracting</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>robust features.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 .</head><label>5</label><figDesc>Summary of popular deep learning frameworks<ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>.</figDesc><table><row><cell>DL Frameworks</cell><cell>Creator</cell><cell>Available Interface</cell><cell cols="2">Popularity Released</cell></row><row><cell>Tensorflow</cell><cell>Google Brain Team</cell><cell>C++, Go, Java, JavaScript, Python, Swift</cell><cell>High</cell><cell>2015</cell></row><row><cell>Caffe2</cell><cell>Facebook AI research</cell><cell>C++, Python</cell><cell>Low</cell><cell>2017</cell></row><row><cell>Deeplearning4j</cell><cell>Skymind</cell><cell>Java, Scala</cell><cell>Low</cell><cell>2014</cell></row><row><cell>MXNet</cell><cell>Apache Software Foundation</cell><cell>C++, Python, Julia, Matlab, JavaScript, Go, R, Scala, Perl</cell><cell>Medium</cell><cell>2015</cell></row><row><cell>Theano</cell><cell>University of Montreal</cell><cell>Python</cell><cell>Medium</cell><cell>2017</cell></row><row><cell>CNTK</cell><cell>Microsoft Research</cell><cell>C++, C#, Python</cell><cell>Low</cell><cell>2016</cell></row><row><cell>PyTorch</cell><cell>Facebook AI research</cell><cell>C++, Python</cell><cell>High</cell><cell>2016</cell></row><row><cell>Keras (higher level library for TensorFlow, CNTK, Theano, etc.)</cell><cell>François Chollet</cell><cell>Python</cell><cell>High</cell><cell>2015</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 .</head><label>6</label><figDesc>Comparison of classical ML approaches used in SDN.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7 .</head><label>7</label><figDesc>Comparison of dimensionality reduction techniques<ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b56">57]</ref>.</figDesc><table><row><cell cols="2">Method Advantages</cell><cell>Disadvantages</cell><cell>Methods</cell><cell>Potential Application in SDN</cell></row><row><cell>Filter</cell><cell>Low computational cost, fast, scalable</cell><cell>Ignores the interaction with the classifier</cell><cell>CFS, IG, FCBF</cell><cell>QoS prediction [58], traffic classification [59,60].</cell></row><row><cell>Wrapper</cell><cell>Competitive classification accuracy, interaction with the classifier</cell><cell>Slow, expensive for large feature space, risk of over-fitting</cell><cell>Forward/backward direction</cell><cell>Traffic classification [61], QoS prediction [58].</cell></row><row><cell>Feature extraction</cell><cell>Reduces dimension without loss of information</cell><cell>No information about the original features</cell><cell>PCA, LDA, AE</cell><cell>Traffic classification [59,62,63].</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>is a popular encrypted traffic classification dataset. It contains only time-related features and regular traffic, as well as traffic captured over a virtual private network (VPN). Specifically, it consists of four scenarios. Scenario A is used for binary classification in order to indicate whether the traffic flow is VPN or not. contains only time-related features. This dataset has eight different labels, corresponding to the eight different types of traffic captured, which are browsing, audio streaming, chat, video streaming, mail, VoIP, P2P, and file transfers; • QUIC [103] is released by the University of California at Davis. It contains five Google services: Google Drive, Youtube, Google Docs, Google Search, and Google Music. •</figDesc><table /><note><p>Both scenario B and scenario C are classification tasks. Scenario B contains only seven non-VPN traffic services like audio, browsing, etc. Scenario C is similar to Scenario B, but it contains seven traffic services of the VPN version. Scenario D contains all fourteen classes of scenario B and scenario C to perform the 14-classification task; • Tor-nonTor dataset[102]</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 .</head><label>8</label><figDesc>Summary of reviewed papers on ML application for traffic classification in SDN.</figDesc><table><row><cell>Classification Level</cell><cell>Ref.</cell><cell>ML/DL Algorithm</cell><cell>Dimensionality Reduction</cell><cell>Dataset Output</cell><cell>Controller</cell></row><row><cell></cell><cell>[61]</cell><cell>DPI and Laplacian SVM</cell><cell>Wrapper method</cell><cell>Voice/video conference, interactive data, streaming, bulk data transfer</cell><cell>N/A</cell></row><row><cell></cell><cell>[78]</cell><cell>Feedforward, MLP</cell><cell>-</cell><cell>Instant message, stream, P2P, HTTP, FTP</cell><cell>Floodlight</cell></row><row><cell></cell><cell>[79]</cell><cell>Spectral clustering</cell><cell>N/A</cell><cell>HTTP, SMTP, SSH, P2P, DNS, SSL2</cell><cell>Floodlight</cell></row><row><cell></cell><cell>[59]</cell><cell>SVM</cell><cell>PCA</cell><cell>DDoS attacks, FTP, video streaming</cell><cell>Floodlight</cell></row><row><cell></cell><cell>[63]</cell><cell>Stacked Autoencoder</cell><cell>AE</cell><cell>Bulk, database, interactive, mail, services, WWW, P2P, attack, games, multimedia</cell><cell>N/A</cell></row><row><cell>Coarse-grained</cell><cell>[86]</cell><cell>Heteroid tri-training (SVM, KNN, and Bayes classifier)</cell><cell>N/A</cell><cell>Voice, video, bulk data, interactive data</cell><cell>N/A</cell></row><row><cell>classification</cell><cell>[87]</cell><cell>SVM, decision tree, random forest, KNN</cell><cell>-</cell><cell>N/A</cell><cell>RYU</cell></row><row><cell></cell><cell>[80]</cell><cell>C4.5, KNN, NB, SVM</cell><cell>Filter and wrapper method</cell><cell>WWW, mail, bulk, services, P2P, database, multimedia, attack</cell><cell>N/A</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>WWW, mail, FTP-control, FTP-data, P2P,</cell><cell></cell></row><row><cell></cell><cell>[83]</cell><cell>CNN</cell><cell>-</cell><cell>database, multimedia, services, interactive,</cell><cell>N/A</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>games</cell><cell></cell></row><row><cell></cell><cell>[81]</cell><cell>DT, RF, GBM, LightGBM</cell><cell>N/A</cell><cell>Web browsing, email, chat, streaming, file transfer, VoIP, P2P</cell><cell>RYU</cell></row><row><cell></cell><cell>[82]</cell><cell>Ensemble classifier (KNN, SVM, RF, AdaBoost, Boosting, XGBoost)</cell><cell>-</cell><cell>Video, voice, bulk data transfer, music, interactive</cell><cell>N/A</cell></row><row><cell></cell><cell>[85]</cell><cell>Deep learning</cell><cell>-</cell><cell>WWW, mail, FTP-control, FTP-pasv, FTP-data, attack, P2P, database, multimedia, services</cell><cell>POX</cell></row><row><cell></cell><cell>[90]</cell><cell>DPI and classification algorithm</cell><cell>N/A</cell><cell>N/A</cell><cell>Floodlight</cell></row><row><cell></cell><cell>[89]</cell><cell>Decision tree (C5.0)</cell><cell>N/A</cell><cell>Top 40 Android applications</cell><cell>N/A</cell></row><row><cell></cell><cell>[62]</cell><cell>Random forest, stochastic gradient boosting, XGBoost</cell><cell>PCA</cell><cell>Bittorent, Dropbox, Facebook, HTTP, Linkedin, Skype, Vimeo, Youtube</cell><cell>HP VAN</cell></row><row><cell>Fine-grained classification</cell><cell>[92]</cell><cell>Decision tree (C5.0), KNN</cell><cell>-</cell><cell>The top 40 most popular mobile applications</cell><cell>Floodlight</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>AIM, email client, Facebook, Gmail, Hangout,</cell><cell></cell></row><row><cell></cell><cell>[95]</cell><cell>MLP, SAE, CNN</cell><cell>AE</cell><cell>ICQ, Netflix, SCP, SFTP, Skype, Spotify, Twitter,</cell><cell>N/A</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Vimeo, Voipbuster, Youtube</cell><cell></cell></row><row><cell></cell><cell>[94]</cell><cell>Deep Learning</cell><cell>Filter method</cell><cell>200 mobile applications</cell><cell>N/A</cell></row><row><cell></cell><cell>[93]</cell><cell>Random forest</cell><cell>-</cell><cell>Bittorrent, Dropbox, Facebook, HTTP, Linkedin, Skype, Vimeo, Youtube</cell><cell>HPE VAN</cell></row><row><cell></cell><cell>[97]</cell><cell>MLP, CNN, SAE</cell><cell>-</cell><cell>Facebook, Gmail, Hangouts, Netflix, Skype, Youtube</cell><cell>Ryu</cell></row><row><cell></cell><cell>[91]</cell><cell>SVM, KNN, Naive Bayes</cell><cell>N/A</cell><cell>SMTP, HTTP, VLC</cell><cell>POX</cell></row><row><cell></cell><cell>[99]</cell><cell>SVM</cell><cell></cell><cell>Video surveillance traffic in IoT environment (critical or non-critical traffic)</cell><cell>N/A</cell></row><row><cell>Others</cell><cell>[60]</cell><cell>Decision tree (C4.5)</cell><cell>Filter method</cell><cell>Elephant flow, mice flow</cell><cell>Floodlight</cell></row><row><cell></cell><cell>[100]</cell><cell>DNN</cell><cell>-</cell><cell>Action (accept/reject)</cell><cell>N/A</cell></row><row><cell></cell><cell>[101]</cell><cell>Deep belief network, neural network</cell><cell>-</cell><cell>Enhanced mobile broadband slice, massive ultra-reliable low-latency communication slice machine-type communications slice,</cell><cell>N/A</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>•</head><label></label><figDesc>KDD'99 [140]  is one of the most well-known datasets for validating IDS. It consists of 41 traffic features and 4 attack categories besides benign traffic. The attack traffic is categorized into denial of service (DoS), remote to local (R2L), user to root (U2R), or probe attacks. This dataset contains redundant observations, and therefore, the trained model can be biased towards the more frequent observations; • The NSL-KDD dataset [141] is the updated version of the KDD'99 dataset. It solves the issues of the duplicate observations. It contains two subsets, a training set and testing set, where the distribution of attack in the testing set is higher than the training set; • The ISCX dataset [121] was released by the Canadian Institute for Cybersecurity, University of New Brunswick. It consists of benign traffic and four types of attack, which are brute force attack, DDoS, HttpDoS, and infiltrating attack; • Gas pipeline and water storage tank [142] is a dataset released by a lab at Mississippi State University in 2014. They proposed two datasets: the first is with a gas pipeline, and the second is for a water storage tank. These datasets consist of 26 features and 1 label. The label contains eight possible values, benign and seven different types of attacks, which are naive malicious response injection, complex malicious response injection, malicious state command injection, malicious parameter command injection,</figDesc><table><row><cell></cell><cell>malicious function command injection, reconnaissance, and DoS attacks;</cell></row><row><cell>•</cell><cell>The UNSW-NB15 dataset [143] is one of the recent datasets; it includes a simulated</cell></row><row><cell></cell><cell>period of data which was 16 h on 22 January 2015 and 15 h on 17 February 2015. This</cell></row><row><cell></cell><cell>dataset has nine types of attacks: fuzzers, analysis, backdoors, DoS, exploits, generic,</cell></row><row><cell></cell><cell>reconnaissance, shellcode, and worms. It contains two subsets, a training set with</cell></row><row><cell></cell><cell>175,341 observations and a testing set with 82,332 observations and 49 features;</cell></row><row><cell>•</cell><cell>The CICDS2017 dataset [144] is one of the recent intrusion detection datasets released</cell></row><row><cell></cell><cell>by the Canadian Institute for Cybersecurity, University of New Brunswick. It contains</cell></row><row><cell></cell><cell>80 features and 7 types of attack network flows: brute force attack, heartbleed attack,</cell></row><row><cell></cell><cell>botnet, DoS Attack, DDoS Attack, web attack, infiltration attack;</cell></row><row><cell>•</cell><cell>The DS2OS dataset [145] was generated through the distributed smart space orches-</cell></row><row><cell></cell><cell>tration system (DS2OS) in a virtual IoT environment. This dataset contains benign</cell></row><row><cell></cell><cell>traffic and seven types of attacks, including DoS, data type probing, malicious control,</cell></row><row><cell></cell><cell>malicious operation, scan, spying, and wrong setup. It consists of 357,952 observations</cell></row><row><cell></cell><cell>and 13 features;</cell></row><row><cell>•</cell><cell>The ToN-IoT dataset [146] was put forward by the IoT Lab of the UNSW Canberra</cell></row><row><cell></cell><cell>Cyber, the School of Engineering and Information Technology (SEIT), and UNSW</cell></row><row><cell></cell><cell>Canberra at the Australian Defence Force Academy (ADFA). It contains traffic collected</cell></row><row><cell></cell><cell>from the Internet of Things (IoT) and industrial IoT devices. It contains benign traffic</cell></row><row><cell></cell><cell>and 9 different types of attacks (backdoor, DDoS, DoS, injection, MITM, password,</cell></row><row><cell></cell><cell>ransomware, scanning, and XSS) with 49 features;</cell></row><row><cell>•</cell><cell>The IoT Botnet dataset [147] uses the MQTT protocol as a communication proto-</cell></row></table><note><p>col. It contains 83 features and 4 different types of attacks, including DDoS, DoS, reconnaissance, and theft, along with benign traffic; • The InSDN dataset [130] is a recent dataset and the first one generated directly from SDN networks. It consists of 80 features and 361,317 observations for both normal and attack traffic. It covers different types of attack types, including DoS, DDoS, probe, 3.3.3. Discussion</p></note></figure>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data Availability Statement: Not Applicable. The study does not report any data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of Interest:</head><p>The authors declare no conflict of interest.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table">9</ref>. Summary of reviewed papers on ML applications for network traffic prediction in SDN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ref. ML/DL Model Controller Contribution</head><p>[109] LSTM POX The authors proposed a traffic prediction framework and deployed it on SDN using a real-world dataset under different model configurations.</p><p>[110] ANN N/A The authors used the prediction results to make online routing decisions.</p><p>[111] ANN Floodlight</p><p>The proposed system tries to benefit from the global view of SDN controller in order to collect the bandwidth utilization ratio, packet loss rate, transmission latency, and transmission hop of each path. Then, using the ANN model, it predicts the load condition of each path.</p><p>[112] Deep CNN N/A</p><p>The authors presented the performance of their systems with three different systems, which are a centralized SDN system, a semi-centralized SDN system, and a distributed conventional control system without centralized SDN.</p><p>[106] GRU-RNN N/A The authors used (GRU-RNN) in order to predict the mobile network traffic matrix in the next hour.</p><p>[108] SVR N/A The authors demonstrate that SVR outperforms the ARIMA method; the average performance improvement is 48% and 26%.</p><p>[113] LSTM N/A The authors focused on network traffic prediction for short time scales using several variations of the LSTM model.</p><p>[75] LSTM+FL Floodlight</p><p>The authors used an LSTM model and federated learning in order to predict the future load to optimize routing decisions and at the same ensure data privacy as well decrease the exchange message between the SDN controller.</p><p>[115] LSTM, BiLSTM, GRU POX The authors proposed a comparative analysis between three RNN-based models: LSTM, GRU, and BiLSTM.</p><p>[116] Shallow ML models, DL models, ensemble learning N/A The authors take advantage of the forecasting results in order to manage the network slice resource.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Network Security</head><p>Despite the advantages of SDN, its security remains a challenge. More specifically, the centralized control plane of SDN can be a point of vulnerability <ref type="bibr">[120]</ref>. An intrusion detection system (IDS) is one of the most important network security tools due to its potential in detecting novel attacks <ref type="bibr">[121]</ref>. According to Base and Mell [122], intrusions are defined as "attempts to compromise the confidentiality, integrity, or availability of a computer or network, or to bypass the security mechanisms of a computer or network".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Existing Solutions</head><p>Recently, ML/DL based models have been widely used for intrusion and attack detection. In this section, we present a literature review of these models for IDS (Table <ref type="table">10</ref>).</p><p>ML-based models are widely applied for network IDS. For example, Latah et al.</p><p>[123] proposed a comparative analysis between different conventional ML-based models for the intrusion detection task using a benchmark dataset (NSL-KDD dataset). The features used by these classifiers were extracted and reduced after the application of the PCA method. The results demonstrate that using PCA enhances the detection rate of the classifiers, as well as the DT approach, showing the best performance in terms of all the evaluation metrics. botnet, exploitation, password guessing, web attacks, and benign traffic (HTTPS, HTTP, DNS, Email, FTP, SSH) that can occur in the SDN environment. The authors achieve a good performance using the GRU-RNN model with only six features.</p><p>[135] DDoS detection XGBoost Filter method POX</p><p>The XGBoost algorithm has strong scalability and higher accuracy and a lower false positive rate than random forest and SVM.</p><p>[136] DDoS classification SAE AE POX Before the DDoS attack detection task, the authors used SAE for feature reduction in an unsupervised manner.</p><p>[120] DDoS classification GAN -Floodlight The authors used GAN to make their system more efficient against adversarial attacks.</p><p>[125] Attack classification RF Filter method N/A The authors used an upgrade metaheuristic algorithm for feature selection and RF as a classifier.</p><p>[124] Attack classification AdaBoost Wrapper method N/A</p><p>The authors demonstrate that using the feature selection method improves the attack classification task as well as produces a low overhead system.</p><p>[137] DDoS detection LSTM, CNN, RNN -N/A The authors have compared different DL-based models.</p><p>[138] DDoS detection CNN -N/A</p><p>The authors proposed an ensemble CNN model for the DDoS attack detection and compared its performance with other known DL-based models using a benchmark dataset.</p><p>[139] DDoS classification AE+RF AE Ryu</p><p>The authors proposed a hybrid ML approach by combining deep learning and conventional ML models. The AE is used to extract a reduced version of the initial features, and the RF acts as the main classifier of the system.</p><p>[129] Attack classification</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN+SVM, CNN+RF, CNN+DT CNN N/A</head><p>The authors demonstrate the potential of CNN for anomaly detection even with a few amount of features (9 features). Additionally, the combination of CNN and SVM, KNN, and especially the RF algorithm enhances the detection rate and provides a higher performance compared to the single CNN.</p><p>[134] DDoS detection SVM, Naive-Bayes, DT, and Logistic Regression</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N/A POX</head><p>The authors compare the performance of different well-known ML-based models, including SVM, Naive-Bayes, DT, and logistic regression.</p><p>[123] Intrusion detection DT, RF, AdaBoost, KNN, SVM PCA N/A</p><p>The authors focused on a comparative analysis between different conventional ML-based models for the intrusion detection task using a benchmark dataset (NSL-KDD dataset).</p><p>[107] DDoS classification SVM PCA Floodlight</p><p>The authors proposed a framework for detection and classification called ATLANTIC. The attack detection is performed by calculating the deviations in the entropy of flow tables, whereas the attack classification was done by the SVM model. The authors proposed a federated learning model in an SDN environment to enable collaborative learning for detection and mitigation of ransomware attacks in healthcare without data exchange.</p><p>[132] Intrusion detection BNN+FL -N/A</p><p>The authors combined FL and binarized neural networks for intrusion detection using programmable network switches (e.g., P4 language).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m">Cisco Visual Networking Index: Global Mobile Data Traffic Forecast Update</title>
		<meeting><address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Cisco</publisher>
			<date type="published" when="2017">2017-2022. 2019</date>
		</imprint>
	</monogr>
	<note>White Paper</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Machine learning for cognitive network management</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ayoubi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Limam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Salahuddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shahriar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boutaba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Estrada-Solano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Caicedo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Mag</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="158" to="165" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Knowledge-defined networking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mestres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rodriguez-Natal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barlet-Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alarcón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Solé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Muntés-Mulero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barkai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Hibbett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Comput. Commun. Rev</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="2" to="10" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A survey of machine learning techniques applied to software defined networking (SDN): Research issues and challenges</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Surv. Tutor</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="393" to="430" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Application of Artificial Intelligence to Software Defined Networking: A survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Latah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Toker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Indian J. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Artificial Intelligence enabled Software-Defined Networking: A comprehensive overview</title>
		<author>
			<persName><forename type="first">M</forename><surname>Latah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Toker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Netw</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="79" to="99" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A survey of networking applications applying the Software Defined Networking concept based on machine learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="95397" to="95417" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Machine learning techniques for traffic identification and classification in SDWSN: A survey</title>
		<author>
			<persName><forename type="first">R</forename><surname>Thupae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Isong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gasela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Abu-Mahfouz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual Conference of the IEEE Industrial Electronics Society</title>
		<meeting>the 44th Annual Conference of the IEEE Industrial Electronics Society<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10-23">21-23 October 2018</date>
			<biblScope unit="page" from="4645" to="4650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Machine Learning and Deep Learning based traffic classification and prediction in Software Defined Networking</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shirmohammadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Symposium on Measurements &amp; Networking (M&amp;N)</title>
		<meeting>the IEEE International Symposium on Measurements &amp; Networking (M&amp;N)<address><addrLine>Catania, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07-10">8-10 July 2019</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A comprehensive survey on machine learning for networking: Evolution, applications and research opportunities</title>
		<author>
			<persName><forename type="first">R</forename><surname>Boutaba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Salahuddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Limam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ayoubi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shahriar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Estrada-Solano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Caicedo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Internet Serv. Appl</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="99" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Survey on SDN based network intrusion detection system using machine learning approaches</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sultana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chilamkurti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Alhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Peer-Netw. Appl</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="493" to="501" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The challenges in SDN/ML based network security: A survey</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03539</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A survey on deep learning: Algorithms, techniques, and applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pouyanfar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sadiq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Shyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Iyengar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv. (CSUR)</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A tutorial survey of architectures, algorithms, and applications for deep learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">APSIPA Trans. Signal Inf. Process</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A survey of feature selection and feature extraction techniques in machine learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Khalid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nasreen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Science and Information Conference</title>
		<meeting>the Science and Information Conference<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08-29">27-29 August 2014</date>
			<biblScope unit="page" from="372" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Toward Integrating Feature Selection Algorithms for Classification and Clustering</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="491" to="502" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A survey on Software-Defined Wireless Sensor Networks: Challenges and design requirements</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Kobo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Abu-Mahfouz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Hancke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1872" to="1899" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A few useful things to know about machine learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="78" to="87" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Machine learning: Trends, perspectives, and prospects</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="page" from="255" to="260" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Machine Learning</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Editorial introduction to the neural networks special issue on deep learning of representations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural networks for classification: A survey</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man, Cybern</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="451" to="462" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards the deployment of machine learning solutions in network traffic classification: A systematic survey</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pacheco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Exposito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gineste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Baudoin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aguilar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Surv. Tutor</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1988" to="2014" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Performance evaluation of feature selection and tree-based algorithms for traffic classification</title>
		<author>
			<persName><forename type="first">O</forename><surname>Aouedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Piamrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parrein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 IEEE International Conference on Communications Workshops (ICC Workshops)</title>
		<meeting>the 2021 IEEE International Conference on Communications Workshops (ICC Workshops)<address><addrLine>Montreal, QC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-06-23">14-23 June 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A survey on Data Mining approaches for Healthcare</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tomar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Bio-Sci. Bio-Technol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="241" to="266" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Semi-Supervised Learning Literature Survey</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">J</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Madison, WI, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin-Madison Department of Computer Sciences</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A semi-supervised stacked autoencoder approach for network traffic classification</title>
		<author>
			<persName><forename type="first">O</forename><surname>Aouedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Piamrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bagadthey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 IEEE 28th International Conference on Network Protocols (ICNP)</title>
		<meeting>the 2020 IEEE 28th International Conference on Network Protocols (ICNP)<address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-10-16">13-16 October 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Introduction to Reinforcement Learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><surname>Others</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
			<biblScope unit="volume">135</biblScope>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Q-learning</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learn</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="279" to="292" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Packet routing in dynamically changing networks: A reinforcement learning approach</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Boyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/1993/hash/4ea06fbc83cdd0a06020c35d50e1e89a-Abstract.html" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022-01-15">on 15 January 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Q-routing: From the algorithm to the routing protocol</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bitaillou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Parrein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Andrieux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning for Networking</title>
		<meeting>the International Conference on Machine Learning for Networking<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-05">3-5 December 2019</date>
			<biblScope unit="page" from="58" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Playing atari with deep reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5602</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning: An overview</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07274</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Deep Learning with Python</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ketkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Santana</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">1</biblScope>
			<pubPlace>Berlin/Heidelberg, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A survey on deep learning for big data</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="146" to="157" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Scalable deep learning on distributed infrastructures: Challenges, techniques, and tools</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Jacobsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv. (CSUR)</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Review of deep learning algorithms and architectures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shrestha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mahmood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="53040" to="53065" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Neural Networks: A Comprehensive Foundation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haykin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Hoboken, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A survey of multiple classifier systems as hybrid systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Woźniak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Corchado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Fusion</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="3" to="17" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A novel ensemble deep learning model for stock prediction based on stock prices and news</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<idno type="DOI">10.1007/s41060-021-00279-9</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Data Sci. Anal</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Ensemble based systems in decision making</title>
		<author>
			<persName><forename type="first">R</forename><surname>Polikar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Circuits Syst. Mag</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="21" to="45" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep learning approach for network intrusion detection in Software Defined Networking</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mhamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mclernon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A R</forename><surname>Zaidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghogho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 International Conference on Wireless Networks and Mobile Communications (WINCOM)</title>
		<meeting>the 2016 International Conference on Wireless Networks and Mobile Communications (WINCOM)<address><addrLine>Fez, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-10-29">26-29 October 2016</date>
			<biblScope unit="page" from="258" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The alternating decision tree learning algorithm</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Machine Learning (ICML)</title>
		<meeting>the 16th International Conference on Machine Learning (ICML)<address><addrLine>Bled, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-06-30">27-30 June 1999</date>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="124" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Machine learning based QoE prediction in SDN networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Abar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Letaifa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>El Asmi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Wireless Communications and Mobile Computing Conference (IWCMC)</title>
		<meeting>the 13th International Wireless Communications and Mobile Computing Conference (IWCMC)<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-30">26-30 June 2017</date>
			<biblScope unit="page" from="1395" to="1400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The boosting approach to machine learning: An overview</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nonlinear Estimation and Classification</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="149" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Issues and future directions in traffic classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dainotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pescape</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Claffy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Netw</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="35" to="40" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Machine learning with big data: Challenges and approaches</title>
		<author>
			<persName><forename type="first">A</forename><surname>Grolinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Elyamany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Capretz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="7776" to="7797" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">On the relationship between feature selection and classification accuracy</title>
		<author>
			<persName><forename type="first">A</forename><surname>Janecek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gansterer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Demel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ecker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the New Challenges for Feature Selection in Data Mining and Knowledge Discovery</title>
		<meeting>the New Challenges for Feature Selection in Data Mining and Knowledge Discovery<address><addrLine>Antwerp, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-09-15">15 September 2008</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="90" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Map-reduce for machine learning on multicore</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bradski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="281" to="288" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Gene selection for cancer classification using support vector machines</title>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barnhill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="389" to="422" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Feature selection, extraction and construction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Motoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. IICM</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2002">2002</date>
			<publisher>Institute Inf. Comput. Mach. Taiwan</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Bi-level dimensionality reduction methods using feature selection and feature extraction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="33" to="38" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Feature selection for classification of hyperspectral data by SVM</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Foody</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="2297" to="2307" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Learning from network device statistics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Stadler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pasquini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Fodor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Netw. Syst. Manag</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="672" to="698" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Identification and selection of flow features for accurate traffic classification in SDN</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Machado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Bisol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Z</forename><surname>Granville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schaeffer-Filho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Symposium on Network Computing and Applications</title>
		<meeting>the 14th International Symposium on Network Computing and Applications<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09">September 2015</date>
			<biblScope unit="page" from="134" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">An efficient elephant flow detection with cost-sensitive in SDN</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Conference on Industrial Networks and Intelligent Systems (INISCom)</title>
		<meeting>the 1st International Conference on Industrial Networks and Intelligent Systems (INISCom)<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-03-04">2-4 March 2015</date>
			<biblScope unit="page" from="24" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A framework for QoS-aware traffic classification using semi-supervised machine learning in SDNs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Services Computing (SCC)</title>
		<meeting>the IEEE International Conference on Services Computing (SCC)<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-07-02">27 June-2 July 2016</date>
			<biblScope unit="page" from="760" to="765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Machine learning in software defined networks: Data collection and traffic classification</title>
		<author>
			<persName><forename type="first">P</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dinis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bernardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tavares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Mamede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Network Protocols (ICNP)</title>
		<meeting>the 24th International Conference on Network Protocols (ICNP)<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-11">8-11 November 2016</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deep learning-based network application classification for SDN</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Emerg. Telecommun. Technol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">3302</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Stability of Feature Selection Algorithms: A Study on High-Dimensional Spaces</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kalousis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Prados</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hilario</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="95" to="116" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Feature selection for classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intell. Data Anal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="131" to="156" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Feature selection for clustering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Pacific-Asia Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Pacific-Asia Conference on Knowledge Discovery and Data Mining<address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">April 18-20 2000</date>
			<biblScope unit="page" from="110" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Feature selection for high-dimensional data: A fast correlation-based filter solution</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Machine Learning (ICML-03)</title>
		<meeting>the 20th International Conference on Machine Learning (ICML-03)<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-08-24">21-24 August 2003</date>
			<biblScope unit="page" from="856" to="863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Deep learning for visual understanding: A review</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oerlemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Lew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="page" from="27" to="48" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">An Ensemble of Deep Auto-Encoders for Healthcare Monitoring</title>
		<author>
			<persName><forename type="first">O</forename><surname>Aouedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A B</forename><surname>Tobji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Hybrid Intelligent Systems</title>
		<meeting>the International Conference on Hybrid Intelligent Systems<address><addrLine>Porto, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-12-15">13-15 December 2018</date>
			<biblScope unit="page" from="96" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The use of multiple measurements in taxonomic problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Eugen</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="179" to="188" />
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Linear discriminant analysis: A detailed tutorial</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tharwat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gaber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hassanien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Commun</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="169" to="190" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Federated Learning for Wireless Communications: Motivation, Opportunities, and Challenges</title>
		<author>
			<persName><forename type="first">S</forename><surname>Niknam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Reed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Mag</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="46" to="51" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Federated Learning for Intrusion Detection System: Concepts, Challenges and Future Directions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Aouedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yenduri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Piamrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K R</forename><surname>Maddikunta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Gadekallu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09527</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">A ransomware spread detection in a distributed integrated clinical environment using federated learning and SDN based mitigation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Thapa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Karmakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Celdran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Camtepe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Varadharajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nepal</surname></persName>
		</author>
		<author>
			<persName><surname>Feddice</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.05434</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A Federated Learning Approach to Routing in Challenged SDN-Enabled Edge Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sacco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Esposito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Marchetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th IEEE Conference on Network Softwarization (NetSoft)</title>
		<meeting>the 6th IEEE Conference on Network Softwarization (NetSoft)<address><addrLine>Ghent, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-07-03">29 June-3 July 2020</date>
			<biblScope unit="page" from="150" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">State of the Art in Traffic Classification: A Research Review</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Claffy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brownlee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the PAM Student Workshop</title>
		<meeting>the PAM Student Workshop<address><addrLine>Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-04-03">1-3 April 2009</date>
			<biblScope unit="page" from="3" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A survey of techniques for internet traffic classification using machine learning</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Armitage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun. Surv. Tutor</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="56" to="76" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Network traffic classification using machine learning techniques over software defined networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Parsaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Sobouti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Khayami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Javidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Adv. Comput. Sci. Appl</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="220" to="225" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A traffic classification method with spectral clustering in SDN</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT)</title>
		<meeting>the 17th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT)<address><addrLine>Guangzhou, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12">December 2016</date>
			<biblScope unit="page" from="391" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Selecting robust features towards reliable and stable traffic classifier in SDN</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A M</forename><surname>Zaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><surname>Fwfs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="166011" to="166020" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Network Traffic Classification Using Ensemble Learning in Software-Defined Networks</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Eom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)</title>
		<meeting>the 2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-04-23">20-23 April 2021</date>
			<biblScope unit="page" from="89" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Achieving Robust Performance for Traffic Classification Using Ensemble Learning in SDN Networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vural</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rahulan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tafazolli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Communications</title>
		<meeting>the IEEE International Conference on Communications<address><addrLine>virtual</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-06">June 2021</date>
			<biblScope unit="page" from="14" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">A Novel SDN-Based Application-Awareness Mechanism by Using Deep Learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="160921" to="160930" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Discriminators for Use in Flow-Based Classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zuev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Crogan</surname></persName>
		</author>
		<ptr target="https://www.cl.cam.ac.uk/~awm22/publication/moore2005discriminators.pdf" />
		<imprint>
			<date type="published" when="2022-01-15">15 January 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Intelligent SDN traffic classification using deep learning: Deep-SDN</title>
		<author>
			<persName><forename type="first">A</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>De Fréin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Zeyadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Andreu-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 2nd International Conference on Computer Communication and the Internet (ICCCI)</title>
		<meeting>the 2020 2nd International Conference on Computer Communication and the Internet (ICCCI)<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-06-29">26-29 June 2020</date>
			<biblScope unit="page" from="184" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">QoS-aware traffic classification architecture using machine learning and deep packet inspection in SDNs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="1209" to="1216" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Network Traffic Classification Using Machine Learning for Software Defined Networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P J</forename><surname>Kuranage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Piamrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hamma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning for Networking</title>
		<meeting>the International Conference on Machine Learning for Networking<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-05">3-5 December 2019</date>
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Personalized service degradation policies on OTT applications based on the consumption behavior of users</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Rojas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Á</forename><forename type="middle">R</forename><surname>Gallón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Corrales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Science and Its Applications</title>
		<meeting>the International Conference on Computational Science and Its Applications<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07-05">2-5 July 2018</date>
			<biblScope unit="page" from="543" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Application-awareness in SDN</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">A</forename><surname>Qazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bellala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arndt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Noubir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGCOMM conference on SIGCOMM</title>
		<meeting>the ACM SIGCOMM conference on SIGCOMM<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08-16">12-16 August 2013</date>
			<biblScope unit="page" from="487" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">MultiClassifier: A combination of DPI and ML for application-layer classification in SDN</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Systems and Informatics (ICSAI)</title>
		<meeting>the 2nd International Conference on Systems and Informatics (ICSAI)<address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-11">November 2014</date>
			<biblScope unit="page" from="682" to="686" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Data traffic classification in Software Defined Networks (SDN) using supervised-learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Raikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Meena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Mulla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Shetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Karanandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="page" from="2750" to="2759" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">TrafficVision: A case for pushing software defined networks to wireless edges</title>
		<author>
			<persName><forename type="first">M</forename><surname>Uddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nadeem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)</title>
		<meeting>the 13th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)<address><addrLine>Brasilia, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-10-13">10-13 October 2016</date>
			<biblScope unit="page" from="37" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Application aware SDN architecture using semi-supervised traffic classification</title>
		<author>
			<persName><forename type="first">P</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bernardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mazandarani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN)</title>
		<meeting>the 2018 IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN)<address><addrLine>Verona, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11-29">27-29 November 2018</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Toward in-network deep machine learning for identifying mobile applications and enabling application specific network slicing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nakao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEICE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="1536" to="1543" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Deep learning based encrypted network traffic classification in sdn home gateway</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><surname>Datanet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="55380" to="55391" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Characterization of encrypted and vpn traffic using timerelated</title>
		<author>
			<persName><forename type="first">G</forename><surname>Draper-Gil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Lashkari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S I</forename><surname>Mamun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Ghorbani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Information Systems Security and Privacy (ICISSP)</title>
		<meeting>the 2nd International Conference on Information Systems Security and Privacy (ICISSP)<address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-02">February 2016</date>
			<biblScope unit="page" from="407" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Application-based online traffic classification with deep learning models on SDN networks</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Technol. Innov</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="216" to="229" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<ptr target="https://www.reinvention.be/webhdfs/v1/docs/complete-white-paper-c11-481360.pdf" />
		<title level="m">Cisco Visual Networking Index: Forecast and Methodology</title>
		<imprint>
			<date type="published" when="2016">2016-2021. 15 January 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">An intelligent system for video surveillance in IoT environments</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Canovas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Jiménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lloret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">100</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">An approach to enhance packet classification performance of software-defined network using deep learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Indira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Valarmathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Devaraj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">101</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Optimal 5G network slicing using machine learning and deep learning concepts</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Abidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Alkhalefah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Moiduddin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alazab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ameen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Gadekallu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stand. Interfaces</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="103518" to="103102" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Characterization of tor traffic using time based features</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Lashkari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Draper-Gil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S I</forename><surname>Mamun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Ghorbani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Information System Security and Privacy (ICISSP)</title>
		<meeting>the 3rd International Conference on Information System Security and Privacy (ICISSP)<address><addrLine>Porto, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-02-21">19-21 February 2017</date>
			<biblScope unit="page">103</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">A novel QUIC traffic classifier based on convolutional neural networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Souihi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mellouk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 IEEE Global Communications Conference (GLOBECOM)</title>
		<meeting>the 2018 IEEE Global Communications Conference (GLOBECOM)<address><addrLine>Abu Dhabi, UAE</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-12-13">9-13 December 2018</date>
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">A comparative analysis of gradient boosting algorithms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bentéjac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Csørgő</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Martínez-Muñoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Rev</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page">105</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Machine learning and software defined networks for high-density wlans</title>
		<author>
			<persName><forename type="first">Á</forename><surname>López-Raventós</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wilhelmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barrachina-Muñoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bellalta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.05534.106</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Machine-learning-based prediction and optimization of mobile metro-core networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alvizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Troia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pattavina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 IEEE Photonics Society Summer Topical Meeting Series (SUM)</title>
		<meeting>the 2018 IEEE Photonics Society Summer Topical Meeting Series (SUM)<address><addrLine>Waikoloa, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07-11">9-11 July 2018</date>
			<biblScope unit="page">107</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">ATLANTIC: A framework for anomaly traffic detection, classification, and mitigation in SDN</title>
		<author>
			<persName><forename type="first">A</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wickboldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Granville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schaeffer-Filho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/IFIP Network Operations and Management Symposium (NOMS)</title>
		<meeting>the IEEE/IFIP Network Operations and Management Symposium (NOMS)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-04-29">25-29 April 2016</date>
			<biblScope unit="page">108</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Predictive Flow Modeling in Software Defined Network</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Sairam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the TENCON 2019-2019 IEEE Region 10 Conference (TENCON)</title>
		<meeting>the TENCON 2019-2019 IEEE Region 10 Conference (TENCON)<address><addrLine>Kochi, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-10-20">17-20 October 2019</date>
			<biblScope unit="page">109</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">A neural network-based framework for traffic matrix prediction in SDN</title>
		<author>
			<persName><forename type="first">A</forename><surname>Azzouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pujolle</surname></persName>
		</author>
		<author>
			<persName><surname>Neutm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/IFIP Network Operations and Management Symposium (NOMS)</title>
		<meeting>the IEEE/IFIP Network Operations and Management Symposium (NOMS)<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-27">23-27 April 2018</date>
			<biblScope unit="page">110</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Matheuristic with machine-learning-based prediction for software-defined mobile metro-core networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Alvizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Troia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pattavina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Opt. Commun. Netw</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">111</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Research on load balance method in SDN</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen-Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ya-Bin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Grid Distrib. Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">112</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">An intelligent traffic load prediction-based adaptive channel assignment algorithm in SDN-IoT: A deep learning approach</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Fadlullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Things J</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">113</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Deep learning models for aggregated network traffic prediction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lazaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Prasanna</surname></persName>
		</author>
		<ptr target="https://www.youtube.com/watch?v=u8OKjyKqcV8&amp;list=RDqyvwOSHOpT8&amp;index=4" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 15th International Conference on Network and Service Management (CNSM)</title>
		<meeting>the 2019 15th International Conference on Network and Service Management (CNSM)<address><addrLine>Halifax, NS, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>CAIDA Anonymized Internet Traces</publisher>
			<date type="published" when="2016-01-15">21-25 October 2019. 2016. 2016. 15 January 2022</date>
			<biblScope unit="page">115</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">An AI-based Traffic Matrix Prediction Solution for Software-Defined Network</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Souihi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mellouk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICC 2021-IEEE International Conference on Communications</title>
		<meeting>the ICC 2021-IEEE International Conference on Communications<address><addrLine>Montreal, QC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-06-23">14-23 June 2021</date>
			<biblScope unit="page">116</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">A Forecasting Approach to Improve Control and Management for 5G Networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Senna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sargento</surname></persName>
		</author>
		<ptr target="http://www.cs.utexas.edu/~yzhang/research/AbileneTM/" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Netw. Serv. Manag</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">118</biblScope>
			<date type="published" when="2021-01-15">2021. 15 January 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Providing public intradomain traffic matrices to the research community</title>
		<author>
			<persName><forename type="first">S</forename><surname>Uhlig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Quoitin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lepropre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Balon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM Comput. Commun. Rev</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">119</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">A multi-source dataset of urban life in the city of Milan and the Province of Trentino</title>
		<author>
			<persName><forename type="first">G</forename><surname>Barlacchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Nadai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Larcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chitic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Torrisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Antonelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vespignani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lepri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Data</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">120</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Adversarial Deep Learning approach detection and defense against DDoS attacks in SDN environments</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Novaes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lloret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Proença</surname></persName>
		</author>
		<author>
			<persName><surname>Jr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Gener. Comput. Syst</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page">121</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Toward developing a systematic approach to generate benchmark datasets for intrusion detection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shiravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shiravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tavallaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Ghorbani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Secur</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">122</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m" type="main">Special Publication on Intrusion Detection Systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Base</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>NIST Infidel, Inc</publisher>
			<biblScope unit="page">123</biblScope>
			<pubPlace>Scotts Valley, CA, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Towards an efficient anomaly-based intrusion detection for software-defined networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Latah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Toker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Netw</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">124</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Machine learning-based IDS for Software-Defined 5G network</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Netw</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">125</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">AI-based two-stage intrusion detection for Software Defined IoT networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Things J</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">126</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<title level="m" type="main">Machine-learning techniques for detecting attacks in SDN</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Le-Khac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Jurcut</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.00817.127</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Deep recurrent neural network for intrusion detection in sdn-based networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mhamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mclernon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A R</forename><surname>Zaidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghogho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 4th IEEE Conference on Network Softwarization and Workshops (NetSoft)</title>
		<meeting>the 2018 4th IEEE Conference on Network Softwarization and Workshops (NetSoft)<address><addrLine>Montreal, QC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-29">25-29 June 2018</date>
			<biblScope unit="page">128</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Deep learning approach for intrusion detection in Software Defined Networking</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mhamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mclernon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A R</forename><surname>Zaidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghogho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>El Moussa</surname></persName>
		</author>
		<author>
			<persName><surname>Deepids</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1533" to="1129" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">A novel hybrid model for intrusion detection systems in SDNs based on CNN and a new regularization technique</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Le-Khac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Albahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jurcut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Netw. Comput. Appl</title>
		<imprint>
			<biblScope unit="volume">191</biblScope>
			<biblScope unit="page" from="103160" to="103130" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">A novel SDN intrusion dataset</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Le-Khac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Jurcut</surname></persName>
		</author>
		<author>
			<persName><surname>Insdn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="165263" to="165284" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Collaborative intrusion detection for VANETs: A deep learning-based distributed SDN approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guizani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">132</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Line-speed and scalable intrusion detection at the network edge via federated learning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Poularakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tassiulas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 IFIP Networking Conference (Networking)</title>
		<meeting>the 2020 IFIP Networking Conference (Networking)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-06-26">22-26 June 2020</date>
			<biblScope unit="page">133</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Detection and mitigation of DDoS attacks in SDN: A comprehensive review, research challenges and future directions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Behal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci. Rev</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="100279" to="100134" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Evaluation of machine learning techniques for security in SDN</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Harjula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ylianttila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ahmad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 IEEE Globecom Workshops (GC Wkshps)</title>
		<meeting>the 2020 IEEE Globecom Workshops (GC Wkshps)<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-11">7-11 December 2020</date>
			<biblScope unit="page">135</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">XGBoost classifier for DDoS attack detection and analysis in SDN-based cloud</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 IEEE International Conference on Big Data and Smart Computing (BIGCOMP)</title>
		<meeting>the 2018 IEEE International Conference on Big Data and Smart Computing (BIGCOMP)<address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-01-17">15-17 January 2018</date>
			<biblScope unit="page">136</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<monogr>
		<author>
			<persName><forename type="first">Q</forename><surname>Niyaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Javaid</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07400.137</idno>
		<title level="m">A deep learning based DDoS detection system in software-defined networking (SDN)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Detection and defense of DDoS attack-based on deep learning in OpenFlow-based SDN</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Commun. Syst</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">138</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">A deep CNN ensemble framework for efficient DDoS attack detection in software defined networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Akhunzada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mustafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K R</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Iqbal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">139</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Multi-plane security framework for software defined networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Duttagupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Achuthan</surname></persName>
		</author>
		<author>
			<persName><surname>Varman</surname></persName>
		</author>
		<ptr target="http://kdd.ics.uci.edu/databases/kddcup99/kddcup99" />
	</analytic>
	<monogr>
		<title level="m">KDD Cup 1999</title>
		<imprint>
			<date type="published" when="2019-11-07">2019. 7 November 2021</date>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page">141</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">A detailed analysis of the KDD CUP 99 data set</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tavallaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Ghorbani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 IEEE Symposium on Computational Intelligence for Security and Defense Applications</title>
		<meeting>the 2009 IEEE Symposium on Computational Intelligence for Security and Defense Applications<address><addrLine>Ottawa, ON, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-07-10">8-10 July 2009</date>
			<biblScope unit="page">142</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Industrial control system traffic data sets for intrusion detection research</title>
		<author>
			<persName><forename type="first">T</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Critical Infrastructure Protection</title>
		<meeting><address><addrLine>Berlin/Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">143</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">A comprehensive data set for network intrusion detection systems (UNSW-NB15 network data set)</title>
		<author>
			<persName><forename type="first">N</forename><surname>Moustafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Slay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Military Communications and Information Systems Conference (MilCIS)</title>
		<meeting>the 2015 Military Communications and Information Systems Conference (MilCIS)<address><addrLine>Canberra, ACT, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-11-12">10-12 November 2015</date>
			<biblScope unit="page">144</biblScope>
		</imprint>
	</monogr>
	<note>UNSW-NB15</note>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Toward generating a new intrusion detection dataset and intrusion traffic characterization</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sharafaldin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Lashkari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Ghorbani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Confer-Ence Inf. Syst. Secur. Priv. (ICISSP)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">145</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">All eyes on you: Distributed Multi-Dimensional IoT microservice anomaly detection</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Pahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">X</forename><surname>Aubet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 14th International Conference on Network and Service Management (CNSM)</title>
		<meeting>the 2018 14th International Conference on Network and Service Management (CNSM)<address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11-09">5-9 November 2018</date>
			<biblScope unit="page">146</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">New Generations of Internet of Things Datasets for Cybersecurity Applications based Machine Learning: TON_IoT Datasets</title>
		<author>
			<persName><forename type="first">N</forename><surname>Moustafa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eResearch Australasia Conference</title>
		<meeting>the eResearch Australasia Conference<address><addrLine>Brisbane, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-10-25">21-25 October 2019</date>
			<biblScope unit="page">147</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">A two-level flow-based anomalous activity detection system for IoT networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Ullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">H</forename><surname>Mahmoud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="530" to="148" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Two Decades of AI4NETS-AI/ML for Data Networks: Challenges &amp; Research Directions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Casas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/IFIP Network Operations and Management Symposium (NOMS)</title>
		<meeting>the IEEE/IFIP Network Operations and Management Symposium (NOMS)<address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-24">20-24 April 2020</date>
			<biblScope unit="page">149</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">On the effectiveness of preprocessing methods when dealing with different levels of class imbalance</title>
		<author>
			<persName><forename type="first">V</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mollineda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl.-Based Syst</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">150</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">A review of class imbalance problem</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Abd Elrahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</author>
		<ptr target="http://spark.apache.org/" />
	</analytic>
	<monogr>
		<title level="j">J. Netw. Innov. Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">152</biblScope>
			<date type="published" when="2013-01-15">2013. 15 January 2022</date>
		</imprint>
	</monogr>
	<note>Apache Spark</note>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">A survey on deep transfer learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<meeting><address><addrLine>Cham, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="270" to="279" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
