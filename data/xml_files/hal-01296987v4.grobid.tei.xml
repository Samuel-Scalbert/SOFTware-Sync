<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Well-Understood Single-Objective Functions in Multiobjective Black-Box Optimization Test Suites</title>
				<funder ref="#_VCBHSeE #_9MCY4Wu">
					<orgName type="full">Slovenian Research Agency</orgName>
				</funder>
				<funder ref="#_xw7dJ6K">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_PRRqpv8">
					<orgName type="full">European Commission</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dimo</forename><surname>Brockhoff</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anne</forename><surname>Auger</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nikolaus</forename><surname>Hansen</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Ecole Polytechnique</orgName>
								<orgName type="laboratory">CMAP</orgName>
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Ecole Polytechnique</orgName>
								<orgName type="laboratory">CMAP</orgName>
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Ecole Polytechnique</orgName>
								<orgName type="laboratory">CMAP</orgName>
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">Institut Polytechnique de Paris</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Jo≈æef Stefan Institute</orgName>
								<address>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Using Well-Understood Single-Objective Functions in Multiobjective Black-Box Optimization Test Suites</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F47AD9E06D0A51A423AC52E629EDFD0E</idno>
					<idno type="DOI">10.1162/evco_a_00298</idno>
					<note type="submission">accepted for publication in Evolutionary Computation.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-07T09:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Black-box optimization benchmarking</term>
					<term>multiobjective optimization</term>
					<term>algorithm comparison</term>
					<term>benchmark suite generator</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Several test function suites are being used for numerical benchmarking of multiobjective optimization algorithms. While they have some desirable properties, like wellunderstood Pareto sets and Pareto fronts of various shapes, most of the currently used functions possess characteristics that are arguably under-represented in real-world problems such as separability, optima located exactly at the boundary constraints, and the existence of variables that solely control the distance between a solution and the Pareto front. Via the alternative construction of combining existing single-objective problems from the literature, we describe the bbob-biobj test suite with 55 biobjective functions in continuous domain, and its extended version with 92 biobjective functions (bbob-biobj-ext). Both test suites have been implemented in the COCO platform for black-box optimization benchmarking and various visualizations of the test functions are shown to reveal their properties. Besides providing details on the construction of these problems and presenting their (known) properties, this paper also aims at giving the rationale behind our approach in terms of groups of functions with similar properties, objective space normalization, and problem instances. The latter allows us to easily compare the performance of deterministic and stochastic solvers, which is an often overlooked issue in benchmarking.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Numerical benchmarking is an important part of (black-box) optimization that helps to understand algorithm behavior and recommend algorithms. In order to obtain meaningful results, a benchmarking experiment should be (i) based on a thorough, welldocumented and well-understood methodology and (ii) either be conducted on realworld problems of interest or a collection of artificial test functions that possess comprehensible difficulties observed in practical optimization problems. This holds true for both single-and multiobjective problems but for the latter, the methodology is less advanced at the moment.</p><p>Many artificial test functions that are frequently used in multiobjective optimization have been derived by setting up the Pareto front shape first without relating it to the intrinsic difficulties of the objective functions. Such an approach has the advantage that the analytical forms of the Pareto front and the Pareto set can be exploited to facilitate the performance assessment. Another aspect of state-of-the-art test suites for multiobjective optimization is the fact that not much progress has been made to avoid the overrepresentation of functions that are too simple or have questionable properties. Several existing (and still frequently used) multiobjective test suites, for example, contain a large share of functions that are separable, have the Pareto set on the domain boundary, or contain distance and position variables<ref type="foot" target="#foot_0">1</ref> -artificial features not reflecting well the difficult black-box problems observed in practice.</p><p>In the context of single-objective algorithm benchmarking, a lot of progress has been made in recent years in the design of artificial test functions that represent a wide range of difficulties observed in practice. The black-box optimization benchmarking test suite <ref type="bibr">(bbob, Hansen et al. (2009)</ref>) in particular has received wide acceptance as its 24 test functions have various advantages over previous test suites. The functions are well understood and expose algorithms to a variety of real-world difficulties such as multimodality, ill-conditioning, non-separability of the variables, and non-linearities. The bbob functions are grouped into five function groups with functions within a group sharing similar difficulties (such as multimodality with weak global structure) and with the aim to not overemphasize certain difficulties. Each function has one or several concrete scientific questions associated with it that can be answered by looking at algorithm performance results on that function (or in combination with another function). General statements beyond the tested concrete functions are possible by testing invariance properties of algorithms such as scaling, rotation and affine invariance. In contrast to the previously mentioned approaches to building multiobjective test suites, we suggest to focus on introducing the known difficulties of real-world problems into the test suite. This is analogous to the single-objective case, but has the disadvantage that analytical formulas for the Pareto front and Pareto set might not be available. The motivation behind this approach is that in practice, multiobjective problems are constructed in exactly this way-with each objective corresponding to a separate single-objective function. Concretely, we propose a generic way to combine the well-established and -understood single-objective functions from the bbob test suite <ref type="bibr" target="#b18">(Hansen et al., 2009)</ref>. Using the bbob test functions as building blocks allows us to build upon a careful statistical choice of the functions (without overrepresenting a certain type of problem) as well as comprehensive difficulties. In turn, the proposed multiobjective functions are more likely to be practically relevant than previous benchmarks. In particular, our proposal fulfills all five recommendations for benchmark suites mentioned by <ref type="bibr">Huband et al. (2006, page 485)</ref>, see also Section 3. We showcase our idea by implementing two biobjective test suites within the COCO platform <ref type="bibr" target="#b20">(Hansen et al., 2021)</ref> that supports automated benchmarking. The implementation within the COCO platform has two important advantages over many other existing test suites: (1) numerical experiments can be done more easily by automation, and, even more importantly, (2) it is possible to compare new results with a large variety of already benchmarked algorithms and to share the results effortlessly. As of end of 2020, the results of 32 algorithm implementations 2 have been collected and made available online 3 .</p><p>The lack of analytical expressions for the Pareto sets and fronts in our approach is addressed by collecting and visualizing approximations from numerical experiments with a large variety of algorithms. The collected hypervolume values are available online for performance assessment 4 . To understand the quality of the reference Pareto set approximations, we investigate necessary optimality conditions in Section 6. We also provide dominance-and gradient-based plots to gain additional insight into the problem properties.</p><p>The non-existence of analytical forms of Pareto set and Pareto front in our approach can be even seen as an advantage: the combination of existing single-objective test functions allows, in a controlled way, to mimic the typical constructions of realworld problems and to empirically investigate the resulting Pareto set and Pareto front shapes from such constructions. Moreover, the proposed multiobjective benchmark functions come in the form of pseudo-random instances, which allows to more easily compare deterministic and stochastic approaches and makes it possible to investigate the variance of properties like a connected or convex Pareto front emanating from the combination of single-objective test functions.</p><p>The contributions of this paper are: (i) the purposeful choice of single-objective functions and their combinations into biobjective problems, (ii) cherry-picking instances to avoid pathological combinations, (iii) a classification of the problems, (iv) implementation of two suites for the COCO platform, (v) identifying problem attributes and properties, (vi) provision of Pareto set approximations with an analysis of their quality, (vii) various visualizations of the constructed functions (see also the supplementary material 5 ), (viii) empirical identification of target values, and (ix) a guide to performance assessment.</p><p>The paper is organized as follows. We start by outlining the fundamental definitions in multiobjective optimization and benchmarking in Section 2 and review multiobjective benchmark suites and their properties in Section 3. Section 4 introduces the main concepts behind the single-objective bbob test suite with more details given in the appendix. Section 5 proposes the bbob-biobj and bbob-biobj-ext test suites which are then analyzed visually in Section 6. The paper concludes with a discussion of how to report algorithm performance data in Section 7 and final remarks in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>We consider biobjective, unconstrained minimization problems of the form</p><formula xml:id="formula_0">min x‚ààR n F (x) = (f Œ± (x), f Œ≤ (x)),</formula><p>where n is the number of variables of the problem (also called the problem dimension), f Œ± : R n ‚Üí R and f Œ≤ : R n ‚Üí R are the two objective functions, and the min operator is 2 Updated list of algorithm data sets: https://numbbo.github.io/data-archive/bbob-biobj/.</p><p>3 Postprocessed performances of most available algorithms are displayed online at https:// numbbo.github.io/ppdata-archive/bbob-biobj/2016-all/ and https://numbbo.github. io/ppdata-archive/bbob-biobj/2019-all/.</p><p>4 The best known hypervolume values for all supported test instances are available via the COCO platform at https://github.com/numbbo/coco/blob/master/code-experiments/src/suite_ biobj_best_values_hyp.c. To create these hypervolume "reference" values, we relied on data from a large variety of numerical experiments-for details, see Section 6.1.</p><p>5 Webpage with supplementary material: https://numbbo.github.io/bbob-biobj.</p><p>Evolutionary Computation Volume x, Number x related to the standard dominance relation. A solution x ‚àà R n is thereby said to dominate another solution y ‚àà R n if f Œ± (x) ‚â§ f Œ± (y) and f Œ≤ (x) ‚â§ f Œ≤ (y) hold and at least one of the inequalities is strict. We adopt the notation f Œ± for the first objective (resp. f Œ≤ for the second objective) instead of f 1 and f 2 to avoid confusion with notations adopted within the single-objective bbob test suite. Solutions which are not dominated by any other solution are called Pareto-optimal or efficient solutions. All Pareto-optimal solutions constitute the Pareto set of which an approximation is sought. The Pareto set's image in the objective space F (R n ) is called the Pareto front. Two specific points in the objective space are important to mention:</p><p>‚Ä¢ The ideal point defined as the vector in objective space that contains the optimal F -value for each objective independently. More precisely, if</p><formula xml:id="formula_1">f opt Œ± := inf x‚ààR n f Œ± (x) and f opt Œ≤ := inf x‚ààR n f Œ≤ (x), the ideal point is given by z ideal = (f opt Œ± , f opt Œ≤ ).</formula><p>‚Ä¢ The nadir point (in objective space) consisting in each objective of the worst value obtained by a Pareto-optimal solution. More precisely, if we denote the Pareto set by P, the nadir point satisfies</p><formula xml:id="formula_2">z nadir = (sup x‚ààP f Œ± (x), sup x‚ààP f Œ≤ (x)) .</formula><p>In the specific case where each of the two objective functions has a unique global minimum (that is, a single point in the search space which maps to the global minimum function value),</p><formula xml:id="formula_3">z nadir = (f Œ± (arg min f Œ≤ (x)), f Œ≤ (arg min f Œ± (x))) .</formula><p>All given definitions generalize trivially to problems with more than two objectives. When solving an unconstrained multiobjective problem as the above, usually the goal is to find, with as few evaluations of F as possible, a set of non-dominated solutions which is (i) as large as possible and (ii) has objective values as close to the Pareto front as possible <ref type="foot" target="#foot_2">6</ref> . Here, we define this optimization goal via the maximization of a quality indicator, namely, the hypervolume <ref type="bibr" target="#b41">(Zitzler et al., 2003)</ref> of the set of all non-dominated solutions found so far <ref type="bibr" target="#b4">(Brockhoff et al., 2016)</ref>.</p><p>In this context, an optimization algorithm addressing the above minimization problem is given an instance of F : we implement each generic multiobjective function F as a parametrized function F Œ∏ : R n ‚Üí R m with a problem dimension n and a parameter value Œ∏ ‚àà Œò that might depend on n and m = 2, the number of objectives. The parameter value Œ∏ determines a function instance. For example, Œ∏ can encode the location of the optimum, x opt Œ± , of the first objective f Œ∏ Œ± : R n ‚Üí R with f</p><formula xml:id="formula_4">x opt Œ± Œ± (x) = ||x -x opt Œ± || 2 .</formula><p>Search space rotations and shifts in the objective values are other generic transformations that can be encoded in instances <ref type="bibr" target="#b20">(Hansen et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Review of Existing Multiobjective Test Suites</head><p>Many multiobjective test suites have been proposed throughout the years. Here, we in particular discuss those that are scalable in the problem dimension and that are unconstrained or box-constrained and defined in the continuous domain-the focus of our proposal for a new benchmark suite.</p><p>The (evolutionary) multiobjective optimization field first performed numerical comparisons of algorithms on single, independently proposed test problems like those by <ref type="bibr" target="#b29">Kursawe (1990)</ref> and <ref type="bibr" target="#b15">Fonseca and Fleming (1995)</ref>, see for example <ref type="bibr" target="#b34">Tan et al. (2002)</ref>, or in real-world studies, see <ref type="bibr" target="#b36">Van Veldhuizen and Lamont (1998)</ref> for an early overview.</p><p>A first attempt to create a consistent multiobjective test suite with several problems with desired properties was, to the best of our knowledge, the work of <ref type="bibr">Van Veldhuizen and Lamont (1999b,a)</ref>. The authors clearly stated the need for scalable test suites and emphasized that problems of a test suite should possess practically relevant features. In the years that followed, several other scalable test suites have been proposed, of which the most established ones are (i) the ZDT suite of <ref type="bibr" target="#b40">Zitzler et al. (2000)</ref>, scalable in the number of variables but with only two objectives, (ii) its rotated version, the IHR problem suite of <ref type="bibr" target="#b26">Igel et al. (2007)</ref>, (iii) the DTLZ suite of <ref type="bibr" target="#b9">Deb et al. (2005)</ref>, with seven problems, all scalable in the number of variables and objectives, (iv) the WFG suite of <ref type="bibr" target="#b25">Huband et al. (2006)</ref> with nine scalable problems of various difficulties, (v) the LZ suite of <ref type="bibr" target="#b30">Li and Zhang (2009)</ref> containing problems with more complicated Pareto sets, (vi) the CEC2007 suite, combining and extending 13 existing test functions from the literature <ref type="bibr" target="#b24">(Huang et al., 2007)</ref>, (vii) the CEC2009 suite with 13 problems overall <ref type="bibr" target="#b39">(Zhang et al., 2009)</ref>, and finally (viii) the CEC2017 suite with 15 collected problems, tailored towards many-objective optimization <ref type="bibr" target="#b5">(Cheng et al., 2017)</ref>.</p><p>Most of these test suites have some desirable properties like well-understood Pareto sets and Pareto fronts with shapes of various kinds (linear, convex, concave, discontinuous). But they also possess artificial characteristics that stem from the easier construction of such problems-overrepresenting properties such as no or only few dependencies among variables, Pareto sets located exactly at the boundary constraints, and the differentiation between position and distance variables. Although, for example, the importance of non-separable test functions in single-objective test suites is unquestioned and even <ref type="bibr">Deb (2001, p.353f</ref>) states its significance, most proposed multiobjective test problems are still separable or mostly separable in the sense that a function is separable if it can be optimized variable by variable.</p><p>Another way of generating multiobjective test problems is to decide on the single objectives and simply combine them to a multiobjective problem. Examples for this are the double sphere or Schaffer function number 1 <ref type="bibr" target="#b33">(Schaffer, 1985)</ref>, the combination of convex quadratic functions such as ellipsoids and cigtab functions by <ref type="bibr" target="#b26">Igel et al. (2007)</ref> or the multimodal functions based on spherical functions by <ref type="bibr" target="#b11">Emmerich and Deutz (2007)</ref>, the latter construction of which has been extended by <ref type="bibr" target="#b28">Kerschke et al. (2016)</ref>.</p><p>Even though all test suites in the above list are scalable in the problem dimension, we rarely see performance studies that investigate the scaling of the algorithms with the problem dimension.</p><p>The arguably most complete paper on the topic of multiobjective benchmark problems to date is still the work of <ref type="bibr" target="#b25">Huband et al. (2006)</ref> where the authors (i) identify important properties test functions should have, (ii) discuss in detail all other available test suites at that time with respect to these properties, and (iii) finally propose a new, well-motivated test suite that avoids many pitfalls of other test suites. In particular, <ref type="bibr">Huband et al. (see Huband et al. (2006)</ref>, page 485) recommend that multiobjective test suites should, in addition to recommendations for single-objective test suites:</p><p>1. contain a few unimodal test problems to test convergence velocity relative to different Pareto optimal geometries and bias conditions, 2. cover the three core types of Pareto optimal geometries: degenerate Pareto optimal fronts, disconnected Pareto optimal fronts, and disconnected Pareto optimal sets, 3. have a majority of its test problems multimodal with a few deceptive problems, 4. have the majority of problems nonseparable, and Evolutionary Computation Volume x, Number x 5. contain problems that are both nonseparable and multimodal to be representative of real-world problems.</p><p>All five recommendations are fulfilled for the test suites proposed in this paper. Similar to the single-objective bbob functions, the WFG suite of <ref type="bibr" target="#b25">Huband et al. (2006)</ref> employs problem transformations that change the properties like (non-)separability, bias, and the shape of the Pareto front of underlying raw objective functions.</p><p>One common property of the above mentioned test suites is that their Pareto sets can be described in analytical form. This certainly has an advantage for performance assessment but it also restricts the types of real-world problem characteristics that can be captured with such functions.</p><p>However, in practice, multiobjective optimization problems are typically constructed by combining objective functions that are defined (and understood) independently such as cost and performance of a new product. The objective functions might thereby come from different domains and share or do not share common properties such as uni-/multimodality, (non-)separability, asymmetry, etc.</p><p>The idea of defining multiobjective test problems by combining single-objective ones is therefore straightforward and has been proposed before, as mentioned above, for example in <ref type="bibr" target="#b33">(Schaffer, 1985)</ref>, <ref type="bibr" target="#b26">(Igel et al., 2007)</ref>, <ref type="bibr" target="#b11">(Emmerich and Deutz, 2007)</ref> or <ref type="bibr" target="#b23">(Horn et al., 2015)</ref>. To create a benchmark suite with challenging properties observed in practice, we follow here the same path and combine some of the existing, well-established, well-understood functions of the bbob test suite to create new multiobjective suites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Single-Objective bbob Functions</head><p>Our multiobjective test suites build on the single-objective bbob function suite <ref type="bibr" target="#b18">(Hansen et al., 2009;</ref><ref type="bibr" target="#b13">Finck et al., 2009)</ref>. The bbob suite includes unimodal and multimodal test functions, separable and non-separable functions, well-conditioned and ill-conditioned problems, see Appendix A for a short definition of those properties. Each function is parametrized (see Section 2) and is scalable with respect to the dimension. Some function pairs allow to answer specific questions: for instance, the ellipsoid and the Rastrigin functions are present in a separable and a non-separable version such that one can investigate how much an algorithm exploits separability. The functions are unbounded but the search domain of interest is [-5, 5] n . Except for the linear slope function f 5 , the optimum of each function lies in the hypercube <ref type="bibr">[-4, 4]</ref> n for all instances and all dimensions. The optimum of the linear function is attained at a (randomly chosen) corner of the hypercube [-5, 5] n and in the orthant beyond this point.</p><p>The bbob test suite has 24 functions, split into five groups. The Separable group contains five separable functions, the Moderate group consists of four functions with low or moderate conditioning, including multimodal functions, the Ill-conditioned functions group contains five unimodal functions with high conditioning, the Multimodal functions group comprises five multimodal functions with adequate global structure, and the Weakly-structured group consists of five multimodal functions with weak global structure. Problem difficulty is typically increasing from the first to the last group, but there are exceptions, for example, solving the B √ºche-Rastrigin function from the first group is difficult for most algorithms. The manually assigned function groups are also used to aggregate performance, allowing to make meaningful statements about the performance on functions with specific properties reflected by the groupings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">The Proposed Biobjective Test Suites</head><p>Given the well-motivated bbob functions from <ref type="bibr" target="#b18">Hansen et al. (2009)</ref>, it is natural to construct a multiobjective test suite from these single-objective functions. For the biobjective case, a pairwise combination of all 24 functions results in 24 2 = 576 biobjective functions. We however assume that multiobjective optimization algorithms are not sensitive to permutations of the objectives, so that we do not include</p><formula xml:id="formula_5">F = (f Œ≤ , f Œ± ) if (f Œ± , f Œ≤ )</formula><p>is already present<ref type="foot" target="#foot_5">7</ref> . This results in the total of 25 2 = 300 function combinations-the number of 2-combinations drawn with replacement.</p><p>While a benchmarking suite should contain a large number of different problems to avoid overfitting, first tests in <ref type="bibr" target="#b3">Brockhoff et al. (2015)</ref> showed that having 300 functions is impracticable in terms of the overall running time of a benchmarking experiment. Therefore, a subset of these 300 functions was selected.</p><p>We present two such selections-the bbob-biobj test suite with 55 functions and its extension, the bbob-biobj-ext test suite with 92 functions. We also provide visualizations for some of the functions, showing different Pareto set and front shapes. Plots for all 92 functions are provided via the supplementary material webpage 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">The bbob-biobj Test Suite</head><p>The biobjective bbob-biobj test suite is created by exploiting the organization of the bbob functions into groups. More precisely, only two (representative) functions from each of the bbob function groups are chosen. This way, we do not introduce any bias towards a specific group. In addition, within each group, the functions are chosen to be the most representative without repeating similar functions. For example, only one ellipsoid, one Rastrigin, and one Gallagher function are included in the bbob-biobj suite although they appear in multiple versions in the bbob suite.</p><p>These ten bbob functions are chosen to create the bbob-biobj test suite:</p><p>‚Ä¢ From the separable functions group: sphere function f 1 and separable ellipsoid function f 2 .</p><p>‚Ä¢ From the functions with low or moderate conditioning: attractive sector function f 6 and original Rosenbrock function f 8 .</p><p>‚Ä¢ From the unimodal functions with high conditioning: sharp ridge function f 13 and sum of different powers function f 14 .</p><p>‚Ä¢ From the multimodal functions with adequate global structure: Rastrigin function f 15 and Schaffer F7 function with condition number 10 f 17 .</p><p>‚Ä¢ From the multimodal functions with weak global structure: Schwefel x sin x function f 20 and Gallagher 101 peaks function f 21 .</p><p>Using the previously described pairwise combinations, this results in 11 2 = 55 biobjective functions for the final bbob-biobj suite, denoted as F 1 to F 55 in the rest of the paper. Figure <ref type="figure" target="#fig_1">1</ref> visualizes these combinations of the chosen single-objective bbob functions f 1 , f 2 , f 6 , f 8 , f 13 , f 14 , f 15 , f 17 , f 20 , and f 21 to the 55 bbob-biobj functions and color-codes the resulting 15 function groups, for example the group of separableill-conditioned functions (F 5 , F 6 , F 14 , F 15 ) where one objective comes from the separable and the other objective comes from the ill-conditioned bbob function group.   All bbob-biobj functions are scalable in the search space dimension and come in the form of instances as it is the case with the original bbob suite.</p><formula xml:id="formula_6">F1 F2 F3 F4 F5 F6 F7 F8 F9 F10 F11 F12 F13 F14 F15 F16 F17 F18 F19 F20 F21 F22 F23 F24 F25 F26 F27 F28 F29 F30 F31 F32 F33 F34 F35 F36 F37 F38 F39 F40 F41 F42 F43 F44 F45 F46 F47 F48 F49 F50 F51 F52</formula><p>In the following, we specify the common properties of the bbob-biobj functions and the main rationale behind them while concrete details on each of the 55 functions are provided via the supplementary material webpage 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Function Domain</head><p>Since we use the single-objective bbob functions to construct the bbob-biobj suite, all functions are unbounded and the extreme solutions of the Pareto set are guaranteed to lie within [-5, 5] n .</p><p>Note that the Pareto set can partially lie outside of this area but that the major part of the Pareto set is expected to lie within it. Initial experiments found Pareto set approximations to be partially outside of the hypercube [-5, 5] n on a few functions in low dimensions, see also Section 6.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Normalization of Objectives</head><p>None of the 55 bbob-biobj functions is explicitly normalized and the optimization algorithms therefore have to cope with objective values in different ranges. Typically, different orders of magnitude between the objective values can be observed.</p><p>However, to assess performance on the test suites, we normalize the objectives based on the ideal and nadir points before calculating the hypervolume indicator <ref type="bibr" target="#b4">(Brockhoff et al., 2016)</ref>. Both points can be computed, because the unique global optimum is known for the used 10 bbob base functions. In the black-box optimization benchmarking setup of the COCO platform, the algorithm is allowed to use the values of the nadir point as an upper bound on a region of interest in objective space but no other normalization is directly available to the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Instances</head><p>Our proposed test functions are parametrized and their instances are instantiations of the underlying parameters of the bbob functions (see <ref type="bibr" target="#b20">Hansen et al., 2021)</ref>  8 . In addition, we assert two conditions:</p><p>1. The Euclidean distance between the two single-objective optimal solutions (also called the extreme solutions) in the search space is at least 10 -4 .</p><p>2. The Euclidean distance between the ideal and the nadir point in the nonnormalized objective space is at least 10 -1 .</p><p>Each function instance has an integer ID. The relation between the instance ID, K F ID , of a biobjective function F = (f Œ± , f Œ≤ ) and the instance IDs, K fŒ± ID and K</p><formula xml:id="formula_7">f Œ≤ ID , of its underlying single-objective functions is K fŒ± ID = 2K F ID + 1 and K f Œ≤ ID = K fŒ± ID + 1.</formula><p>If the two above conditions are not satisfied for all dimensions and functions in the bbob-biobj suite, we increase the instance ID of the second objective successively until both properties are fulfilled. Exceptions to the above rule are, for historical reasons, the bbob-biobj instance IDs 1 and 2 which contain the single-objective instance IDs 2 and 4 and the IDs 3 and 5, respectively. This results in the same instances 1 to 5 here and in <ref type="bibr" target="#b3">Brockhoff et al. (2015)</ref>.</p><p>An implementation of the above procedure is in effect a test function generator. Yet we emphasize that the generated instances of a parametrized function are meant to represent problems with similar difficulties. In the following, we only use a small number of fixed instances: for each biobjective function and given dimension, the bbob-biobj suite contains by default 15 instances 9 , which are chosen in advance and will remain fixed for a long period of time for comparability reasons 10 .</p><p>Problem instances in the multiobjective case tend to differ more wildly than in the single-objective case. Even when for each single objective the different instances are similar, different combinations of them can result in very different shapes of the Pareto front (for example continuous vs. discontinuous) or in different difficulties to solve such problems (the orientation of level sets, for example, might be in accordance between the objectives or perpendicular-resulting in significantly different multiobjective problems when two ill-conditioned functions are combined) 11 . Additionally, for 8 Performing numerical benchmarking experiments on a set of different instances of a parametrized function instead of experiments on a single fixed function has an immediate advantage: deterministic algorithms and stochastic algorithms can be compared easily in the same way stochastic algorithms are naturally compared. Running a deterministic algorithm on different instances of the same parametrized function introduces stochasticity of the runtime to reach certain target difficulties among runs in the same way as the combined stochasticity from the instance generation and the random events within a stochastic algorithm. Care, however, has to be taken that the variation of problem difficulty among instances is relatively low compared to the variation of difficulty between the actual benchmark functions. This assumption does not always hold for all instances of highly multimodal functions or for instances of most combinatorial optimization problems. 9 In principle, as for the instance generation for the bbob suite, the number of possible instances for the bbob-biobj suite is unlimited <ref type="bibr" target="#b20">(Hansen et al., 2021)</ref>. However, even the tiniest performance difference can be made statistically significant with a high enough number of instances and repetition.</p><p>10 Another reason to fix the instances for a long(er) time period is that no analytical form of the Pareto sets and Pareto fronts is available such that (good enough) Pareto set approximations need to be available for all instances for a proper performance assessment of algorithms. 11 We have observed performance differences of up to two orders of magnitude (in the number of function evaluations to reach a certain hypervolume indicator precision) between instances in some cases. Differences Evolutionary Computation Volume x, Number x very different instances the target levels defined for the performance assessment may become incomparable. Consequently, we estimate the Pareto set's hypervolume per instance and do not adopt the technique from the single-objective case to aggregate results from different instances by simulated restarts <ref type="bibr" target="#b20">(Hansen et al., 2021)</ref> to estimate runtimes to target values unattained on a given instance. The second reason to discard simulated restarts in the multiobjective case is the performance evaluation setup in COCO: we measure performance based on the entire archive of all so-far-evaluated solutions. Runs on different instances however produce incompatible archives, hence simulated restarts cannot account for the hypervolume attained by previous runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">The bbob-biobj-ext Test Suite</head><p>Having all combinations of only a subset of the single-objective bbob functions in a test suite like the above bbob-biobj one has also a few disadvantages. Using only a subset of the 24 bbob functions introduces a bias towards the chosen functions and reduces the variety of difficulties a biobjective algorithm is exposed to. Allowing all combinations of (a subset of the) bbob functions also increases the percentage of problems for which both objectives are from different bbob function groups. In practice, however, both objective functions may often come from a similar "function domain".</p><p>The rationale behind the extended test suite, denoted as bbob-biobj-ext, is to reduce the mentioned effects. To this end, we add all within-group combinations of bbob functions which are not already in the bbob-biobj suite and which do not combine a function with itself. For technical reasons, we also remove the Weierstrass function f 16 because its optimum is not necessarily unique and computing the nadir point is more challenging. This extension adds 3‚Ä¢(4+3+2+1-1)+2‚Ä¢(3+2+1-1) = 3‚Ä¢9+2‚Ä¢5 = 37 functions, resulting in 92 functions overall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">The bbob-biobj-ext Functions and Function Groups</head><p>Figure <ref type="figure">2</ref> details the single-objective bbob function combinations contained in the 92 bbob-biobj-ext functions. The first 55 bbob-biobj-ext functions are the same as in the bbob-biobj test suite for compatibility reasons. We still obtain 15 function groups to structure the 92 biobjective functions of the bbob-biobj-ext test suite. Depending on whether a function group combines functions from the same or from different bbob function groups, the new groups contain eight, 12 or just four functions.</p><p>The concrete function definitions are given in the supplementary material 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Normalization and Instances</head><p>Normalization of the objectives and instances for the bbob-biobj-ext test suite are handled in the same manner as for the bbob-biobj suite, i.e., the objective functions are not normalized and 15 instances are prescribed for a typical experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Reference Implementation</head><p>Both the bbob-biobj and the bbob-biobj-ext suites have been implemented in the COCO platform which is freely available and supports access in various programming languages (Python, C/C++, Java, Matlab/Octave). After installation of COCO 12 , this is as easy as typing (here in an IPython shell):</p><p>of more than one order of magnitude happen in maximally 30% of the function/dimension pairs with typical algorithms on the proposed bbob-biobj test suite. Due to the higher amount of multimodal functions in the bbob-biobj-ext suite, differences among instances are more common.</p><p>12 Besides downloading the code, installation of the experiments part with access to the function suites is a single call python do.py build-LANGUAGEOFINTEREST.  </p><formula xml:id="formula_8">F1 F2 F56 F57 F58 F3 F4 F5 F6 F7 F8 F9 F10 F11 F59 F60 F61 F12 F13 F14 F15 F16 F17 F18 F19 F62 F63 F64 F20 F65 F21 F66 F22 F23 F24 F25 F26 F27 F67 F68 F28 F69 F29 F30 F31 F32 F33 F34 F70 F71 F72 F73 F74 F75 F76 F77 F78 F35 F36 F37 F38 F39 F40 F41 F42 F43 F44 F45 F46 F47 F79 F80 F48 F49 F50 F81 F82 F51 F52 F83 F53 F54 F84 F85 F86 F55 F87 F88 F89</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Insights into Problem Properties</head><p>In order to better understand the functions in the bbob-biobj and bbob-biobj-ext suites, we visualize and analyze their properties. We display their best known Pareto set and Pareto front approximations together with 1-dimensional search space cuts in Section 6.1, investigate a necessary optimality condition in Section 6.2, and provide 2-dimensional dominance-based (Section 6.3) and gradient-based plots (Section 6.4) known from the literature for all proposed functions. All discussed plots are available online at the supplementary material webpage 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evolutionary Computation Volume x, Number x</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Plots of Pareto Set and Front Approximations</head><p>In this section, we plot the best currently known approximations of the Pareto set and the Pareto front, obtained from running many algorithms and collecting the nondominated solutions, evaluated during those runs 13 .</p><p>Figure <ref type="figure" target="#fig_4">3</ref> shows exemplary plots for three functions of the bbob-biobj suite in dimension 5: the double sphere function We provide four different plots for each function: the top row of Figure <ref type="figure" target="#fig_4">3</ref> shows the projection onto an axes-parallel cut of the search space defined by two variables (x 1 and x 4 here). The second row shows the projection onto a random plane that contains both single-objective optima 14 and gives contour lines for each objective function. The coordinate system is chosen such that the two optima lie on the first axis and their geometric center is the origin. The third row depicts the same data in the objective space in original scaling (as seen by the algorithm), while the last row shows the same in log-scale, normalized so that the ideal point is at (0, 0) and the nadir point is at (1, 1).</p><formula xml:id="formula_9">F 1 = (f 1 , f 1 )</formula><p>In addition to the best known Pareto set/Pareto front approximations (in black), the plots of Figure <ref type="figure" target="#fig_4">3</ref> show various 1-dimensional cuts ("lines") through the search space: (i) along a random direction through each single-objective optimum (in blue), (ii) along each coordinate axis through each single-objective optimum (blue dotted lines), (iii) along the line connecting both single-objective optima (in red), (iv) two fully random lines 15 (in yellow), and (v) a random line in the random projection plane going through both optima 16 (in green). All those straight lines have the same length of 20 with the support vector in its exact middle. Ticks along the lines indicate line segments of the same length in search space. Thicker points on the lines depict solutions that are non-dominated with respect to all points on the same line.</p><p>The shape of these lines in objective space and the distribution of non-dominated solutions along these lines (in objective and search space) indicate the difficulty of the bbob-biobj-ext problems for algorithms based on line searches. Sometimes smooth, sometimes rather chaotic looking lines in the objective space indicate that the proposed multiobjective problems show a wide range of different landscapes.</p><p>Furthermore, the first two rows of Figure <ref type="figure" target="#fig_4">3</ref> highlight the projected region [-5, 5] n as a gray-shaded area while the gray-shaded areas in the objective space plots in the last two rows denote the regions of interest between the ideal (√ó) and nadir points (+). 13 The non-dominated solutions have been obtained from extensive numerical experiments with a wide range of optimization algorithms. In particular, all 32 algorithm data sets 2 , submitted to the BBOB workshops in the years 2016-2019, contributed together with data from additional runs of random search, weighted sum and Chebyshev scalarization functions optimized by the quasi-Newton BFGS method and by CMA-ES <ref type="bibr" target="#b21">(Hansen and Ostermeier, 2001)</ref>. Moreover, other well-known multiobjective algorithms such as NSGA-II <ref type="bibr" target="#b8">(Deb et al., 2002)</ref>, SMS-EMOA <ref type="bibr" target="#b2">(Beume et al., 2007)</ref>, HMO-CMA-ES <ref type="bibr" target="#b31">(Loshchilov and Glasmachers, 2016)</ref>, and COMO-CMA-ES <ref type="bibr" target="#b35">(Tour√© et al., 2019)</ref> have been run as well. Non-dominated solutions evaluated during all these experiments have been collected to form the displayed Pareto set approximations. Those Pareto set approximations have also been used to calculate reference target precision values for the performance assessment-for details, see <ref type="bibr" target="#b4">(Brockhoff et al., 2016)</ref>. 14 To obtain the second axis, a standard normally distributed vector is orthogonalized with respect to the first axis (via Gram-Schmidt).</p><p>15 of random direction through a random point drawn uniformly in [-4, 4] n 16 with a random direction within the plane and through a random point drawn uniformly in <ref type="bibr">[-4, 4]</ref> 2 Pareto set and Pareto front approximations of Figure <ref type="figure" target="#fig_4">3</ref> are downsampled such that only one solution per grid point is shown-with the precision of 2 decimals for the search space plots and 3 decimals for the objective space plots to define the grid. The number of all available and actually displayed solutions is indicated in the legend of each plot. Due to this downsampling, the number of displayed points (‚àº 20000 or less) in Figure <ref type="figure" target="#fig_4">3</ref> is much smaller than the number of non-dominated solutions contained in the Pareto set approximation (about 6 √ó 10 6 for F 1 , 3 √ó 10 6 for F 10 and 6 √ó 10 5 for F 46 ). For links to the illustrations of all functions, we refer to the supplementary material 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Investigations on Necessary Optimality Conditions</head><p>An important question to ask is whether our collected Pareto set approximations are qualitatively good, i.e., how close they are to the true Pareto front. Assuming differentiable objective functions, a necessary condition for optimality of a point x is that the two objective gradients are collinear and point in opposite directions <ref type="bibr" target="#b32">(Miettinen, 1999)</ref>.</p><p>For our blackbox functions, we estimate collinearity as follows: for each Pareto set approximation (or function instance), we assess the two objective function gradients of solutions by finite (central) differences 17 and compute the angle between them. The angle between the gradients is closely related to the normalized multiobjective gradient by <ref type="bibr" target="#b27">Kerschke and Grimme (2017)</ref>, in the biobjective case defined as</p><formula xml:id="formula_10">‚àáf 1 (x) ‚àáf 1 (x) + ‚àáf 2 (x) ‚àáf 2 (x) . (<label>1</label></formula><formula xml:id="formula_11">)</formula><p>Its value is zero for locally non-dominated solutions <ref type="bibr" target="#b27">(Kerschke and Grimme, 2017)</ref>. The cosine of the angle between the two gradients has a strictly increasing bijection to the length of the normalized biobjective gradient (1):</p><p>Lemma 1. The length of the normalized biobjective gradient (1) and the cosine of the angle between the two gradients, say v and w, are related like</p><formula xml:id="formula_12">1 + cos(v, w) = 1 2 v v + w w 2 ‚àÄ v, w ‚àà R n \ {0} . (<label>2</label></formula><formula xml:id="formula_13">)</formula><p>The proof is given in Appendix B. A value of 0, 1, or 2 for 1 + cos(v, w) in (2) means that the gradients point in the exact opposite direction (indicating local nondominance), are orthogonal, or point in the very same direction, respectively.</p><p>Figure <ref type="figure" target="#fig_5">4</ref> shows empirical cumulative distribution functions (ECDFs) of the value 1 + cos(Œ±), where Œ± is the angle between the two gradients, denoted as gradient angle plots in the following. Shown are the first five instances (using the same color) of three different bbob-biobj functions in dimensions 2, 3, and 5. 18 For the gradient angle plots of all functions, we refer to the supplementary material 5 .</p><p>Depending on the function, two different observations can be made. For simpler, smooth functions such as the double sphere function F 1 = (f 1 , f 1 ), almost all values of 1 + cos(Œ±) are smaller than 10 -4 for all instances and dimensions-indicating that 17 Using a step length of Œµ = 10 -8 to approximate the i-th coordinate of the gradient in x ‚àà R n by</p><formula xml:id="formula_14">f (x+Œµ‚Ä¢e i )-f (x-Œµ‚Ä¢e i ) 2Œµ</formula><p>where e i ‚àà R n is the Cartesian unit vector in the ith variable. 18 Only every hundredth point of the Pareto set approximations is displayed to limit computation time and file sizes. We checked for some cases that the display of all solutions does not change the plots significantly. Reducing the number of displayed points further, for example to every thousandth point, however, starts to visibly roughen the plots. The legends in Figure <ref type="figure" target="#fig_5">4</ref> show the number of displayed points compared to the entire size of the Pareto set approximation for each dimension and for the last instance. the gradients point in nearly opposite directions. For smooth functions, this also suggests that our Pareto set approximations are reasonably close to a true local Pareto set. This also holds for other combinations of objectives such as the sphere/sum of different powers function F 6 = (f 1 , f 14 ), the sphere/Schwefel function F 9 = (f 1 , f 20 ), the attractive sector/sum of different powers function F 23 = (f 6 , f 14 ), the double sum of different powers function F 41 = (f 14 , f 14 ), and the double Schwefel x sin x function F 53 = (f 20 , f 20 ) and with slightly higher cosine values for several other functions, for example the attractive sector/Gallagher 101 peaks function F 27 = (f 6 , f 21 ) and the double original Rosenbrock function F 28 = (f 8 , f 8 ). Both lists are non-exhaustive 5 . On the other hand, there are functions with higher values of 1 + cos(Œ±), indicating (at first sight) that the Pareto set approximations are less well converged. Two examples, the sphere/sharp ridge function F 5 = (f 1 , f 13 ) and the original Rosenbrock/sharp ridge function F 29 = (f 8 , f 13 ) are shown in Figure <ref type="figure" target="#fig_5">4</ref>. A closer look at the functions with the (strongest) right-shift in the ECDF reveals that often one of the objectives is multimodal, flat, or its gradient changes non-smoothly (which is the case for the sharp ridge function of Figure <ref type="figure" target="#fig_5">4</ref>). In the latter case in particular, we do not expect that the values of 1 + cos(Œ±) are close to zero. We have verified that for the combination of sphere and sharp ridge, all solutions in our Pareto set approximation lie along a line between the two single-objective optima, but that depending on which side of the sharp ridge a point is located, the two objectives' gradients are pointing in the same or the opposite direction, resulting in small and large values of 1 + cos(Œ±) respectively.</p><p>Although we do not know the exact Pareto set for the proposed functions (except for the double sphere function F 1 = (f 1 , f 1 )), the generated non-dominated Pareto set approximations seem to be accurate enough also based on consistency: both, the large amount of non-dominated solutions from several algorithms, implemented by various authors as presented here, and the non-dominated solutions on a 2-dimensional grid, as presented in the next subsection, show qualitatively the same sets<ref type="foot" target="#foot_7">19</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Dominance-Based Plots</head><p>To further investigate and understand the bbob-biobj-ext functions and their available Pareto set approximations, we provide three kinds of dominance-based plots for 2-variable problems computed on an axes-parallel grid of 501 √ó 501 points. Figure <ref type="figure" target="#fig_6">5</ref> shows examples of these plot for the first instance of three bbob-biobj functions (the double sphere function F 1 = (f 1 , f 1 ), the sphere/Gallagher 101 peaks function F 10 = (f 1 , f 21 ) and the double Rastrigin function F 46 = (f 15 , f 15 )), while the plots for the other functions and instances can be found in the supplementary material 5 .</p><p>The first row of Figure <ref type="figure" target="#fig_6">5</ref> presents plots of the dominance ratio <ref type="bibr">(Fonseca, 1995, p. 71ff.)</ref>. Based on solutions on a regular grid in search space, the dominance ratio of each grid point is the ratio of all grid points that dominate it. The plot uses a logarithmic color scale with the overall non-dominated points shown in yellow.</p><p>The non-dominated grid points are presented in the second row of Figure <ref type="figure" target="#fig_6">5</ref> in black, together with the level sets of the first objective in blue and the second in red.</p><p>The last row of Figure <ref type="figure" target="#fig_6">5</ref> shows the so-called local dominance landscape plots by 16</p><p>Evolutionary Computation Volume x, Number x <ref type="bibr" target="#b12">Fieldsend et al. (2019)</ref>. These plots use, for each grid point, one of three different colors. In dark green, we show all grid points P for which all 8 neighboring grid points (in the Moore neighborhood) are mutually non-dominated to P . In landscape analysis terms, we can call the green regions in the plots "dominance-neutral local optima regions" <ref type="bibr" target="#b12">(Fieldsend et al., 2019)</ref> in the sense that a dominance-based hill-climber will be able to explore a green region by single non-dominated moves. The pink areas are comprised of grid points for which at least one neighboring grid point dominates it and all dominating movement paths from neighbors in pink regions lead to the same green region <ref type="bibr" target="#b12">(Fieldsend et al., 2019)</ref>. Each pink area is considered a "basin of attraction" of a green area in the sense that a local dominance-based hill climber can only move towards the included green area. Last, a grid point is assigned a white color if at least two of its dominating neighbors belong to two different basins of attraction-white areas in the plots therefore show the boundaries between the basins. The existence of multiple, distinct basins of attractions can be interpreted as multimodality of a multiobjective problem: it is denoted unimodal if and only if a single basin of attraction is present (and thus no two distinct local Pareto-optimal sets exist). Otherwise, the problem is called multimodal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Gradient-Based Plots</head><p>The gradient angle plots of Section 6.2 gave insight into the angle between the gradients of solutions contained in the best known Pareto set approximations. We now present biobjective gradient plots based on 2-dimensional grids. The first row in Figure <ref type="figure" target="#fig_7">6</ref> visualizes the length of the normalized biobjective gradient (1) at 501√ó501 grid points for three bbob-biobj functions. This length signifies how aligned or opposed the single-objective gradients are. For all functions, we again refer to the supplementary material 5 .</p><p>The second row in Figure <ref type="figure" target="#fig_7">6</ref> shows the length of the path from each grid point towards the next local optimum. Inspired by the cumulated gradient field landscapes <ref type="bibr" target="#b27">(Kerschke and Grimme, 2017)</ref>, the length is (recursively) defined as Euclidean distance to the Moore neighbor to which the biobjective gradient points<ref type="foot" target="#foot_8">20</ref> plus the path length of this neighbor<ref type="foot" target="#foot_9">21</ref> . Cumulated gradient field landscapes sum gradient lengths instead of Euclidean distances. We use the latter because they better quantify the actual distance to the local optimum, however both approaches lead to qualitatively very similar figures. Plotting the lengths of the normalized grid-based local search paths as in Figure <ref type="figure" target="#fig_7">6</ref> allows to visualize the difficulty of multiobjective landscapes, at least for problems with 2 variables: although not as clearly as in the previous dominance-based plots we can infer the boundaries of the basins of attractions of the local Pareto-optimal sets as the places in the search space where the path lengths for neighbored grid points decrease in two different directions, see the examples in Figure <ref type="figure" target="#fig_7">6</ref>. With the normalized biobjective gradient plots, we can therefore see how many distinct local Pareto-optimal sets exist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Summary of Observed Problem Properties</head><p>From the above visualizations we report basic properties of the bbob-biobj-ext test functions and the corresponding Pareto set/front approximations that we provide for performance assessment. We investigate properties like continuous vs. discontinuous Pareto fronts and sets, the existence of non-dominated points outside a certain region, and uni-or multimodality. Table <ref type="table">1</ref> details these findings for the 2-variable instances 1-5 where search space related numbers correspond to the region [-5, 5] n .</p><p>We briefly summarize main findings from Table <ref type="table">1</ref>. First, different instances of the same function share most of the time the same properties-especially for the number of basins of attraction and the Pareto front convexity. Similarly, 78 of the 92 bbob-biobj-ext functions do not differ among the instances 1-5 in terms of Pareto set/front (dis-)continuity-only the number of the connected Pareto set/front parts changes in case discontinuities are observed.</p><p>Out of the 92 bbob-biobj-ext functions, only 27 (of which 18 belong to the 55 bbob-biobj suite) have a continuous Pareto front and a continuous Pareto set in all five instances (i.e. 29% resp. 33% of the functions). Only 9 functions show a convex Pareto front for all five instances. Similarly, all five instances of 59 functions are multimodal, as indicated by more than one basin of attraction. Hence we conclude that most of the proposed functions possess challenging Pareto set and Pareto front shapes.</p><p>Furthermore, the Pareto set of most problem instances of the proposed test suites lies within the hyperbox [-5, 5] n . However, 51 of the investigated 92 ‚Ä¢ 5 = 460 instances (from 28 functions) show non-dominated points outside. For this reason, the COCO implementation defines the region of interest as [-100, 100] n although the single-objective optima are always in <ref type="bibr">[-4, 4]</ref> n (with the exception of the linear function f 5 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">On Reporting Algorithm Performance</head><p>The definition of (test) problem instances is only the first step towards benchmarking optimization algorithms. Further steps entail to choose, record and display the actual performance measure(s). As the proposed test problems have been implemented in the COCO software, the postprocessing module of COCO can be directly used for the performance assessment (up to LaTeX templates for publication of the results) and we briefly discuss what this comprises. As best practice, we usually conduct seven steps to analyze the performance of an algorithm, here also illustrated with an example.</p><p>Benchmarking Experiment First, we run the algorithm on a chosen benchmark suite.</p><p>COCO offers example code in all supported languages. A minimal code example in Python is shown in <ref type="bibr">Hansen et al. (2021, Figure 2)</ref>. Here, we have run the COMO-CMA-ES <ref type="bibr" target="#b35">(Tour√© et al., 2019)</ref> with population size 100 on the bbob-biobj suite.</p><p>dimo: prepare all algorithm data sets again wrt new hypervolume values do a release with new hv reference values before submission</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Choosing Algorithms for Comparison</head><p>We decide on (baseline) algorithms to compare with. As of May 2021, data for browsing 3 and downloading from 32 algorithms 2 run on the bbob-biobj test suite is available online. Here, we choose SMS-EMOA and NSGA-II as baselines.</p><p>Postprocessing The postprocessing of COCO, here invoked by the command "python -m cocopp COMO-100 NSGA-II-Matlab SMS-EMOA-DE", then downloads the corresponding baseline data and displays the algorithms performance in both html and LaTeX/PDF format.</p><p>For multiobjective problems, COCO measures the value of an extended hypervolume indicator of all non-dominated solutions evaluated so far<ref type="foot" target="#foot_10">22</ref> . Within a benchmarking experiment, COCO records the number of function evaluations ("runtime") to reach certain indicator values, given as precisions to a reference value. For each instance, function, and dimension, the runtime to 58 target precisions is displayed (amongst other visualizations) in the form of empirical cumulative distribution functions (ECDF), see <ref type="bibr">Hansen et al. (2016a</ref><ref type="bibr">Hansen et al. ( , 2010))</ref>. <ref type="foot" target="#foot_11">23</ref>Test suites that contain many function instances in several dimensions require to aggregate data when analyzing and sharing results. Conveniently, runtimes from different instances or functions can be meaningfully displayed in a single ECDF graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Displaying and Discussing Summary Results In publications, we show summary</head><p>ECDFs over all functions in 5-D and 20-D and the results for each function group in 10-D.</p><p>Figure <ref type="figure">7</ref> shows these runtime distribution graphs aggregated over all functions and Figure <ref type="figure">8</ref> shows the aggregations within function groups<ref type="foot" target="#foot_12">24</ref> . For budgets larger than about 5 ‚Ä¢ 10 3 times dimension evaluations, COMO-100 overall outperforms SMS-EMOA-DE and NSGA-II-Matlab, where the latter two are also more affected by increasing dimension. The qualitative differences of the runtime behaviors between the algorithms remain similar also within function groups, while differences are smaller in the groups involving multimodal objective functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Investigating and Discussing Complementary Results</head><p>We always inspect all results on all single functions. Depending on the outcome of this inspection, we display further graphs. They may show the dependency on dimension or any other remarkable observation.</p><p>Figure <ref type="figure">9</ref> shows ECDF graphs for three single functions. We observe exceptionally good behavior of SMS-EMOA-DE on the double sphere function (Figure <ref type="figure">9</ref>, left). The middle plot of Figure <ref type="figure">9</ref> shows an example where NSGA-II is better than SMS-EMOA-DE for all budgets. Finally, on the right plot, we observe that COMO-100 matches and exceeds the performance of the best 2016 reference algorithm on the ellipsoid/Gallagher 101 peaks function F 19 = (f 2 , f 21 ) for budgets between 5 ‚Ä¢ 10 3 and 10 4 times dimension evaluations but also does not improve anymore shortly after.</p><p>Processed Data Sharing We put the html output from the postprocessing online, see Postprocessed data in the supplementary material 5 . During scientific collaborations, we often share such data repeatedly with collaborators early in the process.</p><p>Raw Data Sharing Finally, we publish the raw data sets by creating a submission issue on GitHub<ref type="foot" target="#foot_13">25</ref> . Raw data can also be "archived" with the cocopp.archiving module. Archived data that are then put online can be used in the postprocessing (cocopp) by everyone who knows the corresponding URL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>Designing test suites is a crucial part of benchmarking optimization algorithms. Arguably, the most problematic aspect of using artificial test functions to assess performance is the representativeness of these regarding difficulties observed in real-world problems. In this paper, we suggest to address the problem of representativeness in the multiobjective case by combining established single-objective test functions with known difficulties observed in practice. Following the concepts of the single-objective bbob test suite, we propose two concrete biobjective test suites based on the idea of combining (subsets of) the existing bbob single-objective functions.</p><p>Our approach contrasts most of the existing test suites for multiobjective optimization. These are based on the desirable property of having well-understood Pareto sets and Pareto fronts with analytical forms but have, on the other hand, artificial characteristics that are arguably under-represented in real-world problems. Examples of such properties are separability, optima located exactly at the boundary constraints, and the existence of variables that solely control the distance between a solution and the Pareto front.</p><p>The disadvantage of unknown analytical forms of the Pareto sets and Pareto fronts in our proposal is addressed by collecting the non-dominated solutions from extensive experiments with dozens of different optimization algorithms and providing and visualizing the Pareto set and Pareto front approximations for each problem. These visualizations lead to new insights into how such non-analytical Pareto sets and Pareto fronts may look in practice.</p><p>Our proposal is currently restricted to two objectives. With a growing number of objectives, the number of arbitrary combinations of single-objective functions grows quickly. This leads to long running times of the benchmarking experiment and, more importantly, discourages to routinely scrutinize new results on each function individually. Hence, we think that further pruning choices should be made to define test suites with more objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A On the Single-objective bbob Functions</head><p>This section discusses properties of real-world problems and how the bbob test suite models different problem difficulties. It then gives more details about the bbob functions, their function groups and instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Real-World Function Properties</head><p>We present here in short the general properties of objective functions that are related to difficulties observed in real-world problems. It depends on these properties whether an optimization problem is easy or hard to solve. These properties build the basis of the five function groups described in Section 4.</p><p>A separable function does not have any dependencies among its variables and can therefore be optimized by applying n independent one-dimensional optimizations along each coordinate axis while keeping the other variables fixed. Difficult optimization problems are typically not separable and thus, non-separable optimization problems should be considered. The typical well-established technique to generate nonseparable benchmark functions from separable ones is the application of a rotation matrix. That is, if g(x) is a separable function with respect to x and R ‚àà R n√ón is a rotation matrix, then g(Rx) will generally be non-separable with respect to x.</p><p>A unimodal function has only one local minimum which is at the same time also its global one. A multimodal function has more local minima which is highly common in practical optimization problems. We consider a multimodal function to have weak global structure if the qualities (the f -values) of the local optima are only weakly related with their locations in search space, e.g. when neighboring optima do not generally have similar quality values.</p><p>Ill-conditioning is another typical challenge of real-parameter optimization and, besides multimodality, probably the most common one. The condition number measures, loosely speaking, how strongly the steepness of the gradient depends on the position within a level set. A small condition number, close to one, indicates a well-conditioned function with little dependency. A large condition number indicates a more difficult, ill-conditioned function with strong dependency between steepness and position. The condition number of convex quadratic functions is the ratio between largest and smallest eigenvalue of the Hessian matrix. Geometrically, these eigenvalues correspond, respectively, to the shortest and longest principal axis of the contour ellipsoids.</p><p>The bbob test suite contains ill-conditioned functions with a typical conditioning of 10 6 . We believe this is a realistic requirement, while we have seen practical problems with conditioning as large as 10 10 ( <ref type="bibr" target="#b6">Collange et al., 2010)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Balancing Problem Difficulties</head><p>It is worth noting that in several existing single-objective test suites, some of the easier properties are overrepresented. For example, in the CUTEr/CUTEst test suite <ref type="bibr" target="#b16">(Gould et al., 2005)</ref>, 202 (54%) out of the 375 functions, that are labeled as unconstrained or bound constrained, are of the "sum of squares" type, a further 58 (15%) are quadratic. Furthermore, out of the 191 problems with a fixed dimension, there are 49 (26%) that have only two variables while only 31 (16%) have a dimension larger than 10. Such an overrepresentation is not a big problem per se, but when making statements on algorithm performance aggregated over all functions in a suite, one has to keep in mind that the performance of the better algorithms might simply come from the fact that they are tailored towards simpler problems.</p><p>With the bbob test suite, all problems are scalable in dimension and belong to a Evolutionary Computation Volume x, Number x</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The functions of the bbob-biobj test suite (F 1 to F 55 ) together with the information about which single-objective bbob functions are used to define them (top and right annotations). Background color is used to delineate function groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>with a continuous Pareto front and a straight line as the Pareto set (left column), the sphere/Gallagher 101 peaks function F 10 = (f 1 , f 21 ) with a continuous Pareto front but a gap in the Pareto set (middle column), and the double Rastrigin function F 46 = (f 15 , f 15 ) for which both Pareto set and Pareto front are discontinuous (right column). The best known Pareto set/front approximations are shown in black.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration in the search space (first two rows) and the objective space (third row: original scaling; forth row: normalized in log-scale) of three bbob-biobj functions: the double sphere function F 1 = (f 1 , f 1 ) (left column), the sphere/Gallagher 101 peaks function F 10 = (f 1 , f 21 ) (middle column), and the double Rastrigin function F 46 = (f 15 , f 15 ) (right column) in dimension 5 for the first instance.</figDesc><graphic coords="14,117.22,481.89,161.22,120.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Gradient angle plots of solutions in our Pareto set approximations for three functions. A necessary optimality condition for smooth functions is 1 + cos(Œ±) = 0. Left: the double sphere function F 1 = (f 1 , f 1 ), Middle: the sphere/sharp ridge function F 5 = (f 1 , f 13 ), Right: the original Rosenbrock/sharp ridge function F 29 = (f 8 , f 13 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Dominance-based plots for three bbob-biobj functions: the double sphere function F 1 = (f 1 , f 1 ) (left column), the sphere/Gallagher 101 peaks function F 10 = (f 1 , f 21 ) (middle column), and the double Rastrigin function F 46 = (f 15 , f 15 ) (right column) in dimension 2 for the first instance. First row: dominance ratio; Second row: non-dominated solutions (in black) and level sets of both objectives; Third row: local dominance landscape plots.</figDesc><graphic coords="17,131.10,347.53,121.55,127.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Gradient-based plots for three bbob-biobj functions: the double sphere function F 1 = (f 1 , f 1 ) (left column), the sphere/Gallagher 101 peaks function F 10 = (f 1 , f 21 ) (middle column), and the double Rastrigin function F 46 = (f 15 , f 15 ) (right column) in dimension 2 for the first instance. First row: pure gradient length at each grid point, Second row: length of the path from each grid point towards the next local optimum (see text for more information).</figDesc><graphic coords="19,131.10,219.57,121.55,110.64" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>A function is said to have a distance variable if changing this variable only results in dominating or dominated solutions. In other words, a distance variable determines solely the distance of a solution from the Pareto front. A position variable, in turn, only results in incomparable solutions when changed, see<ref type="bibr" target="#b25">Huband et al. (2006)</ref> for details.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Evolutionary Computation Volume x, Number xUsing SO-Functions in MOO Test Suites</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p>The distance in objective space is defined here in such a way that the nadir and ideal points have in each coordinate the distance of one. Note also that finding a set of non-dominated solutions as large as possible might not always be the ultimate goal, in particular if the number of objective functions is large.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>Evolutionary Computation Volume x, Number x</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>Evolutionary Computation Volume x, Number xUsing SO-Functions in MOO Test Suites</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>Note that this assumption is not true for simple classical strategies such as optimizing successively a weighted sum w ‚Ä¢ f 1 (x) + (1 -w) ‚Ä¢ f 2 (x) with increasing weight 0 ‚â§ w ‚â§ 1.Evolutionary Computation Volume x, Number x</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_6"><p>Evolutionary Computation Volume x, Number x</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_7"><p>In the cases where our Pareto set approximations go beyond the region [-5, 5] n , the grid-based approach shows additional artifacts for solutions connected to the grid boundary.Evolutionary Computation Volume x, Number x</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_8"><p>The 360 degrees of possible directions are assigned evenly to the eight neighbors.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="21" xml:id="foot_9"><p>A grid point whose normalized biobjective gradient is below 10 -6 in length is considered to be at a (local) Pareto-optimum and assigned zero path length.Evolutionary Computation Volume x, Number x</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="22" xml:id="foot_10"><p>More specifically, the (multiobjective) performance measure used in COCO makes a case distinction. When at least one solution dominates the hypervolume reference point, the hypervolume indicator of all non-dominated solutions is used, normalized so that the ideal point is in the origin and the nadir point is in [1, 1], with this nadir point as the (normalized) reference point. Otherwise, the performance is measured as the negative of the minimal distance of any found solution (in objective space and normalized as above) to the box [0, 1] 2 , for details see<ref type="bibr" target="#b4">(Brockhoff et al., 2016)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23" xml:id="foot_11"><p>All plots shown in this paper have been prepared with COCO version 2.4 and the corresponding hypervolume reference values. Improved hypervolume reference values as well as the bbob-biobj-ext suite are available from version 3.0.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="24" xml:id="foot_12"><p>Displayed is the performance of the three algorithms COMO-CMA-ES with a population size of 100 ("COMO-100", Tour√© et al. (2019); Dufoss√© and Tour√© (2019)), SMS-EMOA with differential evolution as search operator ("SMS-EMOA-DE", Beume et al. (2007); Auger et al. (2016b)) and the Matlab implementation of NSGA-II ("NSGA-II-Matlab", Deb et al. (2002); Auger et al. (2016a)).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="25" xml:id="foot_13"><p>See https://github.com/numbbo/coco/blob/master/howtos/publish-a-dataset-howto.md</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the grant <rs type="grantNumber">ANR-12-MONU-0009</rs> (NumBBO) of the <rs type="funder">French National Research Agency</rs>. We also thank <rs type="person">Ilya Loshchilov</rs> and <rs type="person">Oswin Krause</rs> for their initial suggestions on how to extend the bbob-biobj test suite. Tea Tu≈°ar acknowledges financial support from the <rs type="funder">Slovenian Research Agency</rs> (research project No. <rs type="grantNumber">Z2-8177</rs> and research program No. <rs type="grantNumber">P2-0209</rs>) and the <rs type="funder">European Commission</rs>'s <rs type="programName">Horizon 2020 research and innovation program</rs> (grant agreement No. <rs type="grantNumber">692286</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_xw7dJ6K">
					<idno type="grant-number">ANR-12-MONU-0009</idno>
				</org>
				<org type="funding" xml:id="_VCBHSeE">
					<idno type="grant-number">Z2-8177</idno>
				</org>
				<org type="funding" xml:id="_9MCY4Wu">
					<idno type="grant-number">P2-0209</idno>
				</org>
				<org type="funding" xml:id="_PRRqpv8">
					<idno type="grant-number">692286</idno>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation program</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table">1</ref>: Selected properties of the bbob-biobj-ext test functions for the first five instances in dimension 2. The columns give the properties, from left to right, the number of distinct Pareto set parts (?=unclear), the number of distinct Pareto front parts, the <ref type="bibr">(visual)</ref> convexity of the Pareto front (n=non-convex, y=convex), the existence of solutions within the best known Pareto set approximation that lie outside <ref type="bibr">[-5, 5]</ref> n (n=no such point, y=some points outside of the hyperbox), and finally the number of basins of attractions within <ref type="bibr">[-5, 5]</ref> n , induced visually from the plots described in the text. 5-9 5-9 5-9 5-9 5-9 5-9 5-9 5-9 5-9 5-9 n n n n n n n n n n 10+ 10+ 10+ 10+ 10+ F9=(f1, f20)</p><p>1 5-9 5-9 1 1 1 5-9 5-9 1 1 y y y y y n n n n n 5-9 5-9 5-9 5-9 5-9 F10=(f1, f21) 3 2 2 5-9 1 <ref type="table">f15) 5-9 5-9 10+ 10+ 10+ 3 5-9 5-9 5-9 5-9</ref>  <ref type="table">f21) 5-9 5-9 2 5-9 4 5-9 5-9</ref>    Having all problem groups of similar size also avoids problems of overfitting to certain difficulties if aggregated results are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Function Instances</head><p>All bbob functions come naturally in the form of instances. That is to say, each function optimized by an algorithm takes the form:</p><p>where f raw is a raw function-usually the simplest representative of the function class (like the sphere function with optimum in zero)-and where T i : R n ‚Üí R n are search space transformations and H i : R ‚Üí R are function value transformations that are applied to the raw function. For example search space transformations can be rotations or translations of the optimum and for example, a function-value transformation can be translating the function by a scalar. Each of those transformations applied to the raw function are actually (pseudo-)random, e.g. when applying a translation in the search space, the vector by which the search point is shifted is randomly sampled. The resulting functions can be seen as instances of a parametrized transformation.</p><p>In an abstract manner, the functions optimized are instances of a parametrized function F Œ∏ (as introduced in Section 2); the parameter Œ∏ is instantiated (pseudo-)randomly from an integer number, the so-called instance number, as well as potentially from the function number. We refer to a function class as a set of functions {F Œ∏ : Œ∏ ‚àà Œò} and we often name the function class after its raw function.</p><p>Transformations that are shared by all bbob functions are shifts in the optimal function value and a pseudo-random location of the optimum. In addition, several of the non-separable functions are created by pseudo-random rotations of the search space and many of the simpler functions are made less regular by non-linear transformations in both search and objective space. See <ref type="bibr" target="#b18">Hansen et al. (2009)</ref> for more details.</p><p>Though the potential set of instances for a given bbob function is unbounded (and can be indexed by any positive integer), numerical benchmarking experiments are typically advised on 10-15 of those instances. Default instances in the COCO implementation might change from year to year to avoid overfitting. Note also that in some cases, single instances might be more difficult/easier to solve than others. However, in general, the differences in difficulty among instances of the same bbob function are smaller than among different functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Normalization and Target Difficulties</head><p>All bbob functions are normalized in the sense that the given target function values/difficulties around the optimal function value are comparable over functions and instances. Functions are provided with an f -offset such that the optimal function value is, loosely speaking, a realization of a Cauchy distribution with median zero and interquartile range 200. The optimal function value is furthermore rounded to two decimal places and set to ¬±1000 if its absolute value exceeds 1000 <ref type="bibr" target="#b18">(Hansen et al., 2009)</ref>. The target difficulties are computed as a set of differences to the optimal function value. The differences are equally spaced on the log scale and the same for all functions and instances. Algorithms however are not allowed to use or exploit any of this information <ref type="bibr" target="#b22">(Hansen et al., 2016b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Proof of Lemma 1 (page 14)</head><p>Proof. For v, w ‚àà R n , we have </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Benchmarking MATLAB&apos;s gamultiobj (NSGA-II) on the bi-objective BBOB-2016 test suite</title>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tu≈°ar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tu≈°ar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (Companion), GECCO 2016 Companion</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1233" to="1239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The impact of variation operators on the performance of SMS-EMOA on the bi-objective BBOB-2016 test suite</title>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tu≈°ar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tu≈°ar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (Companion), GECCO 2016 Companion</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016b</date>
			<biblScope unit="page" from="1225" to="1232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SMS-EMOA: Multiobjective Selection Based on Dominated Hypervolume</title>
		<author>
			<persName><forename type="first">N</forename><surname>Beume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Naujoks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Emmerich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1653" to="1669" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Benchmarking Numerical Multiobjective Optimizers Revisited</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (GECCO 2015)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="639" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Biobjective Performance Assessment with the COCO Platform</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tu≈°ar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tu≈°ar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<idno>CoRR, abs/1605.01746</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Benchmark functions for the CEC&apos;2017 competition on many-objective optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>University of Birmingham, UK</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multidisciplinary Optimisation in the Design of Future Space Launchers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Collange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Delattre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Quinquis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multidisciplinary Design Optimization in Computational Mechanics</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="487" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Multi-Objective Optimization Using Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Wiley, Chichester</publisher>
			<pubPlace>UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meyarivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scalable Test Problems for Evolutionary Multi-Objective Optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Multiobjective Optimization: Theoretical Advances and Applications</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Goldberg</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="105" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Benchmarking MO-CMA-ES and COMO-CMA-ES on the bi-objective bbob-biobj testbed</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dufoss√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tour√©</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (Companion), GECCO 2019</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1920" to="1927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Test problems based on Lam√© superspheres</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Emmerich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Deutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Multi-Criterion Optimization</title>
		<meeting><address><addrLine>EMO</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="922" to="936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A feature rich distance-based many-objective visualisable test problem generator</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Fieldsend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Allmendinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Miettinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (GECCO 2019)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="541" to="549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Real-parameter black-box optimization benchmarking 2009: Presentation of the noiseless functions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Finck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<idno>2009/20</idno>
		<imprint>
			<date type="published" when="2009-02">2009. February 2019</date>
		</imprint>
		<respStmt>
			<orgName>Research Center PPE</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Multiobjective genetic algorithms with application to control engineering problems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>University of Sheffield</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An Overview of Evolutionary Algorithms in Multiobjective Optimization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">CUTEr and SifDec: A Constrained and Unconstrained Testing Environment, revisited</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I M</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Orban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Toint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="373" to="394" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">COCO: Performance assessment</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tu≈°ar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tu≈°ar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.03560</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Real-Parameter Black-Box Optimization Benchmarking 2009: Experimental Setup</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Finck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ros</forename></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<idno>RR-6829</idno>
		<imprint>
			<date type="published" when="2009-02">2009. February 2010</date>
		</imprint>
		<respStmt>
			<orgName>INRIA Saclay-Ile-de-France</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">INRIA Research Report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Comparing results of 31 algorithms from the black-box optimization benchmarking BBOB-2009</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Finck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Po≈°√≠k</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and evolutionary computation conference companion (GECCO 2010)</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1689" to="1696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">COCO: A platform for comparing continuous optimizers in a black-box setting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mersmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tu≈°ar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brockhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization Methods and Software</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="114" to="144" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Completely Derandomized Self-Adaptation in Evolution Strategies</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ostermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="195" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">COCO: The Experimental Procedure</title>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tu≈°ar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mersmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brockhoff</surname></persName>
		</author>
		<idno>CoRR, abs/1603.08776</idno>
		<imprint>
			<date type="published" when="2016">2016b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Model-based multiobjective optimization: taxonomy, multi-point proposal, toolbox and benchmark</title>
		<author>
			<persName><forename type="first">D</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Biermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Weihs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bischl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Evolutionary Multi-Criterion Optimization</title>
		<meeting><address><addrLine>EMO</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="64" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Problem Definitions for Performance Assessment of Multiobjective Optimization Algorithms</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Preuss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huband</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Nanyang Technological University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Special Session on Constrained Real-Parameter Optimization</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Review of Multiobjective Test Problems and a Scalable Test Problem Toolkit</title>
		<author>
			<persName><forename type="first">S</forename><surname>Huband</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hingston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>While</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="477" to="506" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Covariance Matrix Adaptation for Multiobjective Optimization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An expedition to multimodal multi-objective optimization landscapes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kerschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grimme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Evolutionary Multi-Criterion Optimization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="329" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Towards analyzing multimodality of continuous multiobjective landscapes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kerschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Preuss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grimme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Trautmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Emmerich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Problem Solving from Nature</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="962" to="972" />
		</imprint>
	</monogr>
	<note>PPSN 2016)</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Variant of Evolution Strategies for Vector Optimization</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kursawe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Problem Solving from Nature (PPSN 1990)</title>
		<editor>
			<persName><forename type="first">H.-P</forename><surname>Schwefel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>M√§nner</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="193" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multiobjective Optimization Problems With Complicated Pareto Sets, MOEA/D and NSGA-II</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="284" to="302" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Anytime bi-objective optimization with a hybrid multi-objective CMA-ES (HMO-CMA-ES)</title>
		<author>
			<persName><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Glasmachers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference Companion (GECCO 2016 Companion)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1169" to="1176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Nonlinear Multiobjective Optimization</title>
		<author>
			<persName><forename type="first">K</forename><surname>Miettinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Kluwer</publisher>
			<pubPlace>Boston, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multiple objective optimization with vector evaluated genetic algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Schaffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Genetic Algorithms and their Applications</title>
		<imprint>
			<date type="published" when="1985">1985. 1985</date>
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Evolutionary algorithms for multi-objective optimization: Performance assessments and comparisons</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Khor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence Review</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="251" to="290" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Uncrowded hypervolume improvement: COMO-CMA-ES and the Sofomore framework</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tour√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Auger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brockhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (GECCO 2019)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="638" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Multiobjective evolutionary algorithm research: A history and analysis</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Van Veldhuizen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Lamont</surname></persName>
		</author>
		<idno>TR-98-03</idno>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>Department of Electrical and Computer Engineering, Graduate School of Engineering, Air Force Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">MOEA test suite generation, design &amp; use</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Van Veldhuizen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Lamont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (GECCO 1999). Workshop Program</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="113" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Multiobjective evolutionary algorithm test suites</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Van Veldhuizen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Lamont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Applied Computing</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="351" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multiobjective Optimization Test Instances for the CEC 2009 Special Session and Competition</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tiwari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CES</title>
		<imprint>
			<biblScope unit="volume">487</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>The School of Computer Science and Electronic Engieering, University of Essex</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Comparison of Multiobjective Evolutionary Algorithms: Empirical Results</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="195" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Performance Assessment of Multiobjective Optimizers: An Analysis and Review</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laumanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grunert</forename><surname>Da Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="132" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
