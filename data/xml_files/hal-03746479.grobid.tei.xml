<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4DEE3D00A081F5F99A89F7580E59B153</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-21T10:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>L'étiquetage en composantes connexes (ECC) est un problème fondamental du traitement d'images depuis plusieurs décennies <ref type="bibr">[26][10]</ref>. Il consiste à trouver les composantes connexes (ensembles de pixels adjacents) dans une image binaire et à leur assigner un identifiant unique appelé étiquette. Les applications de ce traitement sont nombreuses : on y retrouve la conduite autonome <ref type="bibr">[29][7]</ref>, la vidéo-surveillance <ref type="bibr">[13]</ref>[27], l'imagerie médicale <ref type="bibr">[6][25][1][20][14]</ref> ainsi que d'autres domaines <ref type="bibr">[24]</ref> pour lesquels une implémentation cadence temps-réel est importante. Très étudié en 2D, des algorithmes d'ECC existent également pour la 3D, mais des progrès restent à faire, notamment pour atteindre des performances permettant d'assurer un traitement temps-réel. En effet, avec le passage à la 3D, le voisinage s'agrandit à 6 voisins sans diagonales (6-connexité) et à 26 avec (26-connexité), ce qui d'une part fait exploser le nombre d'opérations effectuées et d'autre part pose des problèmes de localité mémoire. Dans cet article, un nouvel algorithme d'étiquetage nommé LSL3D est proposé pour le traitement d'images 3D en 26-connexité. Les contributions sont 1) l'utilisation d'une machine à état (FSM) pour traiter efficacement les segments en utilisant un encodage par Run-Length Encoding (RLE) et 2) un mécanisme de cache permettant une réutilisation de résultats partiels et réduisant le nombre de calculs. Une étude de performance a montré que notre algorithme par segments est de 1.8× à 2.3× plus rapide que l'État-de-l'Art sur des bases d'images médicales. De plus, sur des images aléatoires en 3D, davantage stressantes, à granularité faible, le LSL3D est de 1.5× jusqu'à 3.1× plus rapide. L'article se compose de la façon suivante : La Section 2 donne une vue d'ensemble de l'ECC ainsi que les difficultés pour la 3D. La Section 3 fait un état-de-l'art de la littérature existante. Ensuite, la Section 4 introduit trois stratégies pour gérer les équivalences entre étiquettes tout en atténuant la malédiction de la dimension. Pour finir, la Section 5 étudie l'impact du SIMD sur les algorithmes d'ECC en 3D Outre ces jeux de données tirés de cas réels, s'ajoutent des générateurs d'images aléatoires qui permettent de faire varier à la fois la densité (proportion de pixels blancs dans l'image) et la granularité (taille de chaque bloc au moment de la génération) (Figure <ref type="figure">7</ref>). Ainsi, les résultats de l'article peuvent être reproduits en utilisant le générateur MT19937 [23] et en faisant varier la densité (notée d dans la suite de l'article) de 0% à 100% ainsi que la granularité (notée g) de 1 à 16. Tous les résultats présentés par la suite ont été obtenu sur un Intel Xeon Gold 6126.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">État de l'art des algorithmes d'ECC en 3D</head><p>Si tous les algorithmes efficaces reprennent le principe évoqué en Section 2.1, de nombreuses propositions ont étés faites pour accélérer le traitement en trois phases. Ces travaux ont ciblé, dans la majorité, les images 2D ; les travaux 3D adaptant souvent ces propositions sans proposer de mécanisme spécifique. Ainsi, dans cette section, nous présenterons les trois principales évolutions et leur adaptation à la 3D. Dans cet état de l'art, seront notés en gras tous les algorithmes retenus comme points de comparaison. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Algorithmes par pixel</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Une unification par machine à état finie</head><p>La recherche de superpositions entre segments peut également être réalisée sans ER via l'utilisation d'une machine à états finie (FSM). Dans l'algorithme 2D [17], chaque état de la FSM encode une configuration de segments entre la ligne courante et la ligne précédente. La fusion de deux lignes revient donc à itérer sur ces deux lignes en même temps : une nouvelle étiquette est créée pour chaque segment isolé alors que deux segments en contact voient leur composante fusionnées. Si cette amélioration de l'algorithme se montre performante sur des images simples, il n'en va pas de même pour des images plus complexes. Ainsi, sur la Figure <ref type="figure" target="#fig_0">2</ref>, qui présente les résultats des expérimentations sur les images aléatoires, le passage à une machine à état accélère d'un facteur ×1.3 le traitement d'images à forte granularité (g = 16), mais est ×0.61 plus lent avec une image pixelisée (g = 1). Une tendance similaire peut être observée sur les images médicales (Figure <ref type="figure">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Cache partiel de lignes fusionnées</head><p>La complexité de la machine à état posant des problèmes de performance sur les images complexes, nous avons repensé l'algorithme pour tenir compte de la séquentialité des traitements en conservant une partie des calculs intermédiaires. Outre la simplification des calculs, ceci va permettre de simplifier la machine à états (qui passe de 27 états et 55 transitions à 9 états et 18 transitions). Plus précisément, comme le montre la Figure <ref type="figure">1</ref>, deux itérations consécutives sur la même tranche traitent trois lignes plusieurs fois : la ligne courante (en rouge) et deux lignes voisines (en bleu) vont être retraitées dans la fusion suivante. On peut donc supprimer les calculs redondants en mettant en cache les résultats partiels (lignes vertes) dans un tableau de double-lignes.</p><p>Compas'2022 : Parallélisme/ Architecture/ Système MIS/UPJV -Amiens France, 5-8 juillet 2022</p><p>Dans un premier temps, il est possible de réduire le masque de lignes adjacentes à un masque 2 × 2. Bien que cela complexifie le traitement (l'adjacence avec le 4ème voisin devant se faire à l'itération suivante), cela permet d'établir une symétrie avec le plan précédent. Cette symétrie permet de réutiliser le calcul effectué (Figure <ref type="figure">1b</ref>). L'unification se fait ainsi en deux étapes : une première (1) fusionne la ligne actuelle (en rouge) et sa voisine du plan précédent (en bleu). Cela produit une double-ligne (en vert) qui contient la superposition des segments des deux lignes. Ensuite, une seconde étape (2) fusionne la double-ligne avec celle créée durant l'itération précédente. La double-ligne produite à l'étape (1) est réutilisée pour l'itération suivante pour éviter de la recalculer.</p><p>Le test des performances du LSL_DOUBLE sur images aléatoire (Figure <ref type="figure" target="#fig_0">2</ref>) se montre concluant. Il garde en effet l'efficacité du LSL_FSM sur les images simples (g = 4 et g = 16) tout en se montrant performant sur des images plus complexes (g = 1). Il est ainsi ×1.3 -1.5 plus rapide que le meilleur algorithme sur g = 4 et g = 16 et seulement ×0.94 moins rapide que le meilleur sur g = 1.</p><p>Outre ces bons résultats, on remarque sur la Figure <ref type="figure" target="#fig_0">2</ref> que LSL_DOUBLE résiste bien mieux à l'augmentation de la densité (écart entre la courbe verte et violette, au-delà d'une densité de 25%). En effet, pour ces niveaux de densités, le nombre de segments est statistiquement élevé, ce qui dégrade d'autant les algorithmes d'ECC basés sur un encodage RLE (par segments). Dans le cas de LSL_DOUBLE, ce phénomène est atténué par la fusion des segments au sein d'une double-ligne : plus le nombre de segments est élevé, plus il y aura de segments superposés, plus il y aura de fusions et moins il y aura de segments au final dans la double-ligne. Le mécanisme de double-ligne est donc particulièrement efficace pour des images complexes. Sur les images de mitochondria, LSL_DOUBLE se montre presque aussi rapide que LSL_FSM et que RBTS 3D, qui est le meilleur algorithme de l'état de l'art en scalaire sur des images simples. Sur le benchmark plus complexe de OASIS, LSL_DOUBLE est le plus performant (Figure <ref type="figure">3</ref>). Ce nouvel algorithme est à la fois efficace sur des images simples comme sur des images complexes, là où RBTS 3D est peu performant sur OASIS (×1.3 plus lent).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Prise en compte d'optimisations spécifiques à l'architecture</head><p>Comme vu dans la section précédente, l'  Malgré toutes ces limites, notre implémentation AVX512 de notre algorithme LSL3D se montre beaucoup plus rapide que les meilleurs algorithmes de l'état de l'art, comme on peut le vérifier sur la Figure <ref type="figure">4</ref>. on retrouve pour chacun des benchmarks (mitochondria et OASIS), les performances comparées des implémentations AVX512 des différentes versions de LSL3D par rapport aux meilleurs temps des algorithmes de l'État de l'art. Ainsi, pour chaque image des deux benchmarks, on retient en ordonnée, le plus petit temps d'exécution parmi les meilleurs algorithmes de l'état de l'art (LEB, RBTS, PRED++ 3D, SAUF++ 3D, EPDT_19c, EPDT_22c et EPDT_26c), la valeur en abscisse correspond, elle, à la performance de notre algorithme. On peut y voir que nos algorithmes sont meilleurs dans tous les (points toujours au-dessus de la première bissectrice) et que la version LSL_DOUBLE (points bleu foncés) est la plus performante des trois pour des images complexes (OASIS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion et travaux futurs</head><p>Cet article introduit un nouvel algorithme d'étiquetage en composantes connexes, LSL3D, qui combine un encodage par segment (RLE) pour diminuer globalement la complexité en 3D, une approche d'unification par machine à états finie pour être efficace sur les images simples, et un mécanisme de cache de double-lignes pour les images complexes. En plus d'une implémentation scalaire, nous utilisons les </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 2 -</head><label>2</label><figDesc>FIGURE 2 -Temps d'exécution des algorithmes sur images aléatoires à granularité (g) et densité variables sur Xeon</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 5 -</head><label>5</label><figDesc>FIGURE 5 -OASIS dataset</figDesc><graphic coords="11,98.38,340.09,209.80,141.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1. un premier étiquetage qui créé des étiquettes temporaires, tout en capturant les connections entre voisins dans une table d'équivalence. Cette table peut être vue comme un graphe orienté du voisinage.</figDesc><table /><note><p><p><p><p>2. une résolution d'équivalence qui détermine la Fermeture Transitive (FT) du graphe associé à la table d'équivalence, 3. un étiquetage final pour remplacer les étiquettes temporaires par les étiquettes finales (habituellement, la plus petite de chaque composante).</p>Les algorithmes modernes utilisent des optimisations algorithmiques pour accélérer ces étapes. Comme ces algorithmes sont en général limités par leur control-flow plutôt que par les accès mémoire ou les calculs, les banque d'images utilisées pour l'évaluation des performances ont un impact sur celles-ci.</p>2.2. Procédure de benchmark et jeux de données</p>Afin d'évaluer la performance des algorithmes d'ECC, la communauté a mis en place une suite de benchmarks avec YACCLAB [4]. On y retrouve deux jeux d'images médicales en 3D (domaine applicatif de l'ECC) (Figures 5 et 6) : mitochondria [21] qui contient 3 images et OASIS [22] qui contient 373 images. Les images de mitochondria sont composées de blobs (volumes pleins) de grandes tailles ainsi que de quelques petites composantes connexes. À l'inverse, les images de OASIS sont composées d'un volume creux et complexe.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Extension de l'unification par segments pour la 3D</head><label></label><figDesc>De façon naïve, la première phase considère tous les voisins pour chaque pixel, ce qui est très couteux. Ainsi, en utilisant un parcours séquentiel, Rosenfeld [26] montre qu'il est possible de diviser par deux le nombre de voisins considérés. On appelle cet ensemble de voisins masque de Rosenfeld. Cette approche par masque a été améliorée par Wu [30] dans l'algorithme SAUF en remarquant qu'il n'est pas toujours nécessaire de consulter tout le masque. Il est par exemple inutile de regarder les autres SAUF repose donc sur un arbre de décision qui capture les différents cas. Cet algorithme a été adapté à la 3D par Bolelli [2] avec l'algorithme SAUF 3D.Plusieurs travaux ont par ailleurs cherché à optimiser cet arbre de décision, notamment par He en 2D [11] et en 3D [19] (LEB 3D).Si les propositions basées sur le masque ou sur l'arbre de décision exploitent le fait que le traitement a déjà été fait pour certains points du voisinage, elles ne tiennent pas compte des décisions précédentes. L'idée de He [12] est de s'appuyer sur la décision précédente de façon à simplifier l'arbre. Il propose ainsi un algorithme à états basé sur un graphe d'arbre de décisions pouvant être vu comme un automate. Cette approche est généralisée par Grana avec l'algorithme PRED [8], ensuite étendu à la 3D par Bolelli avec PRED 3D [2]. L'introduction de Direct Rooted Acyclic Graphs (DRAG) par Bolelli [3] a permis de réduire l'empreinte du code de décision. Les DRAG ont ainsi étés utilisés par Bolelli [2] pour optimiser des algorithmes existants comme avec SAUF++ et PRED++, avec des versions adaptées à la 3D (SAUF++ 3D et PRED++ 3D). Les implémentations successives du LSL ont été testé suivant le benchmark de la Section 2.2. Elles sont comparées à 7 algorithmes de l'État-de-l'Art : LEB, RBTS, PRED++ 3D, SAUF++ 3D, EPDT_19c, EPDT_22c et EPDT_26c. Parmi les algorithmes EPDT, seul le meilleur est présenté (EPDT_22c). Les Figures 2 et 3 présentent les résultats, ceux-ci sont analysés dans les sections qui suivent. Afin de trouver les superpositions de segments sans parcourir la ligne courante plusieurs fois, le premier LSL [16] en 2D utilise deux tables ER (ligne courante et précédente) pour stocker les positions relatives des segments. Dans la 3D, en reprenant l'idée du masque de Rosenfeld, une unification est réalisée entre la ligne courante et les 4 lignes voisines au moyen de 5 tables ER (Figure1a), ce qui n'est pas sans poser des problèmes de localité spatiale puisque ces 5 tables correspondent à deux plans différents. La performance de notre algorithme LSL_ER en 3D est visible sur la Figure2. LSL_ER devient plus rapide pour g &gt; 4 sur les images aléatoires et creuse l'écart pour des granularités plus élevées (jusqu'à ×1.3 pour</figDesc><table><row><cell>Compas'2022 : Parallélisme/ Architecture/ Système</cell><cell cols="2">Compas'2022 : Parallélisme/ Architecture/ Système</cell></row><row><cell>MIS/UPJV -Amiens France, 5-8 juillet 2022</cell><cell cols="2">MIS/UPJV -Amiens France, 5-8 juillet 2022</cell></row><row><cell cols="2">cols (a) Unification 3D classique FIGURE 1 -Unification par segments en 3D cols rows slices (b) Unification 3D avec double-lignes (1) pixels du masque lorsque celui du dessus est présent. 4. LSL3D : stratégie d'unification efficace pour volumes 3D rows slices 4.1.</cell><cell>(2)</cell></row><row><cell cols="3">Cette section présente, pas à pas, la transformation et l'amélioration du LSL classique 2D en un nouvel</cell></row><row><cell>algorithme 3D optimisé :</cell><cell></cell></row><row><cell cols="3">-Une première étape étend le LSL vers la 3D en gardant un étiquetage relatif par ligne (version</cell></row><row><cell cols="3">LSL_ER). Une difficulté de ce travail est la réorganisation des structures de données pour exploiter</cell></row><row><cell>la localité spatiale.</cell><cell></cell></row><row><cell cols="3">-La deuxième étape consiste à remplacer la table ER par une Machine à États Finie (FSM) (LSL_FSM)</cell></row><row><cell>(et les calculs associés)</cell><cell></cell></row><row><cell cols="3">-la troisième étape repose sur l'ajout d'un mécanisme de cache de résultats partiels, pour réaliser</cell></row></table><note><p><p><p><p><p><p><p><p><p><p><p><p>3.2. Algorithmes par blocs</p>Afin de réduire le nombre de comparaisons dans la première phase,</p>Grana [9]  </p>propose une approche par bloc (les pixels dans un même bloc 2 × 2 étant nécessairement dans la même composante). L'arbre de décision utilisé pour les algorithmes par bloc est amélioré par Chabardes [5] avec une forêt d'arbres de décision, qui est elle-même ensuite remplacée par un DRAG [3]. Étendre cette approche à un cube 2 × 2 × 2 n'est en pratique pas évident, car cela complexifie énormément l'automate. L'algorithme Entropy Partition Decision Tree [28] repose sur une approche intermédiaire avec des blocs 2×1×1 (EPDT_19c et EPDT_22c, avec prise en compte de 19 et 22 pixels voisins respectivement) ou 2 × 2 × 1 (EPDT_26c).</p>3.3. Algorithmes par segments</p>Bien que les approches par blocs se montrent efficaces, il est également possible de grouper les pixels en segments : suites continues de pixels. Un pré-traitement d'encodage en segments (Run Length Encoding, noté RLE par la suite) est alors appliqué avant la recherche des composantes. Ensuite, l'algorithme d'étiquetage établi les adjacences entre segments (superpositions entre segment actuel et segment de la ligne précédente) et effectue les fusions de composantes si nécessaire. Cette approche par segments est employée par He dans Run Based Two Scans (RBTS) sur images 2D [18] et en 3D avec RBTS 3D</p>[19]</p>. L'utilisation de segments a également été proposée par Lacassagne avec le Light Speed Labeling (LSL)</p>[15]</p>[16] dans le cadre des images 2D. Outre un encodage RLE, il introduit plusieurs structures de données intermédiaires afin de simplifier le calcul des voisinages, en compensant la perte des coordonnées des pixels par une position relative des segments. Bien que le LSL soit aujourd'hui l'un des algorithmes les plus efficaces en 2D, aucune adaptation à la 3D n'a été proposée. Il est pourtant un très bon candidat puisque la compression en segments permettrait d'atténuer l'explosion combinatoire qui accompagne l'ajout d'une troisième dimension. l'union/unification avec des double-lignes (LSL_FSM_DOUBLE), afin de tirer parti de la localité temporelle (là où la première étape ciblait la localité spatiale) g = 16) Pour les images médicales, LSL_ER est dans l'ensemble plus rapide que l'Etat-de-l'Art (Figure</p>3</p>) : bien que RBTS soit ×1.1 plus rapide sur mitochondria, il est également ×1.3 plus lent sur OASIS. À l'inverse, bien que PRED++ 3D soit aussi rapide sur OASIS, il est ×1.3 plus lent sur mitochondria. Les limites du LSL s'expliquent par la durée de l'étape de RLE, particulièrement sur les grandes images (de 60% à 70% du temps d'exécution sur mitochondria). Non seulement le RLE créé une table de segment (RLC) mais en plus, l'initialisation de la table ER est couteuse, car celle-ci contient 1 élément par pixel.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Ces résultats s'expliquent essentiellement par le surcoût engendré dans la phase d'unification. En effet, même si la phase RLE est accélérée par l'absence du calcul de ER, la complexité de la machine à états 3D (27 états et 55 transitions, contre 8 états et 14 transitions pour la FSM en 2D) dégrade fortement les performances du prédicteur de branchement lors de cette deuxième phase. Cela est naturellement plus prégnant sur des images complexes, où il y a plus d'unifications avec une variété de configurations (et donc de transitions empruntées) plus grande.</figDesc><table /><note><p>) : sur mitochondria (granularite elevée), LSL_FSM améliore le temps d'exécution par rapport à LSL_ER d'un facteur ×1.1, et à l'inverse LSL_FSM est plus lent sur OASIS d'un facteur ×0.95.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>unification par double-ligne est efficace et réduit le temps d'exécution du LSL3D : le temps d'unification (qui ne requiert plus de table ER supplémentaire) se retrouve très optimisé. Le goulot d'étranglement devient alors la phase de pré-traitement (encodage RLE) et le ré-étiquetage final (phase 3, voir Section 2.1). Ainsi, sur la Figure3, ils représentent 70% du temps d'exécution sur les images complexes (OASIS) et jusqu'à 90% sur les images simples (mitochondria). Heureusement, ces phases se prêtent toutes deux bien à des travaux de parallélisation au niveau instruction avec le SIMD. Plusieurs propositions ont d'ailleurs étés faites dans ce sens pour des images 2D[17]. Nous avons donc repris l'idée de ces travaux pour les adapter aux images 3D et ainsi réalisé trois implémentations parallèles pour différents jeux d'instruction SIMD, à savoir le SSE4, l'AVX2 et l'AVX512. Les résultats présentés sur la Figure2(une colonne par implémentation) montrent que quelque soit le jeu d'instructions, l'utilisation du SIMD réduit le temps d'exécution de toutes nos versions sur les images aléatoires. À lui seul le SSE4 suffit à rendre LSL_ER plus rapide que tous les algorithmes de l'état de l'art d'un facteur ×1.1 à ×2.6. On retrouve aussi ces bons résultats sur les benchmarks de la littérature (Figures3a et 3b), avec un speedup de ×1.4 à ×2.0 plus rapide que l'état de l'art sur mitochondria et OASIS (Figure3). Le passage à des instructions plus complexes traitant des registres plus grand n'apportent pas de performances sur des images simples, mais permettent tout de même d'améliorer de 10% les performances sur les images complexes d'OASIS. On peut d'ailleurs observer ce même phénomène sur les images aléatoires où l'on observe une amélioration des performances avec une forte densité pour une granularité g = 4.</figDesc><table><row><cell cols="2">Compas'2022 : Parallélisme/ Architecture/ Système</cell><cell></cell><cell></cell></row><row><cell cols="2">MIS/UPJV -Amiens France, 5-8 juillet 2022</cell><cell></cell><cell></cell></row><row><cell>LEB_3D RBTS_3D</cell><cell>SAUFpp_3D PREDpp_3D</cell><cell>EPDT_3D_22c LSL_ER</cell><cell>LSL_FSM LSL_FSM_DOUBLE</cell></row><row><cell>([HFXWLRQ7LPH&gt;PV@</cell><cell></cell><cell></cell><cell></cell></row><row><cell>'HQVLW\&gt;@</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Plus précisément, nous avons été confrontés, pour l'AVX2 à l'absence d'instruction compress (sélection</cell></row><row><cell cols="4">d'éléments à partir d'un masque) nous forçant à utiliser l'implémentation SSE de la look-up table durant</cell></row></table><note><p>l'étape de RLE, limitant d'autant le speed-up apportés par l'AVX2. Dans le cas de l'AVX512, l'instruction compress est bien présente. Malheureusement, sur le Xeon, elle n'est disponible que pour des éléments de 32-bits, nous obligeant à ajouter une conversion supplémentaire vers le 16-bits pour le traitement des segments (pour des raisons de localité mémoire, la table RLC utilise des entiers de 16-bits). Malgré toutes ces limites, notre algorithme LSL_DOUBLE et son implémentation sur AVX512 se montre en moyenne ×1.5 à ×3.0 plus rapide que le meilleur algorithme de l'État-de-l'Art.</p></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
