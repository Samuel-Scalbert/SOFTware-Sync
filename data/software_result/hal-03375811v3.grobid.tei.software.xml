<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">State estimation in nonlinear parametric time dependent systems using Tensor Train</title>
				<funder ref="#_Xtp6eK4">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher />
				<availability status="unknown"><licence /></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Lombardi</forename><surname>Damiano</surname></persName>
							<email>damiano.lombardi@inria.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">COMMEDIA</orgName>
								<orgName type="institution">Inria Paris</orgName>
								<address>
									<addrLine>2 rue Simone Iff</addrLine>
									<postCode>75012</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Inria Paris</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">State estimation in nonlinear parametric time dependent systems using Tensor Train</title>
					</analytic>
					<monogr>
						<imprint>
							<date />
						</imprint>
					</monogr>
					<idno type="MD5">DBB436266665E0A5BA1FF6A3D60B8CF3</idno>
					<idno type="DOI">10.1002/nme.7067</idno>
					<note type="submission">Received: Added at production Revised: Added at production Accepted: Added at production DOI: xxx/xxxx</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-03-07T09:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid" />
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>State Estimation</term>
					<term>Reduced-order modelling</term>
					<term>Tensor Train</term>
				</keywords>
			</textClass>
			<abstract>
<div><p>In the present work we propose a reduced-order method to solve the state estimation problem when nonlinear parametric time-dependent systems are at hand. The method is based on the approximation of the set of system solutions by means of a Tensor Train format. The particular structure of Tensor Train makes it possible to set up both a variational and a sequential method. Several numerical experiments are proposed to assess the behaviour of the method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div><head n="1">INTRODUCTION</head><p>State estimation is one of the fundamental problems in data assimilation, and we refer to <ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5</ref> for a general introduction to this topic. As many problems in the realm of data assimilation, state estimation often involves a heavy computational burden, making it a challenging or a prohibitive task.</p><p>The classical formulation of state estimation problems is the so called variational formulation: state estimation is recast as an optimisation problem in which the cost function is a norm of the discrepancy between the measurements and the state observations (a comprehensive overview can be found in <ref type="bibr" target="#b0">1</ref> ). In order to mitigate the computational cost of variational approaches, several studies proposed to replace the costly full-order model by a reduced-order one <ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14</ref> . Equivalently, in a number of contributions in the literature, a low rank constraint has been taken into account <ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16</ref> .</p><p>Sequential methods (we refer to <ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22</ref> ) are an alternative route to data assimilation. These are suitable in cases in which the data are acquired progressively, consisting often in long time series, and when data assimilation is a step towards control tasks in quasi real time. From a computational point of view, we can see sequential methods as a viable way to substantially decrease the computational cost with respect to variational data assimilation.</p><p>In several studies the authors proposed methods to further reduce the computational cost of sequential methods by using reduced-order models <ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27</ref> .</p><p>Recently, tensor methods have been considered in order to solve inverse problems and data assimilation problems in an efficient way. In <ref type="bibr" target="#b27">28</ref> tensor methods are used to speed-up the bayesian inverse problem arising in electromyography. Tensor methods have been proposed to mitigate the high complexity of the Kalman filter with the state dimension in <ref type="bibr" target="#b28">29</ref> and in combination with a Kalman filter strategy to identify multilinear forms in <ref type="bibr" target="#b29">30</ref> . In <ref type="bibr" target="#b30">31</ref> a tensor Henkel completion problem is introduced in order to perform data assimilation for traffic speed estimation.</p><p>A different approach consists in casting state estimation as an optimal recovery problem ( 32 ): this is what is done, for instance, by the Parametrized Background Data Weak (PBDW) method <ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38</ref> . PBDW has been originally proposed for static problems. It has been adapted to time dependent problems in <ref type="bibr" target="#b38">39</ref> .</p><p>In the present work we investigate a possibility of exploiting a tensor approximation of a set of solutions of a non-linear parametric time dependent dynamical system in order to set up a data assimilation framework which is similar, in the spirit, to optimal recovery problems. The main advantage of optimal recovery is related to the possibility of performing state estimation without performing parameter estimation. Indeed, parameters influence the state in a highly non-linear way: parameter estimation often reduces to a non-linear non-convex optimisation problem, potentially cumbersome to be solved. One of the contributions of the present work is the extension of optimal recovery to time dependent problems, taking into account the noise and the level of confidence we have in the model. In particular, we show that, if a set of solutions is represented as a Tensor Train (TT, we refer to <ref type="bibr" target="#b39">40</ref> ), it is possible to cast state estimation in two different ways:</p><p>1. Variational. We formulate optimal recovery in space time. The proposed approach is similar, in the spirit, to the time adaptation of PBDW (presented in <ref type="bibr" target="#b38">39</ref> ). The main difference consists in the fact that we do not introduce, here, the saddle point problem typical of the PBDW method. Instead, we opt for a penalised formulation which makes it possible to deal in a natural way with noisy data and incorporate the notion of confidence both in model and data. Another difference consists in the fact that the TT approximation can be seen as a dynamical basis approximation. As we will detail in the next section, this is appealing in view of performing the error analysis, interpret the observability of the system, and derive a sequential approach.</p><p>2. Sequential. The particular choice of the TT approximation makes it possible to easily derive a sequential state estimation. Since the problem to be solved is linear and we restrict to linear observation operators, the resulting approach is a particularisation of the Kalman filter.</p><p>The structure of the work is as follows. In Section 2 we introduce the notation used throughout the whole manuscript. In Section 3 we present the main idea of the method, the variational and the sequential formulation as well as the error analysis. In Section 4 we present three numerical experiments in order to assess the behaviour of the method.</p></div>
<div><head n="2">NOTATION.</head><p>Let , ∈ ℕ * , let Ω ⊂ ℝ be an open bounded set, the physical domain, let Θ ⊂ ℝ be the parameters domain. In the following we denote a point ∈ Ω, a parameter vector ∈ Θ and the time by ∈ [0, ]. The system state is a real valued function</p><formula xml:id="formula_0">∈  (Ω × [0, ] × Θ),</formula><p>where  is a suitable Banach space:</p><formula xml:id="formula_1">( , , ) ∶ ⎧ ⎪ ⎨ ⎪ ⎩ Ω × [0, ] × Θ → ℝ ( , , )  → ( , , )<label>(1)</label></formula><p>For sake of simplicity we consider here a scalar function, the extension to vector valued functions being straightforward (Indeed, some cases will be presented in Section 4).</p><p>In general, the system state is governed by an equation of the form  ( , , , ) = 0. In the present work we make the following assumptions:</p><formula xml:id="formula_2">1. The system state ∈  ⊆ 2 (Ω × [0, ] × Θ). It holds 2 (Ω × [0, ] × Θ) = 2 (Ω) ⊗ 2 ([0, ]) ⊗ 2 (Θ).</formula><p>We denote the 2 scalar product of two elements , ∈ 2 (Ω) as ⟨ , ⟩ 2 (Ω) .</p><p>2. We introduce an approximation of the state in a Tensor Train format <ref type="bibr" target="#b39">40</ref> and we assume that the Tensor Train formulation has been computed or rounded by means of the TT-SVD algorithm (presented in <ref type="bibr" target="#b39">40</ref> ). We consider here a continuous formulation, and, with a slight abuse of notation we introduce the TT format for a multivariate function for which the function domain is the cartesian product of domains. Tensor train in a continuous setting has been presented in <ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42</ref> . We choose here to set the variable index order as to be --. This a priori arbitray choice is motivated by the problem at hand, in which we would like to estimate a space-time field, resulting from a linear combination of few space-time modes. Let 1 , 2 ∈ ℕ * be the TT-ranks and</p><formula xml:id="formula_3">1 = 1, … , 1 , 2 = 1, … , 2 .</formula><p>The space modes are defined as 1 ∈ 2 (Ω):</p><formula xml:id="formula_4">1 ( ) ∶ ⎧ ⎪ ⎨ ⎪ ⎩ Ω → ℝ  → 1 ( )<label>(2)</label></formula><p>The time-dependent TT-core is defined as a matrix function whose entries 1 2 ∈ 2 (0, ) read:</p><formula xml:id="formula_5">1 2 ( ) ∶ ⎧ ⎪ ⎨ ⎪ ⎩ [0, ] → ℝ  → 1 2 ( )<label>(3)</label></formula><p>The parameter modes are real valued functions 2 ( ) ∈ 2 (Θ) defined as:</p><formula xml:id="formula_6">2 ( ) ∶ ⎧ ⎪ ⎨ ⎪ ⎩ Θ → ℝ  → 2 ( )<label>(4)</label></formula><p>The TT approximation of the system state is:</p><formula xml:id="formula_7">( , , ) ≈ 1 ∑ 1 =1 2 ∑ 2 =1 1 ( ) 1 2 ( ) 2 ( ).<label>(5)</label></formula><p>This is the way in which the model will be taken into account in the data assimilation problem, and it is efficient provided that the ranks 1 , 2 are not too large. The system state can be observed through a process, which provides, in general, partial and noisy measurements. In the present work we make the following assumptions:</p><p>1. A measurement is an application of a linear form on the system state.</p><p>2. The noise is additive, unbiased and independent.</p><p>3. The noise has a finite covariance.</p><p>Let ∈ ℕ * denote the number of measurements and = 1, … , . As a consequence of the hypothesis that the measurements are linear forms applied to the state, there exists a set of elements ∈ 2 (Ω) (in a more general setting, an element of the dual space  * ) such that the measurement is the scalar product between the state and the elements . In this paper, we will denote = 1≤ ≤ the set of representers and ⟨ , ⟩ 2 (Ω) the set of observables, defined as follows. The observable is a vector valued function ∈ [ 2 ([0, ] × Θ)] , = ⟨ , ⟩ 2 (Ω) whose components are defined as:</p><formula xml:id="formula_8">( , ) ∶ ⎧ ⎪ ⎨ ⎪ ⎩ [0, ] × Θ → ℝ ( , )  → ( , ) = ⟨ , ⟩ 2 (Ω)<label>(6)</label></formula><p>A system instance is featured by a specific value * and when it is observed at time * this produces a real vector * ∈ ℝ . The second hypothesis on the nature of the measurements simply means that we can model them as: * = ( * , * ) + .</p><p>(</p><formula xml:id="formula_9">)<label>7</label></formula><p>The third hypothesis translates into the fact that we can introduce a norm based on the covariance ∈ ℝ × , defined as follows:</p><formula xml:id="formula_10">∈ ℝ , ‖ ‖ 2 = -1 . (<label>8</label></formula><formula xml:id="formula_11">)</formula><p>In the present work we will make use of some terms and notation related to tensor scientific computing, in particular fibres and slices. When translated to the continuous formulation, a fibre is a function depending upon one single variable (e.g. we fix = 0 , = 0 and we consider ( , 0 , 0 )). The slices are functions depending upon two variables, for instance ( , , 0 ).</p></div>
<div><head n="3">THE METHOD.</head><p>The main idea which is investigated in the present contribution is the following. We would like to estimate the system state without explicitly computing the hidden parameters . Under the assumptions presented in the previous section, by leveraging the properties of the TT approximation, we can achieve this goal by solving a linear problem.</p><p>Let us assume that the 'true' state of the system is * ( , ) and there exists at least one parameter value * ∈ Θ such that the distance between the TT-model and the true state is less than a prescribed accuracy. In general, the existence of a unique parameter value such that the TT-model is the closest possible to the true state is an open question (identifiability), and it is not investigated in this work.</p><p>When introducing a value * ∈ Θ in the parameters modes of the TT expression we get a real vector * ∈ ℝ 2 whose entries are:</p><formula xml:id="formula_12">* 2 = 2 ( * ).</formula><p>In this context, performing a state estimation amounts to finding an approximation ∈ ℝ 2 of * by exploiting a set of measurements at different times. Let us call ̂ the resulting state approximation:</p><formula xml:id="formula_13">̂ ( , ) = 1 ∑ 1 =1 2 ∑ 2 =1 1 ( ) 1 2 ( ) 2 . (<label>9</label></formula><formula xml:id="formula_14">)</formula><p>Instead of solving a heavily non-linear problem to find , we directly try to estimate the state by solving a linear problem for . Several remarks are in order.</p></div>
<div><head>Remark.</head><p>For sake of simplicity in the presentation, we have considered here the case in which the solution variability is purely related to the parameters. Of course in general there can be a variability in the initial and boundary conditions too. This can be taken into account in a similar way. Indeed, once the TT approximation of the set of solutions is available, the state estimation problem simply translates into a linear problem for . We would like to estimate a linear combination of space-time modes in such a way that the discrepancy between measurements and model observations is low in norm.</p></div>
<div><head>Remark.</head><p>The TT approximation introduced above can be interpreted as a dynamical basis approach in view of solving the data assimilation problem, indeed:</p><formula xml:id="formula_15">̂ ( , ) = 2 ∑ 2 =1 1 ∑ 1 =1 1 ( ) 1 2 ( ) 2 . (<label>10</label></formula><formula xml:id="formula_16">)</formula><p>The actual approximation of the state is obtained as a linear combination with constant in time weights of the time-varying modes determined by the contraction of the space modes 1 with the time dependent core 1 2 . For every time we can consider</p><formula xml:id="formula_17">∑ 1 1 =1 1 ( ) 1<label>2</label></formula><p>( ) as a set of 2 space modes built by means of a linear combination of 1 space ambient modes 1 . When</p><p>2 &lt; 1 we are in a case in which the ambient space is bigger and we consider a linear subspace embedded in it and evolving in it. When considering the case 2 &gt; 1 we are performing a lifting thanks to the core , introducing a redundant dictionary of linear dependent space modes.</p></div>
<div><head>Remark.</head><p>In the present work, we will construct a database of solutions of the system for different values of the parameters and then we will determine the Tensor Train by using the TT-SVD algorithm (detailed in <ref type="bibr" target="#b39">40</ref> ). Given the system equation  ( , , , ) = 0 we could directly construct an approximation in Tensor Train format of the set of solutions <ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49</ref> . This is an appealing possibility in view of realistic applications.</p></div>
<div><head n="3.1">Variational data assimilation.</head><p>The variational data assimilation approach consists in recasting the state estimation as an optimisation problem. Let ∈ ℕ * be the number of time observations. Let = 1, … , and the observation times be ∈ [0, ]. The set of observations is * ∈ ℝ .</p><p>The problem consists in finding ∈ ℝ 2 such that a misfit functional,  , is minimised.</p><formula xml:id="formula_18"> ( ) ∶ ⎧ ⎪ ⎨ ⎪ ⎩ ℝ 2 → ℝ +  →  ( ) = 1 2 ∑ =1 ‖ * -⟨ ̂ ( , ), ⟩ 2 (Ω) ‖ 2</formula><p>A regularisation by means of a prior can be introduced. Let 0 ∈ ℝ 2 × 2 be a symmetric positive definite matrix. A norm can be induced by the scalar product:</p><formula xml:id="formula_19">∈ ℝ 2 , ‖ ‖ 2 0 = -1 0 .</formula><p>Let 0 ∈ ℝ 2 be the value used to regularise . It could be taken as the mean of a prior on , 0 being the prior covariance. The inverse of the covariance -1 0 represents the confidence level in the prior. From a mathematical point of view, the regularisation provides stability and, as shown in Section 3.1.1, ensures uniqueness of the solution. The minimisation problem to be solved reads:</p><formula xml:id="formula_20">̂ = arg inf ∈ℝ 2  ( ) + 1 2 ‖ -0 ‖ 2 0 . (<label>11</label></formula><formula xml:id="formula_21">)</formula><p>In view of solving the optimisation problem for we have to discuss the space discretisation of the tensor. Let the state be approximated in space by means of a generic method, for instance finite differences, elements or volumes. The only step in which the space discretisation of the state appears (besides the reconstruction) is the scalar product ⟨ ̂ , ⟩ 2 (Ω) . Let us consider, as an example, a ̂ ( , ) discretised by means of finite elements with ∈ ℕ * degrees of freedom. Let ( ) 1≤ ≤ be the set of basis functions, Φ ∈ ℝ × 1 be the matrix whose entries are the values of the degrees of freedom of the space modes approximation. It holds:</p><formula xml:id="formula_22">̂ ( , ) ≈ 1 ∑ 1 =1 2 ∑ 2 =1 ∑ =1 Φ 1 ( ) 1 2 ( ) 2 .</formula><p>Let the generic , 1 ≤ ≤ (the Riesz representer of the -th measurement) be discretised on the same finite element basis (the values of the degrees of freedom being stored in a matrix Ξ ∈ ℝ × ):</p><formula xml:id="formula_23">≈ ∑ =1 Ξ ( ).</formula><p>The scalar product is discretised as follows:</p><formula xml:id="formula_24">⟨ ̂ ( , ), ⟩ 2 (Ω) ≈ 1 ∑ 1 =1 2 ∑ 2 =1 ∑ =1 ∑ =1 Ξ Φ 1 ⟨ , ⟩ 2 (Ω) 1 2 ( ) 2 ,</formula><p>in which ⟨ , ⟩ 2 (Ω) are the entries of the mass matrix. Concerning the time discretisation: we need to be able to evaluate (or approximate) the values of the core for = . In the case in which 1≤ ≤ coincide with the points of the time discretisation used (or a subset of the time points considered) this evaluation is straightforward. In cases in which the observation times do not coincide we need to consider an interpolation. In the tests presented in this work, for sake of simplicity, we considered cases in which the observation time instants coincide with the time points used for the discretisation.</p></div>
<div><head n="3.1.1">Existence and uniqueness of the solution.</head><p>The problem presented in Eq.( <ref type="formula" target="#formula_20">11</ref>), with the regularisation term ‖ -0 ‖ 2 0 admits a unique solution. This can be deduced by the expression of the function  . Indeed, provided that 0 is symmetric and positive definite, it is a strictly convex function, such that lim ‖ ‖ 2, →∞  ( ) = +∞. This implies that there exists, unique, the minimiser of the problem. In this case, there exists a unique stationary point, which is also the global minimum, solution of the Euler-Lagrange equations. Let us introduce some notation. Let ∈ ℝ × 1 be the Grammian matrix corresponding to the observation of the space modes 1 ( ):</p><formula xml:id="formula_25">1 = ⟨ 1 , ⟩ 2 (Ω) .</formula><p>Let Ψ ∈ ℝ × × 2 be a third order tensor whose expression reads:</p><formula xml:id="formula_26">Ψ 2 = 1 ∑ 1 =1 1 1 2 ( ).</formula><p>It represents the observation of the time evolving modes that are used to approximate the model state. Henceforth, the observation of the model outcome reduces to the linear combination of these:</p><formula xml:id="formula_27">̂ ( ) = 2 ∑ 2 =1 Ψ 2 2 , 1 ≤ ≤ ,</formula><p>which is a contraction of the third order tensor by . The slices of Ψ with respect to the index = 1, … , are considered, consisting in matrices: Ψ ( ) ∈ ℝ × 2 . The Euler-Lagrange equations read:</p><formula xml:id="formula_28">-1 0 + ∑ =1 [Ψ ( ) ] -1 [Ψ ( ) ] = -1 0 0 + ∑ =1 [Ψ ( ) ] -1 * . (<label>12</label></formula><formula xml:id="formula_29">)</formula><p>By inspection, we see that the matrix on the left hand side is actually invertible (this condition being ensured by the regularisation), providing a unique solution.</p><p>It is of interest to consider the case of no regularisation, namely -1 0 = 0. In this case, the condition for the system matrix to be invertible depends on the sequence of matrices Ψ ( ) . Let us consider the unfolding of Ψ obtained by stacking vertically the slices Ψ ( ) . This provides a matrix ∈ ℝ ⋅ × 2 :</p><formula xml:id="formula_30">= ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ Ψ (1) Ψ (2) … Ψ ( ) ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦ We introduce ̂ -1 ∈ ℝ ⋅ × ⋅</formula><p>which is a block diagonal matrix in which all the blocks are equal to -1 :</p><formula xml:id="formula_31">̂ -1 = ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ -1 0 … 0 0 -1 … 0 … … … 0 0 … … -1 ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦ It holds: = ∑ =1 [Ψ ( ) ] -1 [Ψ ( ) ] = ̂ -1 . The matrix = ̂ -1 ∈ ℝ 2 × 2 is invertible provided that: rank( ) = 2</formula><p>. This is an Observability condition (perfectly analogue to the Kalman observability <ref type="bibr" target="#b49">50</ref> ). Remark that an approximation of can be obtained by repeated observations in time even for cases in which &lt; 2 , which is a necessary condition for the observability of static systems.</p><p>A way to assess the observability is to estimate the lowest eigenvalue of , denoted 2 .</p></div>
<div><head>Remark.</head><p>In cases in which 2 is not large the smallest eigenvalue can be directly computed. As an alternative, an analytical estimate can be obtained as follows: let</p><formula xml:id="formula_32">= tr([ ̂ -1 ]) 2 and = tr([ ̂ -1 ] 2 ) 2 -2 .</formula><p>In <ref type="bibr" target="#b50">51</ref> Wolkowicz and Styan proved lower and upper bounds for the lowest and the largest eigenvalues values (respectively 2 and 1 ) of a complex square matrix:</p><formula xml:id="formula_33">-( 2 -1) 1∕2 ≤ 2 ≤ - ( 2 -1) 1∕2 , + ( 2 -1) 1∕2 ≤ 1 ≤ + ( 2 -1) 1∕2 .</formula></div>
<div><head n="3.1.2">Error analysis.</head><p>In this section, we study the error in the prediction of a state * ( , , ). The following hypotheses are made:</p><p>( 1 ) Let the best TT approximation of the system at time and parameter be obtained or rounded by the TT-SVD method, denoted by ̂ * . The 2 (Ω) error of the system state satisfies:</p><formula xml:id="formula_34">sup ∈[0, ] sup ∈Θ ‖ * -̂ * ‖ 2 2 (Ω) ≤ 2 ,</formula><p>which is the TT truncation error.</p><p>( 2 ) The noise is additive, independent, unbiased, with covariance ∈ ℝ × .</p><p>Proposition 1. Let the hypotheses 1 -2 hold and let us consider no regularisation ( -1 0 = 0). Let and * be the representation of the best TT state and of the estimated state on the space-time basis. Due to the presence of noise is a random variable.</p></div>
<div><head>Let</head><p>= [ ̂ -1 ] be the observability matrix. It holds:</p><formula xml:id="formula_35">1. ‖ [( - * )]‖ 2, 2 ≤ 1∕2 2 ‖ ‖ [ 2 (Ω)] . 2. [‖ - * ‖ 2 2, 2 ] =≤ tr( -1 ) ≤ 2 2 tr( )-tr( ) 2 + 2 ‖ ‖ 2 -2 2 2 2 ‖ ‖ 2 -2 2 tr( ) .</formula><p>Proof. The equation for is obtained by measuring the true state:</p><formula xml:id="formula_36">= ∑ =1 [Ψ ( ) ] -1 (⟨ , * ( )⟩ 2 (Ω) + ( ) ).</formula><p>Let the TT truncation error (the model error in the present case) be denoted by . By introducing the relationship: * = ̂ * + , we get:</p><formula xml:id="formula_37">( - * ) = ∑ =1 [Ψ ( ) ] -1 (⟨ , ( , * )⟩ 2 (Ω) + ( ) ).</formula><p>There are two contributions to the error: the first one is deterministic and it is related to the observation of the model error (the measurement of the TT truncation error ), the second one is stochastic and it is related to the measurement noise. Since the noise is unbiased, the expectation of the error reads:</p><formula xml:id="formula_38">[( - * )] = -1 ∑ =1 [Ψ ( ) ] -1 ⟨ , ( , * )⟩ 2 (Ω) .</formula><p>Let us consider the singular value decomposition of , = . Then:</p><formula xml:id="formula_39">= [ ̂ -1 ]</formula><p>.</p><p>Henceforth, we have:</p><formula xml:id="formula_40">-1 ∑ =1 [Ψ ( ) ] -1 = -1 ( ̂ -1 ) -1 ̂ -1 .</formula><p>The norm of the observation of the measurement error can be bounded by using the Cauchy-Schwarz inequality:</p><formula xml:id="formula_41">|⟨ , ( , * )⟩ 2 (Ω) | ≤ ‖ ‖ 2 (Ω) ‖ ( , * )‖ 2 (Ω) ≤ ‖ ‖ 2 (Ω)</formula><p>. The 2 norm of the mean error, by virtue of the equations written above satisfies:</p><formula xml:id="formula_42">‖ [( - * )]‖ 2, 2 ≤ 1∕2 2 ‖ ‖ [ 2 (Ω)] . (<label>13</label></formula><formula xml:id="formula_43">)</formula><p>This proves the first point of the proposition.</p><p>The covariance of the error is given by:</p><formula xml:id="formula_44">= [(( - * ) -[ - * ]) ⊗ (( - * ) -[ - * ])].</formula><p>For sake of compactness let us introduce † = -1 ̂ -1 . The covariance of the error, by virtue of the hypotheses on the noise structure, satisfies:</p><formula xml:id="formula_45">ℎ = ∑ , =1 ∑ , =1 † † ℎ = -1 ℎ . (<label>14</label></formula><formula xml:id="formula_46">)</formula><p>The expected value of the 2, 2 norm squared of the error satisfies:</p><formula xml:id="formula_47">[‖ - * ‖ 2 2, 2 ] = tr( ) -[ - * ] 2 ≤ tr( ),</formula><p>where the equality holds for the cases in which the model error is not observable, i.e. ⟨ , ⟩ 2 (Ω) = 0.</p><p>In order to bound the trace of the error covariance, we use a result proved by Bai and Golub in <ref type="bibr" target="#b51">52</ref> :</p><formula xml:id="formula_48">tr( -1 ) ≤ tr( ) 2 ⎡ ⎢ ⎢ ⎢ ⎣ ‖ ‖ 2 tr( ) 2 2 2 ⎤ ⎥ ⎥ ⎥ ⎦ -1 ⎡ ⎢ ⎢ ⎢ ⎣ 2 1 ⎤ ⎥ ⎥ ⎥ ⎦ . (<label>15</label></formula><formula xml:id="formula_49">)</formula><p>This leads to the conclusion.</p><p>The further bound on the trace of the inverse of the observability matrix, obtained by explicitly computing the bound proposed by Bai and Golub, might be computationally appealing in view of estimating the error propagation in large systems. Indeed, it makes it possible to get an estimation without computing and storing the inverse of the observability matrix.</p><p>Proposition 2. Let the hypotheses 1 -2 hold and let us consider no regularisation terms ( -1 0 = 0). Let the error norm squared be denoted by:</p><formula xml:id="formula_50">2 = ‖ * -̂ ‖ 2 2 (Ω×[0, ]) . (<label>16</label></formula><formula xml:id="formula_51">)</formula><p>Due to the presence of noise, this is a random variable. Its expected value satisfies:</p><formula xml:id="formula_52">[ 2 ] ≤ 2 + tr([ ̂ -1 ] -1 ). (<label>17</label></formula><formula xml:id="formula_53">)</formula><p>Proof. Let the TT state approximation be denoted by ̂ . The first step to prove the error bound consists in noticing that the error can be written as follows:</p><formula xml:id="formula_54">‖ * -̂ ‖ 2 2 (Ω×[0, ]) = ∫ 0 ‖ * -̂ ‖ 2 2 (Ω)</formula><p>, which can be rewritten as:</p><formula xml:id="formula_55">∫ 0 ‖ * -̂ * + ̂ * -̂ ‖ 2 2 (Ω) ≤ 2 + ∫ 0 ‖ ̂ * -̂ ‖ 2 2 (Ω) .</formula><p>Let us focus on the second term on the right hand side:</p><formula xml:id="formula_56">∫ 0 ‖ ̂ * -̂ ‖ 2 2 (Ω) = ∫ 0 1 ∑ 1 , 1 ⟨ 1 , 1 ⟩ 2 (Ω) 2 ∑ 2 , 2 1 2 1 2 ( * 2 - 2 )( * 2 - 2 ) .</formula><p>Under the hypothesis that the TT approximation has been obtained or rounded by TT-SVD, it holds:</p><formula xml:id="formula_57">⟨ 1 , 1 ⟩ Ω = 1 , 1 , ∫ 0 1 ∑ 1 1 2 1 2 = 2 , 2 ,</formula><p>leading to:</p><formula xml:id="formula_58">∫ 0 ‖ ̂ * -̂ ‖ 2 2 (Ω) = ‖ * -‖ 2 2, 2 . (<label>18</label></formula><formula xml:id="formula_59">)</formula><p>The result of the previous proposition makes it possible to conclude.</p></div>
<div><head>Remark:</head><p>Let us consider the effect of the regularisation 0 , 0 on the error. The equation for reads:</p><formula xml:id="formula_60">-1 0 + [ ̂ -1 ] = -1 0 + ∑ =1 [Ψ ( ) ] -1 (⟨ , * ( )⟩ 2 (Ω) + ( ) ).<label>(19)</label></formula><p>The equation for * reads:</p><formula xml:id="formula_61">[ ̂ -1 ] * = ∑ =1 [Ψ ( ) ] -1 (⟨ , ̂ * ( )⟩ 2 (Ω) .</formula><p>We add and subtract -1 0 * on both sides:</p><formula xml:id="formula_62">-1 0 + [ ̂ -1 ] * = -1 0 * + ∑ =1 [Ψ ( ) ] -1 (⟨ , ̂ * ( )⟩ 2 (Ω) .</formula><p>We can now subtract this to Eq.( <ref type="formula" target="#formula_60">19</ref>):</p><formula xml:id="formula_63">-1 0 + [ ̂ -1 ] ( - * ) = -1 0 ( 0 - * ) + ∑ =1 [Ψ ( ) ] -1 (⟨ , ( , * )⟩ 2 (Ω) + ( ) )</formula><p>.</p><p>This provides an interpretation on the role the regularisation term plays: the expression is a weighted average between the prior error, encoded by ( 0 - * ) and the measurement error, which is due to the observation of the model error (deterministic part)</p><p>and the noise (stochastic part). The weights of this sum depend on the levels of confidence we have on the prior ( -1 0 ) and on the measurements ( ̂ -1 ). The regularisation term provides stability to the estimation of . There are several possible outcomes: the most favorable one is when the prior and its covariance are pertinent, and this makes it possible to reduce the error due to the noise (and the covariance associated to the estimation). A possible negative scenario is the one in which a prior inducing a large error (i.e. 0 -is large in norm) is enforced with a small covariance (i.e. <ref type="bibr">-1</ref> 0 is large in norm): in this case the error - * will be roughly equal to the prior error 0 -, hence large in norm.</p></div>
<div><head n="3.2">Sequential data assimilation.</head><p>A Tensor Train approximation of the state makes it possible to systematically derive a sequential approach to state estimation. This is is of the utmost interest, since it is the most natural way to deal with applications in which measurements are sets of long time series, acquired progressively, or applications in which the observer is used to set up a control.</p><p>The starting point consists in considering that a model instance (i.e. a state evolution ( , )) is simply identified by a vector ∈ ℝ 2 . As seen in the previous section, the TT approximation of the state can be interpreted as dynamical basis approach: the time evolution is taken into account by the core and the representation of the state on the basis ( ) do not change in time.</p><p>If we write the evolution equation for the representation of the state on the space-time modes we have:</p><formula xml:id="formula_64">= 0.</formula><p>The evolution of the representation of the state is linear, the observations are linear, a Kalman filter is probably the best way to set up a sequential state estimation. Let (0) , (0) be the initial state estimation (a pure a priori value) and its associated covariance.</p><p>Let the model error covariance be</p><formula xml:id="formula_65">( ) 1≤ ≤ ∈ ℝ 2 × 2 .</formula><p>The Kalman filter reads as follows:</p><formula xml:id="formula_66">( +1, ) = ( ) , (<label>20</label></formula><formula xml:id="formula_67">) ( +1, ) = ( ) + ( ) ,<label>(21)</label></formula><p>= * ( +1 ) -Ψ ( +1) ( +1, ) , (</p><formula xml:id="formula_68">= + Ψ ( +1) ( +1, ) [Ψ ( +1) ] ,<label>22)</label></formula><formula xml:id="formula_69">= ( +1, ) [Ψ ( +1) ] -1 (<label>(23)</label></formula><formula xml:id="formula_70">) ( +1) = ( +1, ) + , (<label>24</label></formula><formula xml:id="formula_71">) ( +1) = [ -Ψ ( +1) ] ( +1, )<label>25</label></formula></div>
<div><head n="3.2.1">Error analysis</head><p>The error of the sequential approach is studied. In particular, we prove that, in absence of model error ( ( ) = 0, ∀ ), the estimate provided at final time by the Kalman filter equals the variational one. This is a known result in a standard setting. Here we simply prove that the proposed formulation respects this.</p><p>Proposition 3. Let (0) , (0) be the initial guess of the estimation. Let the model error be zero, i.e. = 0, = 1, … , . The final covariance matrix of the Kalman filter estimation satisfies:</p><formula xml:id="formula_73">[ ( ) ] -1 = [ (0) ] -1 + ̂ -1 .</formula><p>Moreover:</p><formula xml:id="formula_74">( ) = ( ) ,</formula><p>where ( ) satisfies (the reader is referred to Eq.12):</p><formula xml:id="formula_75">[ (0) ] -1 + ̂ -1 ] ( ) = [ (0) ] -1 (0) + ∑ =1 [Ψ ( ) ] -1 ( ) * .</formula><p>Proof. Let us write the Kalman filter as an observer:</p><formula xml:id="formula_76">= ( ) [Ψ ( +1) ] ( + Ψ ( +1) ( ) [Ψ ( +1) ] ) -1 (<label>27</label></formula><formula xml:id="formula_77">) ( +1) = [ -Ψ ( +1) ] ( ) + ( +1) * . (<label>28</label></formula><formula xml:id="formula_78">) ( +1) = [ -Ψ ( +1) ] ( )<label>(29)</label></formula><p>By making use of the Woodbury matrix identity, this iteration can be rewritten as follows:</p><formula xml:id="formula_79">[ ( +1) ] -1 = [ ( ) ] -1 + [Ψ ( +1) ] -1 Ψ ( +1) , (<label>30</label></formula><formula xml:id="formula_80">) ( +1) -1 ( +1) = [ ( ) ] -1 ( ) + [Ψ ( +1) ] -1 ( +1) * . (<label>31</label></formula><formula xml:id="formula_81">)</formula><p>This leads to:</p><formula xml:id="formula_82">( +1) = ( +1) [ ( ) ] -1 ( ) + ( +1) [Ψ ( +1) ] -1 ( +1) * , (<label>32</label></formula><formula xml:id="formula_83">)</formula><p>and iterating for , -1, … , = 1, we obtain:</p><formula xml:id="formula_84">( ) = ( ) [ (0) ] -1 (0) + ∑ =1 [Ψ ( ) ] -1 ( ) * . (<label>33</label></formula><formula xml:id="formula_85">)</formula><p>The estimate of ( ) can be obtained by making use of the equation for the inverse of the covariance. It holds:</p><formula xml:id="formula_86">[ ( ) ] -1 = [ (0) ] -1 + ∑ =1 [Ψ ( ) ] -1 Ψ ( ) , (<label>34</label></formula><formula xml:id="formula_87">)</formula><p>which concludes the proof, since it delivers the same result as the corresponding variational estimation.</p></div>
<div><head n="3.3">Computing the ranks.</head><p>In the present work we rely on the TT-SVD algorithm to compute the TT approximation of the state. In this algorithm, the input parameter is the prescribed accuracy . The TT approximation obtained will be such that ‖ ( , , ) -̂ ( , , )‖ 2 (Ω×[0, ]×Θ) ≤ .</p><p>When discretised, this will be ensured at discrete level, according to the scalar product used in the SVD at each step of the method. The ranks 1 , 2 are obtained as function of . When considering the reconstruction starting from the measurements * , the error depends not only on the ability to well approximate the state, but also on the observability (which is related to the eigenvalue 2 ). There is a trade-off: the larger the ranks the better the state approximation, the larger the ranks the poorer the observability. The error estimators derived makes it possible to obtain an estimation of the ranks. This would require to compute the matrix = ̂ -1 and compute the error bounds varying the ranks, and chose the ones minimising the error bounds. In the present work we will propose two different numerical investigations: first, we will consider two different values of the prescribed accuracy , and use the ranks determined by the TT-SVD algorithm; second, we will vary the ranks ( 1 , 2 )</p><p>and impose them: we will see how these impact the model and the reconstruction errors. In both cases we will monitor the error bounds proposed and assess wether they are sharp enough to provide a good indication.</p></div>
<div><head n="3.4">Complexity of the methods.</head><p>In this section we discuss the computational complexity of the proposed methods, as function of the TT ranks and of the spacetime discretisation of the problem. We start by discussing the computational cost needed to obtain the objects common to both the variational and the sequential methods.</p><p>• The space discretisation plays a role in the computation of the Grammian elements</p><formula xml:id="formula_88">1 = ⟨ 1 , ⟩ 2 (Ω)</formula><p>and when reconstructing the state. Let ∈ ℕ be the number of degrees of freedom in space, the cost of computing the Grammian is:</p><formula xml:id="formula_89">( 1 )</formula><p>.</p><p>• The set of slices Ψ ( ) 1≤ ≤ has a cost of: (</p><p>).</p><p>Concerning the variational method, the cost consists in assembling the linear system and solving it:</p><p>• The cost of assembling the system matrix is:</p><formula xml:id="formula_91"> ( 2 2 + 2 2 )</formula><p>. The cost of assembling the right hand side is:</p><formula xml:id="formula_92"> ( 2 + 2 ) .</formula><p>• Solving the linear system with a direct solver (noticing that it is symmetric positive definite) costs ( 3 2 ∕3), by using a conjugate gradient method, we could have a cost scaling as ( <ref type="formula" target="#formula_4">2</ref>2 ).</p><p>Concerning the sequential method, the cost of one time iteration of the Kalman filter is:</p><p>• Updating the covariance by adding the model error: ( <ref type="formula" target="#formula_4">2</ref>2 ).</p><p>• Computing the matrix : ( 2 2 + 2 2 )</p><p>• Computing the Kalman filter gain : ( 3 2 + 2 2 ). By solving a set of linear systems with iterative methods (to compute -1 ) we have a complexity of 2 for every linear system.</p><p>• Update of the state and covariance: ( 2 ) and ( <ref type="formula" target="#formula_4">2</ref>2 + 3 2 ).</p><p>This cost has to be multiplied by in order to obtain the total cost. By looking at the computational cost we see that it scales, for both methods, linearly with respect to , and at most cubically in the rank 2 , quadratically or cubically in . This has to be compared to the cost a standard method of data assimilation would have. Let us consider, for instance, a system whose state evolution is governed by a PDE. A classical variational method would consist in solving a direct system, an adjoint system and performing an update. When considering a time marching scheme for both the direct and the ajoint, iterative solvers, this would generally scales as ( 2 ). The number of optimisation iterations needed would be, typically, between 10 2 and 10 3 . Of course, as for all reduced order methods, we need to discuss about the offline cost, which is represented, in the present context, by the TT approximation of the system solutions. As for all reduced-order methods applied to data assimilation, the splitting offline-online is advantageous in all applications in which we need to perform data assimilation multiple times.</p></div>
<div><head n="4">NUMERICAL EXPERIMENTS.</head><p>Several numerical experiments are proposed to illustrate the method and assess its properties and performances.</p><p>In all the test cases presented in this section, we will consider, as a measure of quality of the reconstruction, the relative 2 error of the state reconstruction:</p><formula xml:id="formula_93">= ∫ 0 ∫ Ω ( * -̂ ) 2 ∫ 0 ∫ Ω ( * ) 2<label>(35)</label></formula><p>In particular, the methods proposed in the present work will be tested on ∈ ℕ random instances, and the mean and the standard deviation of will be computed, denoted by and respectively. The subscripts and will be used to denote the results obtained by the variational and the sequential approaches. In the variational estimation we did not consider any regularisation.</p><p>Concerning the initial condition for the Kalman filter, we computed the mean value of for the TT approximation of the state, and we took 0 as 20 times the covariance of . This choice models the fact that we do not want to impose a strong prior (the average solution) on the state.</p><p>To assess the observability of the system in different configurations, we will compute the smallest eigenvalue of the observability matrix and the Bai and Golub bound of the trace of its inverse (denoted by ).</p></div>
<div><head n="4.1">1D-1D Fisher-Kolmogorov-Petrovski-Piskunov equation.</head><p>The </p><formula xml:id="formula_94">0 ( ) = exp -( -) 2 . (<label>36</label></formula><formula xml:id="formula_95">)</formula><p>The equation reads:</p><formula xml:id="formula_96">= 2 + (1 -),<label>(37)</label></formula><formula xml:id="formula_97">(0, ) = (1, ) = 0,<label>(38)</label></formula><formula xml:id="formula_98">( , 0) = 0 . (<label>39</label></formula><formula xml:id="formula_99">)</formula><p>The problem has been discretised by means of standard piece-wise linear finite elements with a number of degrees of freedom respectively.</p><p>• The tests are performed by considering the solutions obtained by simulating the system when = 100 random samples of the parameters are drawn from a uniform distribution in the range of the parameters considered for the database. We will consider the average and the standard deviation of the relative error.</p><p>An example of the reconstruction obtained by the variational method is shown in Fig. <ref type="figure" target="#fig_1">1</ref>.c). The results of the numerical experiments are summarised in Table <ref type="table" target="#tab_1">1</ref>. In general, we see that a better observability of the system (encoded in the eigenvalue and the theoretical bound) translates into better results in terms of error on the state reconstruction. In this respect, having a more precise model does not guarantee to have a better result: indeed, consider the case of scarce observations = 8; when = 10 -3 a large number of TT-modes implies a poor observability (a lack of regularisation), and an error which is around 60% (obtained by means of a variational approach) with a moderate level of noise, contrary to the case = 10 -2 , for which the error is around 4%. Of course, when rich observations are available = 64, a less precise model results in a saturation of error. We see that, with a variational approach, the error is around 1.3% for = 10 -3 and it stays around 2% for = 10 -2 , as when taking only = 32 observations into account. This is due to the fact that, for a less precise model, the TT truncation error starts polluting the reconstruction result.</p><p>We study the evolution of the error as function of the ranks ( 1 , 2 ) of the TT approximation of the state. We fix = 32 and -1 = 10   5.0 10 -2 6.3 10 -3 5.6 10 -2 6.2 10 -3 10 800 5.3 10 -2 1.41 10 3 4.9 10 -1 5.2 10 -2 6.4 10 -3 5.7 10 -2 6.6 10 -3 20 100 2.0 10 -2 5.96 10 2 6.4 10 -2 2.7 10 -2 8.0 10 -3 3.3 10 -2 9.7 10 -3 20 200</p><p>1.8 10 -2 3.98 10 2 1.4 10 -1 2.3 10 -2 4.4 10 -3 3.1 10 -2 7.8 10 -3 20 400</p><p>1.8 10 -2 3.44 10 2 3.1 10 -1 2.1 10 -2 3.8 10 -3 3.5 10 -2 6.2 10 -3 20 800</p><p>1.8 10 -2 3.41 10 2 6.1 10 -1 2.2 10 -2 3.7 10 -3 4.1 10 -2 5.5 10 -3 40 100</p><p>1.4 10 -2 3.77 10 2 6.3 10 -2 2.9 10 -2 1.1 10 -2 3.3 10 -2 1.3 10 -2 40 200</p><p>6.8 10 -3 9.01 10 1 1.5 10 -1 2.3 10 -2 9.6 10 -3 2.7 10 -2 8.1 10 -3 40 400</p><p>5.0 10 -3 2.48 10 1 9.6 10 -1 1.9 10 -2 7.4 10 -3 2.8 10 -2 6.9 10 -3 40 800</p><p>4.9 10 -3 7.61 10 0 1.3 10 1 2.1 10 -2 9.7 10 -3 3.5 10 -2 6.1 10 -3 80 100 1.4 10 -2 3.80 10 2 6.3 10 -2 3.0 10 -2 1.0 10 -2 3.3 10 -2 1.2 10 -2 80 200</p><p>6.1 10 -3 8.59 10 1 1.5 10 -1 2.1 10 -2 9.0 10 -3 2.6 10 -2 8.0 10 -3 80 400 2.6 10 -3 2.93 10 1 7.0 10 -1 2.1 10 -2 1.2 10 -2 2.6 10 -2 7.4 10 -3 80 800</p><p>1.5 10 -3 8.85 10 0 8.9 10 0 2.6 10 -2 1.4 10 -2 2.9 10 -2 4.9 10 -3 observe that the and provide a good indication on the reconstruction error. We see that a more precise model (lower )</p><p>does not necessary imply a lower reconstruction error (and a small variance) if the observability deteriorates.</p></div>
<div><head n="4.1.1">4D-var estimation.</head><p>We present in this section the formulation of the 4D-var state estimation and comment about the results we obtain for this test case. Contrary to when using the proposed approach, which is based on an optimal recovery principle, when applying 4D-var we have to perform a joint state-parameter estimation. The problem reads as follows: * , * , * = arg inf , sup ( , , ),</p><formula xml:id="formula_100"> = ∑ =1 1 2 ‖ ( ) -(̂ , , )‖ 2 2, -∫ 0 ∫ Ω ( -2 -(1 -)) ̂ = [ 1 , … , ].</formula><p>To solve the problem, we proceeded as follows: first, we considered a discretisation of the direct system; then, we derived the Euler-Lagrange equations, obtaining the adjoint (backward equation) and the gradients with respect to the parameters. We solved the optimisation, in a classical forward-backward strategy. We have run the tests varying the number of measurements and the noise, obtaining analogous results with respect to the ones shown above. The cost is, roughly, two orders of magnitude larger than the one we need with the TT-based method. Clearly, the result and the cost depend heavily on the initialisation chosen for the parameters. As this is a non-linear non-convex optimisation problem (parameters affect the state evolution in a heavily non-linear way), local minima make it necessary to perform the optimisation multiple times, for multiple initialisations.</p><p>This illustrates well one of the advantages of optimal recovery methods, i.e. the possibility of solving state estimation without performing parameter estimation.</p></div>
<div><head n="4.2">Arnold-Beltrami-Childress flow.</head><p>The Arnold-Beltrami-Childress (ABC) flow is an example of chaotic dynamical system, whose solution is also a solution of the Euler equations written in a Lagrangian framework. Let = ( , , ) ∈ ℝ 3 , ∈ [0, 4], ( , , ) ∈ [0.9, 1.1] 3 . The system of equations reads:</p><formula xml:id="formula_101">̇ = sin( ) + cos( ), ̇ = sin( ) + cos( ), ̇ = sin( ) + cos( ).<label>(40)</label></formula><p>The initial condition for the system is a set of = 64 points, ( ) 0 , 1 ≤ ≤ 64, uniformly distributed in [0, 1] 3 . We chose a final time = 4 to discretise the equations with a Δ = 0.04. The problem we solve is the following: we observe trajectories our of 64, with some noise. Based on these observations, we try to reconstruct the whole set of 64 Lagrangian trajectories. An example of solution is presented in Fig. <ref type="figure" target="#fig_3">2</ref>.a). We solved the data assimilation problems in the following configurations:    • We considered two different levels of noise: -1 = 10 4 , 10 2</p><p>• The value of = 10 -2 , 10 -3 . For the case considered the TT ranks are ( 1 = 20, 2 = 10) and ( 1 = 48, 2 = 31)</p><p>respectively.</p><p>• The tests are performed by considering the solutions obtained by simulating the system when = 100 random samples of the parameters are drawn from a uniform distribution in the range of the parameters considered for the database. 1.5 10 -2 6.3 10 -3 1.9 10 -2 8.9 10 -3 16 16  7.3 10 -3 7.03 10 0 1.4 10 0 1.5 10 -2 8.7 10 -3 1.7 10 -2 1.2 10 -2 16 24  7.3 10 -3 3.49 10 0 4.3 10 0 1.4 10 -2 4.5 10 -3 1.4 10 -2 8.1 10 -3 16 32  7.3 10 -3 2.66 10 3 7.5 10 0 1.7 10 -2 7.5 10 -3 1.4 10 -2 7.4 10 -3 32 8</p><p>9.1 10 -3 9.54 10 0 5.2 10 -1 1.0 10 -2 3.1 10 -3 1.7 10 -2 7.3 10 -3 32 16  3.1 10 -3 1.47 10 0 7.82 10 0 8.3 10 -3 2.4 10 -3 9.1 10 -3 3.4 10 -3 32 24  1.7 10 -3 5.01 10 -1 3.6 10 1 1.0 10 -2 3.5 10 -3 7.4 10 -3 2.2 10 -3 32 32</p><p>1.6 10 -3 3.71 10 -1 6.4 10 1 1.2 10 -2 4.2 10 -3 7.3 10 -3 2.1 10 -3 48 8</p><p>9.1 10 -3 9.39 10 0 5.3 10 -1 1.1 10 -2 3.6 10 -3 1.7 10 -2 8.9 10 -2 48 16  2.9 10 -3 1.15 10 0 1.0 10 1 7.9 10 -3 3.0 10 -3 9.7 10 -3 3.8 10 -3 48 24  1.1 10 -3 9.97 10 -2 1.9 10 2 1.3 10 -2 5.3 10 -3 1.1 10 -2 3.  An example of the solution of the data assimilation problem is presented in Fig. <ref type="figure" target="#fig_3">2</ref>: at the center we see = 4 observed trajectories, with a low level of noise; on the right, we see the reconstruction of the 64 trajectories performed by means of a variational method. The results of the numerical experiments are summarised in Table <ref type="table" target="#tab_4">3</ref>. In general, the behaviour of the method is very similar to the one observed for the previous case. When we consider = 10 -2 the model is less precise, but the lower dimensional space provides a regularisation which helps, in terms of observability, when having scarce observations. In this case, we observed that the variational approach always outperforms the sequential one and that the error is less than 5% on average. When having rich observations, the model error starts polluting the estimation, so that we cannot reach less than 1% of accuracy. When we consider a better approximation of the solutions set (taking = 10 -3 ), we observe that the data assimilation is particularly sensitive to the case of scarce observations ( = 2). In this case, the sequential method provides a better results, with an error that stays below 35%. When increasing the number of observed trajectories, the variational approach can reach an error which is below 1%.</p><p>We study the results as functions of the ranks. We fix = 8 and -1 = 10 4 . We take 1 = {16, 32, 48, 64} and 2 = {8, 16, 24, 32}. As for the previous case, we see that the and provide a good indication on the reconstruction error.</p></div>
<div><head n="4.2.1">4D-var estimation.</head><p>We present in this section the formulation of the 4D-var state estimation for the ABC flow. Let = [ <ref type="bibr" target="#b0">(1)</ref> , … , ( ) ] be the set of trajectories we would like to estimate, ̇ -( , ) = 0 be the evolution equation. The initial condition is known, but in order  We considered the following configurations for the data assimilation problem:</p><formula xml:id="formula_102">• = 3 2 , 4 2 , 5 2</formula><p>, regions, which corresponds to different degrees of space resolution in the observation.</p><p>• We considered two different levels of noise: -1 = 10 3 , 10 1</p><p>• The value of = 10 -3 , 10 -5 . For the case considered the TT ranks are ( 1 = 7, 2 = 2) and ( 1 = 12, 2 = 2)</p><p>respectively.</p><p>• The tests are performed by considering the solutions obtained by simulating the system when = 100 random samples of the parameters are drawn from a uniform distribution in the range of the parameters considered for the database.  <ref type="table">6</ref> Result of the test case described in Section 4.3, for the different ranks. Due to the graphical layout, we factorised the results for and and their values in terms of mean and variance have to be multiplied by 10 -2 .</p><p>In Table <ref type="table" target="#tab_7">5</ref> we report the results in terms of mean and variance for the velocity and the pressure reconstruction. For this case, we observe that the theoretical indicators of the system observability are roughly the same when we consider = 10 -3 or = 10 -5 , the differences being in the further digits. Moreover, the time history considered in relatively short. Since the number of measurements in time is low, the sequential method has a performance which is less satisfactory (the error being large in the first time steps). Concerning the other properties of the system such as the behaviour with respect to the model error and the amount of measurements considered, we observe analogous trends with respect to the ones commented for the two previous numerical experiments.</p><p>We study the performances of the state estimation when varying the rank. We fix = 4 2 and -1 = 10 3 . The ranks imposed are 1 = {4, 8, 12, 16} and 2 = {1, 2}.</p><p>The results are reported in Table <ref type="table">6</ref>. In this case, we clearly see that the element playing a key role in the ability of reaching a good accuracy in reconstructing the state is 2 . For 2 = 1 the error stagnates, for all values of 1 . When considering 2 = 2 the model error decreases substantially (reaching 10 -6 ), the values of , are almost stable, and the reconstruction error is significantly smaller. We give an interpretation of this behaviour hereafter, when commenting the 4D-var formulation for this problem.</p></div>
<div><head n="4.3.1">4D-var estimation.</head><p>We present in this section the formulation of the 4D-var state estimation The problem reads as follows: * , * , * , * , * = arg inf In the present case, thanks to the properties of the system, we can devise a more specific and fast method to solve the parameter estimation. Let us observe that the boundary conditions of the system depend linearly upon the parameters. Let ( <ref type="bibr" target="#b0">(1)</ref> , <ref type="bibr" target="#b0">(1)</ref> ) be the solution obtained when considering ( 1 = 1, 2 = 0) and ( ( <ref type="formula" target="#formula_4">2</ref>) , <ref type="bibr" target="#b1">(2)</ref> ) the solution obtained when considering ( 1 = 0, 2 = 1).</p><p>Then, a generic solution, by linearity, will be obtained as: ( , ) = 1 ( (1) , <ref type="bibr" target="#b0">(1)</ref> ) + 2 ( (2) , <ref type="bibr" target="#b1">(2)</ref> ). This can be inserted directly into the discrepancy, leading to a quadratic problem to be solved for 1 , 2 . The state is then reconstructed by performing one direct simulation. It is interesting to observe that the TT approximation retrieves this, as 2 = 2 for all model errors , leading to the same result. So, in this case, the strategies have more or less the same cost. However, we can remark that the 4D-var would be, in general, much more costly, and it can be accelerated by noticing and exploiting particular properties of the system. These are, in this case, automatically retrieved by the proposed method.</p></div>
<div><head>General remarks on the results.</head><p>The results commented in this section show that, despite the fact that the systems considered are quite different in terms of nature (kind of non-linearities, dynamics of the solution), the method has a uniform, stable behaviour. The differences observed between the variational and the sequential method are expected. Furthermore, the theoretical quantities based on the spectrum of the Observability matrix provide a good indication on the error made in the state estimation.</p></div>
<div><head n="5">CONCLUSION</head><p>In the present work we presented both a variational and a sequential formulations of the state estimation problem, which leverage the Tensor Train format representation of a set of parametric solutions of a system. Given the expression of the tensor train solution, it is possible to construct the observability matrix, whose spectrum provides an insight on the stability of the state estimation problem. The interpretation of the Tensor Train format used in the present work as a dynamical basis approximation makes it possible to naturally derive a sequential state estimation formulation. Several numerical results were proposed to assess the behaviour of the method. The main perspectives consist in extending the present approach to stochastic inverse problems, and to apply it to more realistic large scale systems.</p></div><figure xml:id="fig_0"><head /><label /><figDesc>first test proposed is on the Fisher-Kolmogorov-Petrovski-Piskunov (FKPP) equation. Let ∈ [0, 1] and ∈ [0, 5]. Let = 10 -3 , ∈ [0.5, 5] be the reaction coefficient, ∈ [0.1, 0.6], ∈ [100, 250], ∈ [0.25, 0.75] be the parameters determining the initial condition:</figDesc></figure>
<figure xml:id="fig_1"><head>FIGURE 1</head><label>1</label><figDesc>FIGURE 1 Test case presented in Section 4.1: (a-b) contour plots of two different solutions, for two different values of parameters. (c) Reconstruction at different time steps: the red dots are the observations, the black dashed line is the true state and the blue line is the solution of the variational data assimilation.</figDesc></figure>
<figure xml:id="fig_3"><head>FIGURE 2</head><label>2</label><figDesc>FIGURE 2 Test case presented in Section 4.2: (a) Lagrangian trajectories of 64 fluid particles. (b) Observed trajectories, affective by a low level noise. (c) Reconstruction performed by a variational method, in black, the true Lagrangian trajectories, in blue, the reconstructed ones.</figDesc><graphic coords="21,50.81,58.72,145.08,127.26" type="bitmap" /></figure>
<figure xml:id="fig_4"><head>-</head><label /><figDesc /></figure>
<figure xml:id="fig_6"><head>FIGURE 3</head><label>3</label><figDesc>FIGURE 3 Example of Stokes flow, Section 4.3, for 1 = 0.4 and 2 = 0.35. In (a) we show the velocity field and in (b) the contour lines of the pressure field, at time = 0.25.</figDesc><graphic coords="24,50.81,57.28,177.60,161.70" type="bitmap" /></figure>
<figure xml:id="fig_7"><head>2 ‖</head><label>2</label><figDesc>( ) -⟨ ( , , ), ⟩ 2 (Ω) ‖ 2 2, -∫ 0 ∫ Ω ( -Δ + ∇ ) + ∇ ⋅ .</figDesc></figure>
<figure type="table" xml:id="tab_1"><head>TABLE 1</head><label>1</label><figDesc>Result of the test case described in Section 4.1, for the different configurations of the data assimilation problem.</figDesc><table /></figure>
<figure type="table" xml:id="tab_2"><head>TABLE 2</head><label>2</label><figDesc>Result of the test case described in Section 4.1, as function of the ranks.</figDesc><table /></figure>
<figure type="table" xml:id="tab_4"><head>TABLE 3</head><label>3</label><figDesc>Result of the test case described in Section 4.2, for the different configurations of the data assimilation problem.</figDesc><table><row><cell>•</cell><cell>= {2, 4, 8, 16}, which corresponds to observations ranging from 3.1% to 25% of the number of trajectories (space</cell></row><row><cell /><cell>degrees of freedom).</cell></row></table></figure>
<figure type="table" xml:id="tab_6"><head>TABLE 4</head><label>4</label><figDesc>Result of the test case described in Section 4.2, as function of the ranks.</figDesc><table /></figure>
<figure type="table" xml:id="tab_7"><head>TABLE 5</head><label>5</label><figDesc>Result of the test case described in Section 4.3, for the different configurations of the data assimilation problem. Due to the graphical layout, we factorised the results for and and their values in terms of mean and variance have to be multiplied by 10 -2 .</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments:</head><p>The author acknowledges support from <rs type="funder">ANR</rs> grant <rs type="grantNumber">ADAPT 18-CE46-0001</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Xtp6eK4">
					<idno type="grant-number">ADAPT 18-CE46-0001</idno>
				</org>
			</listOrg>
			<div type="annex">
<div><p>to estimate the state we need to estimate the parameters = [ , , ]. The problem reads as follows: * , * , * = arg inf , sup ( , , ),</p><p>where the observation reduces to trajectories indexed by [ 1 , … , ]. To solve the variational data assimilation we considered the time discretisation of the direct system and derived the equation for (the dynamics of the backward system is linear, with a block diagonal matrix). We applied a classical forward backward strategy. As in the previous case, we were able to obtain results</p><p>with an error which is similar. However, to mitigate the effect of possible local minima, we are obliged to test the optimisation by changing initialisation for the parameters, which represents, of course, an extra cost.</p></div>
<div><head n="4.3">2D unsteady Stokes flow.</head><p>The last example we propose is a Stokes flow. It is a linear system, whose solution is a vector valued function. Let Ω = [0, 1] 2 , = [0, 1], the fluid density be = 1 and the viscosity be = 0.05. Let ( , ) be the velocity field, let be the pressure. We consider the following system of equations:</p><p>This is a classical 2D lid driven cavity setup. In the present work we consider, as parameters, the amplitude of the velocity field prescribed on the top of the cavity:</p><p>The observation consists of the set of the average velocity in subsets of the domain. Let Ω be partitioned in of non-overlapping squares Ω (such that ⋃ 1≤ ≤ Ω = Ω), the -th observation at time is the vector:</p><p>that is to say, we measure the average of the velocity on certain regions. The system was simulated by P2-P1 finite elements (with a number of degrees of freedom of, roughly 2600 for the velocity and 680 for the pressure). In time, we considered an implicit Euler, with Δ = 1∕20.</p><p>An example of the solution is shown in Figure <ref type="figure">3</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Data assimilation</title>
		<author>
			<persName><forename type="first">Bkw</forename><surname>Lahoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Menard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">State estimation for dynamic systems</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Chernousko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">State estimation in distributed parameter systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Wouwer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zeitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Control Systems, Robotics and Automation-Volume XIV: Nonlinear, Distributed, and Time Delay Systems-III</title>
		<imprint>
			<biblScope unit="page">92</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Optimal state estimation: Kalman, H infinity, and nonlinear approaches</title>
		<author>
			<persName><forename type="first">D</forename><surname>Simon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Classification, Parameter Estimation and State Estimation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Aerodynamic data reconstruction and inverse design using proper orthogonal decomposition</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bui-Thanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Damodaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Willcox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIAA journal</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1505" to="1516" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A reduced-order strategy for 4D-Var data assimilation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Durbiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Blayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Dimet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Marine Systems</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="70" to="82" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A non-linear observer for unsteady three-dimensional flows</title>
		<author>
			<persName><forename type="first">M</forename><surname>Buffoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Camarri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Iollo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lombardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Salvetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">227</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2626" to="2643" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reduced basis approximation and a posteriori error bounds for 4D-Var data assimilation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kaercher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boyaval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Grepl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Veroy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization and Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="663" to="695" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">3D-VAR for parameterized partial differential equations: a certified reduced basis approach</title>
		<author>
			<persName><forename type="first">N</forename><surname>Aretz-Nellesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Grepl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Veroy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Computational Mathematics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2369" to="2400" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">POD/DEIM Strategies for reduced data assimilation systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Stefanescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sandu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Navon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A POD reduced-order 4D-Var adaptive mesh ocean modelling approach</title>
		<author>
			<persName><forename type="first">F</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Navon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal for Numerical Methods in Fluids</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="709" to="732" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Reduced order modeling based on POD of a parabolized Navier-Stokes equations model II: Trust region POD 4D VAR data assimilation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Navon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Alekseev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Mathematics with Applications</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="380" to="394" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reduced order methods for parametric optimal flow control in coronary bypass grafts, toward patient-specific data assimilation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zainib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ballarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fremes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Triverio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiménez-Juan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rozza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal for Numerical Methods in Biomedical Engineering</title>
		<imprint>
			<biblScope unit="page">3367</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A low-rank approach to the solution of weak constraint variational data assimilation problems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">357</biblScope>
			<biblScope unit="page" from="263" to="281" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Low rank updates in preconditioning the saddle point systems arising from data assimilation problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gratton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gürol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Trémolet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Vasseur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization Methods and Software</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="69" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Special issue on sequential state estimation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haykin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="399" to="400" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The SEEK filter method for data assimilation in oceanography: a synthesis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Brasseur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Verron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ocean Dynamics</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="650" to="661" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Data assimilation: the ensemble Kalman filter</title>
		<author>
			<persName><forename type="first">G</forename><surname>Evensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Sequential state estimation for electrophysiology models with front level-set data using topological gradient derivations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Collin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moireau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="402" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">State observers of a vascular fluid-structure interaction model through measurements in the solid</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bertoglio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Gerbeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moireau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Methods in Applied Mechanics and Engineering</title>
		<imprint>
			<biblScope unit="volume">256</biblScope>
			<biblScope unit="page" from="149" to="168" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A discrete-time optimal filtering approach for non-linear systems as a stable discretization of the Mortensen observer</title>
		<author>
			<persName><forename type="first">P</forename><surname>Moireau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ESAIM: Control, Optimisation and Calculus of Variations</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1815" to="1847" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using low-rank ensemble Kalman filters for data assimilation with high dimensional imperfect models</title>
		<author>
			<persName><forename type="first">I</forename><surname>Hoteit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Triantafyllou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Korres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JNAIAM</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="67" to="78" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient state/parameter estimation in nonlinear unsteady PDEs by a reduced basis ensemble Kalman filter</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pagani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Manzoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Quarteroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM/ASA Journal on Uncertainty Quantification</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="890" to="921" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Time-resolved flow reconstruction with indirect measurements using regression models and Kalman-filtered POD ROM</title>
		<author>
			<persName><forename type="first">R</forename><surname>Leroux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chatellier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>David</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experiments in Fluids</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Parameterised non-intrusive reduced order methods for ensemble Kalman filter data assimilation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Fluids</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="page" from="69" to="77" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A multifidelity ensemble Kalman filter with reduced order control variates</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Popov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sandu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Iliescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1134" to="A1162" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bayesian inversion for electromyography using low-rank tensor formats</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rörich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Werthmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Göddeke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Grasedyck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inverse Problems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">55003</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Tensor Network Kalman filter with an application in recursive MIMO Volterra system identification</title>
		<author>
			<persName><forename type="first">K</forename><surname>Batselier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="17" to="25" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Kalman Filter for Multilinear Forms and Its Connection with Tensorial Adaptive Filters</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Paleologu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Benesty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Stanciu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Oprea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ciochină</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">3555</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Low-Rank Hankel Tensor Completion for Traffic Speed Estimation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.113352021</idno>
		<imprint />
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A survey of optimal recovery</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Micchelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Rivlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Optimal estimation in approximation theory</title>
		<imprint>
			<date type="published" when="1977">1977</date>
			<biblScope unit="page" from="1" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">PBDW state estimation: Noisy observations; configuration-adaptive background spaces; physical interpretations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Maday</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Patera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Penn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ESAIM: Proceedings and Surveys</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="144" to="168" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">PBDW method for state estimation: error analysis for noisy data and nonlinear formulation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Maday</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Taddei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.008102019</idno>
		<imprint />
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Adaptive PBDW approach to state estimation: noisy observations; user-defined update spaces</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Maday</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Taddei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="669" to="B693" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Data assimilation in reduced modeling</title>
		<author>
			<persName><forename type="first">P</forename><surname>Binev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dahmen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Devore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Petrova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wojtaszczyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM/ASA Journal on Uncertainty Quantification</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Greedy algorithms for optimal measurements selection in state estimation using reduced models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Binev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nichols</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM/ASA Journal on Uncertainty Quantification</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1101" to="1126" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An adaptive parametrized-background data-weak approach to variational data assimilation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Taddei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ESAIM: Mathematical Modelling and Numerical Analysis</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1827" to="1858" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A Time-Dependent Parametrized Background Data-Weak Approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Benaceur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Numerical Mathematics and Advanced Applications ENUMATH</title>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Vermolen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Vuik</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019">2019. 2021</date>
			<biblScope unit="volume">Cham</biblScope>
			<biblScope unit="page" from="125" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Tensor-train decomposition</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Oseledets</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2295" to="2317" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Spectral tensor-train decomposition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bigoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Engsig-Karup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Marzouk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2405" to="A2439" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A continuous analogue of the tensor-train decomposition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gorodetsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Marzouk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer methods in applied mechanics and engineering</title>
		<imprint>
			<biblScope unit="volume">347</biblScope>
			<biblScope unit="page" from="59" to="84" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Fast solution of parabolic problems in the tensor train/quantized tensor train format with initial application to the Fokker-Planck equation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Dolgov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename><surname>Khoromskij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Oseledets</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3016" to="A3038" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Enabling high-dimensional hierarchical uncertainty quantification by ANOVA and tensor-train decomposition</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Oseledets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Daniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="76" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Polynomial chaos expansion of random coefficients and the solution of stochastic partial differential equations in the tensor train format</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dolgov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename><surname>Khoromskij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Litvinenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Matthies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM/ASA Journal on Uncertainty Quantification</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1109" to="1135" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Low-rank tensor methods for model order reduction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nouy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.015552015</idno>
		<imprint />
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Adaptive low-rank methods: problems on Sobolev spaces</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bachmayr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dahmen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Numerical Analysis</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="744" to="796" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A tensor-train accelerated solver for integral equations in complex geometries</title>
		<author>
			<persName><forename type="first">E</forename><surname>Corona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rahimian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zorin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">334</biblScope>
			<biblScope unit="page" from="145" to="169" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">High-dimensional uncertainty quantification for an electrothermal field problem using stochastic collocation on sparse grids and tensor train decompositions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Loukrezis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Römer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schöps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Gersem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Numerical Modelling: Electronic Networks, Devices and Fields</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">e2222</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Observability, eigenvalues, and Kalman filtering</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Aerospace and Electronic Systems</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="269" to="273" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Bounds for eigenvalues using traces</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wolkowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Styan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linear algebra and its applications</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="471" to="506" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Bounds for the trace of the inverse and the determinant of symmetric positive definite matrices</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Numerical Mathematics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="29" to="38" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>